{
  "rootPackage": {
    "endpoints": [
      {
        "environments": [{ "id": "Default", "baseUrl": "https://{yourserver}.com" }],
        "defaultEnvironment": "Default",
        "urlSlug": "server-message",
        "method": "POST",
        "id": "serverMessage",
        "originalEndpointId": "endpoint_.serverMessage",
        "name": "Server Message",
        "path": {
          "pathParameters": [],
          "parts": [
            { "type": "literal", "value": "" },
            { "type": "literal", "value": "/server" }
          ]
        },
        "queryParameters": [],
        "headers": [],
        "request": {
          "contentType": "application/json",
          "type": {
            "type": "object",
            "extends": [],
            "properties": [
              {
                "description": "These are all the messages that can be sent to your server before, after and during the call. Configure the messages you'd like to receive in `assistant.serverMessages`.\n\nThe server where the message is sent is determined by the following precedence order:\n\n1. `tool.server.url` (if configured, and only for \"tool-calls\" message)\n2. `assistant.serverUrl` (if configure)\n3. `phoneNumber.serverUrl` (if configured)\n4. `org.serverUrl` (if configured)",
                "key": "message",
                "valueType": { "type": "id", "value": "type_:ServerMessageMessage" }
              }
            ]
          }
        },
        "response": {
          "type": { "type": "reference", "value": { "type": "id", "value": "type_:ServerMessageResponse" } },
          "description": "This is the response that is expected from the server to the message.\n\nNote: Most messages don't expect a response. Only \"assistant-request\", \"tool-calls\" and \"transfer-destination-request\" do.\n"
        },
        "errors": [],
        "errorsV2": [],
        "examples": [
          {
            "path": "/server",
            "pathParameters": {},
            "queryParameters": {},
            "headers": {},
            "requestBody": { "message": { "type": "voice-request", "text": "message", "sampleRate": 1.1 } },
            "responseStatusCode": 200,
            "responseBody": {
              "messageResponse": {
                "destination": {
                  "type": "sip",
                  "sipUri": "destination",
                  "message": "destination",
                  "description": "destination"
                },
                "assistantId": "assistantId",
                "assistant": {
                  "transcriber": { "provider": "talkscriber" },
                  "model": { "provider": "vapi", "model": "model" },
                  "voice": { "provider": "rime-ai", "fillerInjectionEnabled": false, "voiceId": "marsh" },
                  "firstMessageMode": "assistant-speaks-first",
                  "hipaaEnabled": false,
                  "clientMessages": [
                    "conversation-update",
                    "function-call",
                    "hang",
                    "model-output",
                    "speech-update",
                    "status-update",
                    "transcript",
                    "tool-calls",
                    "user-interrupted",
                    "voice-input"
                  ],
                  "serverMessages": [
                    "conversation-update",
                    "end-of-call-report",
                    "function-call",
                    "hang",
                    "speech-update",
                    "status-update",
                    "tool-calls",
                    "transfer-destination-request",
                    "user-interrupted"
                  ],
                  "silenceTimeoutSeconds": 30,
                  "maxDurationSeconds": 600,
                  "backgroundSound": "off",
                  "backchannelingEnabled": false,
                  "backgroundDenoisingEnabled": false,
                  "modelOutputInMessagesEnabled": false,
                  "transportConfigurations": [{ "provider": "twilio", "timeout": 60, "record": false }],
                  "name": "name",
                  "firstMessage": "firstMessage",
                  "voicemailDetection": { "provider": "twilio" },
                  "voicemailMessage": "voicemailMessage",
                  "endCallMessage": "endCallMessage",
                  "endCallPhrases": ["endCallPhrases"],
                  "metadata": { "key": "value" },
                  "serverUrl": "serverUrl",
                  "serverUrlSecret": "serverUrlSecret",
                  "artifactPlan": { "recordingEnabled": true, "videoRecordingEnabled": false },
                  "startSpeakingPlan": { "waitSeconds": 0.4, "smartEndpointingEnabled": false },
                  "stopSpeakingPlan": { "numWords": 0, "voiceSeconds": 0.2, "backoffSeconds": 1 },
                  "monitorPlan": { "listenEnabled": false, "controlEnabled": false },
                  "credentialIds": ["credentialIds"]
                },
                "assistantOverrides": {
                  "transcriber": { "provider": "talkscriber" },
                  "model": { "provider": "vapi", "model": "model" },
                  "voice": { "provider": "rime-ai", "fillerInjectionEnabled": false, "voiceId": "marsh" },
                  "firstMessageMode": "assistant-speaks-first",
                  "hipaaEnabled": false,
                  "clientMessages": [
                    "conversation-update",
                    "function-call",
                    "hang",
                    "model-output",
                    "speech-update",
                    "status-update",
                    "transcript",
                    "tool-calls",
                    "user-interrupted",
                    "voice-input"
                  ],
                  "serverMessages": [
                    "conversation-update",
                    "end-of-call-report",
                    "function-call",
                    "hang",
                    "speech-update",
                    "status-update",
                    "tool-calls",
                    "transfer-destination-request",
                    "user-interrupted"
                  ],
                  "silenceTimeoutSeconds": 30,
                  "maxDurationSeconds": 600,
                  "backgroundSound": "off",
                  "backchannelingEnabled": false,
                  "backgroundDenoisingEnabled": false,
                  "modelOutputInMessagesEnabled": false,
                  "transportConfigurations": [{ "provider": "twilio", "timeout": 60, "record": false }],
                  "variableValues": { "key": "value" },
                  "name": "name",
                  "firstMessage": "firstMessage",
                  "voicemailDetection": { "provider": "twilio" },
                  "voicemailMessage": "voicemailMessage",
                  "endCallMessage": "endCallMessage",
                  "endCallPhrases": ["endCallPhrases"],
                  "metadata": { "key": "value" },
                  "serverUrl": "serverUrl",
                  "serverUrlSecret": "serverUrlSecret",
                  "artifactPlan": { "recordingEnabled": true, "videoRecordingEnabled": false },
                  "startSpeakingPlan": { "waitSeconds": 0.4, "smartEndpointingEnabled": false },
                  "stopSpeakingPlan": { "numWords": 0, "voiceSeconds": 0.2, "backoffSeconds": 1 },
                  "monitorPlan": { "listenEnabled": false, "controlEnabled": false },
                  "credentialIds": ["credentialIds"]
                },
                "squadId": "squadId",
                "squad": {
                  "name": "name",
                  "members": [{}],
                  "membersOverrides": {
                    "hipaaEnabled": false,
                    "silenceTimeoutSeconds": 30,
                    "maxDurationSeconds": 600,
                    "backchannelingEnabled": false,
                    "backgroundDenoisingEnabled": false,
                    "modelOutputInMessagesEnabled": false
                  }
                },
                "error": "error"
              }
            },
            "codeExamples": { "nodeAxios": "" },
            "requestBodyV3": {
              "type": "json",
              "value": { "message": { "type": "voice-request", "text": "message", "sampleRate": 1.1 } }
            },
            "responseBodyV3": {
              "type": "json",
              "value": {
                "messageResponse": {
                  "destination": {
                    "type": "sip",
                    "sipUri": "destination",
                    "message": "destination",
                    "description": "destination"
                  },
                  "assistantId": "assistantId",
                  "assistant": {
                    "transcriber": { "provider": "talkscriber" },
                    "model": { "provider": "vapi", "model": "model" },
                    "voice": { "provider": "rime-ai", "fillerInjectionEnabled": false, "voiceId": "marsh" },
                    "firstMessageMode": "assistant-speaks-first",
                    "hipaaEnabled": false,
                    "clientMessages": [
                      "conversation-update",
                      "function-call",
                      "hang",
                      "model-output",
                      "speech-update",
                      "status-update",
                      "transcript",
                      "tool-calls",
                      "user-interrupted",
                      "voice-input"
                    ],
                    "serverMessages": [
                      "conversation-update",
                      "end-of-call-report",
                      "function-call",
                      "hang",
                      "speech-update",
                      "status-update",
                      "tool-calls",
                      "transfer-destination-request",
                      "user-interrupted"
                    ],
                    "silenceTimeoutSeconds": 30,
                    "maxDurationSeconds": 600,
                    "backgroundSound": "off",
                    "backchannelingEnabled": false,
                    "backgroundDenoisingEnabled": false,
                    "modelOutputInMessagesEnabled": false,
                    "transportConfigurations": [{ "provider": "twilio", "timeout": 60, "record": false }],
                    "name": "name",
                    "firstMessage": "firstMessage",
                    "voicemailDetection": { "provider": "twilio" },
                    "voicemailMessage": "voicemailMessage",
                    "endCallMessage": "endCallMessage",
                    "endCallPhrases": ["endCallPhrases"],
                    "metadata": { "key": "value" },
                    "serverUrl": "serverUrl",
                    "serverUrlSecret": "serverUrlSecret",
                    "artifactPlan": { "recordingEnabled": true, "videoRecordingEnabled": false },
                    "startSpeakingPlan": { "waitSeconds": 0.4, "smartEndpointingEnabled": false },
                    "stopSpeakingPlan": { "numWords": 0, "voiceSeconds": 0.2, "backoffSeconds": 1 },
                    "monitorPlan": { "listenEnabled": false, "controlEnabled": false },
                    "credentialIds": ["credentialIds"]
                  },
                  "assistantOverrides": {
                    "transcriber": { "provider": "talkscriber" },
                    "model": { "provider": "vapi", "model": "model" },
                    "voice": { "provider": "rime-ai", "fillerInjectionEnabled": false, "voiceId": "marsh" },
                    "firstMessageMode": "assistant-speaks-first",
                    "hipaaEnabled": false,
                    "clientMessages": [
                      "conversation-update",
                      "function-call",
                      "hang",
                      "model-output",
                      "speech-update",
                      "status-update",
                      "transcript",
                      "tool-calls",
                      "user-interrupted",
                      "voice-input"
                    ],
                    "serverMessages": [
                      "conversation-update",
                      "end-of-call-report",
                      "function-call",
                      "hang",
                      "speech-update",
                      "status-update",
                      "tool-calls",
                      "transfer-destination-request",
                      "user-interrupted"
                    ],
                    "silenceTimeoutSeconds": 30,
                    "maxDurationSeconds": 600,
                    "backgroundSound": "off",
                    "backchannelingEnabled": false,
                    "backgroundDenoisingEnabled": false,
                    "modelOutputInMessagesEnabled": false,
                    "transportConfigurations": [{ "provider": "twilio", "timeout": 60, "record": false }],
                    "variableValues": { "key": "value" },
                    "name": "name",
                    "firstMessage": "firstMessage",
                    "voicemailDetection": { "provider": "twilio" },
                    "voicemailMessage": "voicemailMessage",
                    "endCallMessage": "endCallMessage",
                    "endCallPhrases": ["endCallPhrases"],
                    "metadata": { "key": "value" },
                    "serverUrl": "serverUrl",
                    "serverUrlSecret": "serverUrlSecret",
                    "artifactPlan": { "recordingEnabled": true, "videoRecordingEnabled": false },
                    "startSpeakingPlan": { "waitSeconds": 0.4, "smartEndpointingEnabled": false },
                    "stopSpeakingPlan": { "numWords": 0, "voiceSeconds": 0.2, "backoffSeconds": 1 },
                    "monitorPlan": { "listenEnabled": false, "controlEnabled": false },
                    "credentialIds": ["credentialIds"]
                  },
                  "squadId": "squadId",
                  "squad": {
                    "name": "name",
                    "members": [{}],
                    "membersOverrides": {
                      "hipaaEnabled": false,
                      "silenceTimeoutSeconds": 30,
                      "maxDurationSeconds": 600,
                      "backchannelingEnabled": false,
                      "backgroundDenoisingEnabled": false,
                      "modelOutputInMessagesEnabled": false
                    }
                  },
                  "error": "error"
                }
              }
            },
            "codeSamples": []
          }
        ],
        "description": "",
        "authed": false
      },
      {
        "environments": [{ "id": "Default", "baseUrl": "https://{yourserver}.com" }],
        "defaultEnvironment": "Default",
        "urlSlug": "client-message",
        "method": "POST",
        "id": "clientMessage",
        "originalEndpointId": "endpoint_.clientMessage",
        "name": "Client Message",
        "path": {
          "pathParameters": [],
          "parts": [
            { "type": "literal", "value": "" },
            { "type": "literal", "value": "/client" }
          ]
        },
        "queryParameters": [],
        "headers": [],
        "request": {
          "contentType": "application/json",
          "type": {
            "type": "object",
            "extends": [],
            "properties": [
              {
                "description": "These are all the messages that can be sent to the client-side SDKs during the call. Configure the messages you'd like to receive in `assistant.clientMessages`.",
                "key": "message",
                "valueType": { "type": "id", "value": "type_:ClientMessageMessage" }
              }
            ]
          }
        },
        "response": {
          "type": { "type": "reference", "value": { "type": "id", "value": "type_:ClientInboundMessage" } },
          "description": "These are the messages that can be sent from client-side SDKs to control the call."
        },
        "errors": [],
        "errorsV2": [],
        "examples": [
          {
            "path": "/client",
            "pathParameters": {},
            "queryParameters": {},
            "headers": {},
            "requestBody": { "message": { "type": "voice-input", "input": "message" } },
            "responseStatusCode": 200,
            "responseBody": { "message": { "type": "say", "content": "message", "endCallAfterSpoken": true } },
            "codeExamples": { "nodeAxios": "" },
            "requestBodyV3": {
              "type": "json",
              "value": { "message": { "type": "voice-input", "input": "message" } }
            },
            "responseBodyV3": {
              "type": "json",
              "value": { "message": { "type": "say", "content": "message", "endCallAfterSpoken": true } }
            },
            "codeSamples": []
          }
        ],
        "description": "These are all the webhook messages that will be sent to the client-side SDKs during the call.\nConfigure the messages you'd like to receive in `assistant.clientMessages``.",
        "authed": false
      }
    ],
    "subpackages": [],
    "types": [
      "type_:ServerMessageMessage",
      "type_:ClientMessageMessage",
      "type_:TransferDestinationNumber",
      "type_:TransferDestinationSip",
      "type_:CreateByoPhoneNumberDtoFallbackDestination",
      "type_:CreateByoPhoneNumberDto",
      "type_:CreateTwilioPhoneNumberDtoFallbackDestination",
      "type_:CreateTwilioPhoneNumberDto",
      "type_:CreateVonagePhoneNumberDtoFallbackDestination",
      "type_:CreateVonagePhoneNumberDto",
      "type_:CreateVapiPhoneNumberDtoFallbackDestination",
      "type_:CreateVapiPhoneNumberDto",
      "type_:UserMessage",
      "type_:SystemMessage",
      "type_:BotMessage",
      "type_:ToolCallMessage",
      "type_:ToolCallResultMessage",
      "type_:OpenAiMessageRole",
      "type_:OpenAiMessage",
      "type_:ArtifactMessagesItem",
      "type_:Artifact",
      "type_:DeepgramTranscriber",
      "type_:GladiaTranscriberModel",
      "type_:GladiaTranscriberLanguageBehaviour",
      "type_:GladiaTranscriberLanguage",
      "type_:GladiaTranscriber",
      "type_:TalkscriberTranscriberLanguage",
      "type_:TalkscriberTranscriber",
      "type_:ConditionOperator",
      "type_:Condition",
      "type_:ToolMessageStart",
      "type_:ToolMessageCompleteRole",
      "type_:ToolMessageComplete",
      "type_:ToolMessageFailed",
      "type_:ToolMessageDelayed",
      "type_:JsonSchemaType",
      "type_:JsonSchema",
      "type_:OpenAiFunctionParameters",
      "type_:OpenAiFunction",
      "type_:Server",
      "type_:CreateDtmfToolDtoMessagesItem",
      "type_:CreateDtmfToolDto",
      "type_:CreateEndCallToolDtoMessagesItem",
      "type_:CreateEndCallToolDto",
      "type_:CreateVoicemailToolDtoMessagesItem",
      "type_:CreateVoicemailToolDto",
      "type_:CreateFunctionToolDtoMessagesItem",
      "type_:CreateFunctionToolDto",
      "type_:GhlToolMetadata",
      "type_:CreateGhlToolDtoMessagesItem",
      "type_:CreateGhlToolDto",
      "type_:MakeToolMetadata",
      "type_:CreateMakeToolDtoMessagesItem",
      "type_:CreateMakeToolDto",
      "type_:TransferDestinationAssistant",
      "type_:TransferDestinationStep",
      "type_:CreateTransferCallToolDtoMessagesItem",
      "type_:CreateTransferCallToolDtoDestinationsItem",
      "type_:CreateTransferCallToolDto",
      "type_:KnowledgeBase",
      "type_:AnyscaleModelToolsItem",
      "type_:AnyscaleModel",
      "type_:AnthropicModelToolsItem",
      "type_:AnthropicModelModel",
      "type_:AnthropicModel",
      "type_:CustomLlmModelToolsItem",
      "type_:CustomLlmModelMetadataSendMode",
      "type_:CustomLlmModel",
      "type_:DeepInfraModelToolsItem",
      "type_:DeepInfraModel",
      "type_:GroqModelToolsItem",
      "type_:GroqModelModel",
      "type_:GroqModel",
      "type_:OpenAiModelToolsItem",
      "type_:OpenAiModelModel",
      "type_:OpenAiModelFallbackModelsItem",
      "type_:OpenAiModel",
      "type_:OpenRouterModelToolsItem",
      "type_:OpenRouterModel",
      "type_:PerplexityAiModelToolsItem",
      "type_:PerplexityAiModel",
      "type_:TogetherAiModelToolsItem",
      "type_:TogetherAiModel",
      "type_:ModelBasedCondition",
      "type_:RuleBasedConditionOperator",
      "type_:RuleBasedCondition",
      "type_:BlockStartMessageConditionsItem",
      "type_:BlockStartMessage",
      "type_:BlockCompleteMessageConditionsItem",
      "type_:BlockCompleteMessage",
      "type_:CreateConversationBlockDtoMessagesItem",
      "type_:CreateConversationBlockDto",
      "type_:CreateToolCallBlockDtoMessagesItem",
      "type_:CreateToolCallBlockDtoTool",
      "type_:CreateToolCallBlockDto",
      "type_:HandoffStepBlock",
      "type_:HandoffStep",
      "type_:CreateWorkflowBlockDtoMessagesItem",
      "type_:CreateWorkflowBlockDtoStepsItem",
      "type_:CreateWorkflowBlockDto",
      "type_:AssignmentMutationConditionsItem",
      "type_:AssignmentMutation",
      "type_:CallbackStepBlock",
      "type_:CallbackStep",
      "type_:StepDestinationConditionsItem",
      "type_:StepDestination",
      "type_:VapiModelToolsItem",
      "type_:VapiModelStepsItem",
      "type_:VapiModel",
      "type_:ExactReplacement",
      "type_:RegexOptionType",
      "type_:RegexOption",
      "type_:RegexReplacement",
      "type_:FormatPlanReplacementsItem",
      "type_:FormatPlan",
      "type_:ChunkPlan",
      "type_:AzureVoiceId",
      "type_:AzureVoice",
      "type_:CartesiaVoiceModel",
      "type_:CartesiaVoiceLanguage",
      "type_:CartesiaVoice",
      "type_:DeepgramVoiceId",
      "type_:DeepgramVoice",
      "type_:ElevenLabsVoiceId",
      "type_:ElevenLabsVoiceModel",
      "type_:ElevenLabsVoice",
      "type_:LMNTVoiceId",
      "type_:LmntVoice",
      "type_:NeetsVoiceId",
      "type_:NeetsVoice",
      "type_:OpenAIVoiceId",
      "type_:OpenAiVoice",
      "type_:PlayHtVoiceVoiceId",
      "type_:PlayHtVoiceEmotion",
      "type_:PlayHtVoice",
      "type_:RimeAIVoiceId",
      "type_:RimeAiVoiceModel",
      "type_:RimeAiVoice",
      "type_:TransportConfigurationTwilioRecordingChannels",
      "type_:TransportConfigurationTwilio",
      "type_:TwilioVoicemailDetectionVoicemailDetectionTypesItem",
      "type_:TwilioVoicemailDetection",
      "type_:SummaryPlan",
      "type_:StructuredDataPlan",
      "type_:SuccessEvaluationPlanRubric",
      "type_:SuccessEvaluationPlan",
      "type_:AnalysisPlan",
      "type_:TranscriptPlan",
      "type_:ArtifactPlan",
      "type_:MessagePlan",
      "type_:TranscriptionEndpointingPlan",
      "type_:StartSpeakingPlan",
      "type_:StopSpeakingPlan",
      "type_:MonitorPlan",
      "type_:CreateAssistantDtoTranscriber",
      "type_:CreateAssistantDtoModel",
      "type_:CreateAssistantDtoVoice",
      "type_:CreateAssistantDtoFirstMessageMode",
      "type_:CreateAssistantDtoClientMessagesItem",
      "type_:CreateAssistantDtoServerMessagesItem",
      "type_:CreateAssistantDtoBackgroundSound",
      "type_:CreateAssistantDto",
      "type_:CreateCustomerDto",
      "type_:TransportCost",
      "type_:TranscriberCost",
      "type_:ModelCost",
      "type_:VoiceCost",
      "type_:VapiCost",
      "type_:AnalysisCostAnalysisType",
      "type_:AnalysisCost",
      "type_:AnalysisCostBreakdown",
      "type_:CostBreakdown",
      "type_:Analysis",
      "type_:Monitor",
      "type_:AssistantOverridesTranscriber",
      "type_:AssistantOverridesModel",
      "type_:AssistantOverridesVoice",
      "type_:AssistantOverridesFirstMessageMode",
      "type_:AssistantOverridesClientMessagesItem",
      "type_:AssistantOverridesServerMessagesItem",
      "type_:AssistantOverridesBackgroundSound",
      "type_:AssistantOverrides",
      "type_:SquadMemberDto",
      "type_:CreateSquadDto",
      "type_:ImportTwilioPhoneNumberDtoFallbackDestination",
      "type_:ImportTwilioPhoneNumberDto",
      "type_:CallType",
      "type_:CallCostsItem",
      "type_:CallMessagesItem",
      "type_:CallPhoneCallProvider",
      "type_:CallPhoneCallTransport",
      "type_:CallStatus",
      "type_:CallEndedReason",
      "type_:CallDestination",
      "type_:Call",
      "type_:ServerMessageAssistantRequestPhoneNumber",
      "type_:ServerMessageAssistantRequest",
      "type_:ServerMessageConversationUpdatePhoneNumber",
      "type_:ServerMessageConversationUpdateMessagesItem",
      "type_:ServerMessageConversationUpdate",
      "type_:ServerMessageEndOfCallReportPhoneNumber",
      "type_:ServerMessageEndOfCallReportEndedReason",
      "type_:ServerMessageEndOfCallReportCostsItem",
      "type_:ServerMessageEndOfCallReport",
      "type_:ServerMessageHangPhoneNumber",
      "type_:ServerMessageHang",
      "type_:ServerMessageModelOutputPhoneNumber",
      "type_:ServerMessageModelOutput",
      "type_:ServerMessagePhoneCallControlPhoneNumber",
      "type_:ServerMessagePhoneCallControlRequest",
      "type_:ServerMessagePhoneCallControlDestination",
      "type_:ServerMessagePhoneCallControl",
      "type_:ServerMessageSpeechUpdatePhoneNumber",
      "type_:ServerMessageSpeechUpdateStatus",
      "type_:ServerMessageSpeechUpdateRole",
      "type_:ServerMessageSpeechUpdate",
      "type_:ServerMessageStatusUpdatePhoneNumber",
      "type_:ServerMessageStatusUpdateStatus",
      "type_:ServerMessageStatusUpdateEndedReason",
      "type_:ServerMessageStatusUpdateMessagesItem",
      "type_:ServerMessageStatusUpdateDestination",
      "type_:ServerMessageStatusUpdate",
      "type_:ToolCallFunction",
      "type_:ToolCall",
      "type_:FunctionToolWithToolCallMessagesItem",
      "type_:FunctionToolWithToolCall",
      "type_:GhlToolWithToolCallMessagesItem",
      "type_:GhlToolWithToolCall",
      "type_:MakeToolWithToolCallMessagesItem",
      "type_:MakeToolWithToolCall",
      "type_:ServerMessageToolCallsPhoneNumber",
      "type_:ServerMessageToolCallsToolWithToolCallListItem",
      "type_:ServerMessageToolCalls",
      "type_:ServerMessageTransferDestinationRequestPhoneNumber",
      "type_:ServerMessageTransferDestinationRequest",
      "type_:ServerMessageTransferUpdatePhoneNumber",
      "type_:ServerMessageTransferUpdateDestination",
      "type_:ServerMessageTransferUpdate",
      "type_:ServerMessageTranscriptPhoneNumber",
      "type_:ServerMessageTranscriptRole",
      "type_:ServerMessageTranscriptTranscriptType",
      "type_:ServerMessageTranscript",
      "type_:ServerMessageUserInterruptedPhoneNumber",
      "type_:ServerMessageUserInterrupted",
      "type_:ServerMessageLanguageChangedPhoneNumber",
      "type_:ServerMessageLanguageChanged",
      "type_:ServerMessageVoiceInputPhoneNumber",
      "type_:ServerMessageVoiceInput",
      "type_:ServerMessageVoiceRequestPhoneNumber",
      "type_:ServerMessageVoiceRequest",
      "type_:ServerMessageResponseAssistantRequestDestination",
      "type_:ServerMessageResponseAssistantRequest",
      "type_:ToolCallResultMessageItem",
      "type_:ToolCallResult",
      "type_:ServerMessageResponseToolCalls",
      "type_:ServerMessageResponseTransferDestinationRequestDestination",
      "type_:ServerMessageResponseTransferDestinationRequest",
      "type_:ServerMessageResponseVoiceRequest",
      "type_:ServerMessageResponseMessageResponse",
      "type_:ServerMessageResponse",
      "type_:ClientMessageConversationUpdateMessagesItem",
      "type_:ClientMessageConversationUpdate",
      "type_:ClientMessageHang",
      "type_:ClientMessageMetadata",
      "type_:ClientMessageModelOutput",
      "type_:ClientMessageSpeechUpdateStatus",
      "type_:ClientMessageSpeechUpdateRole",
      "type_:ClientMessageSpeechUpdate",
      "type_:ClientMessageTranscriptRole",
      "type_:ClientMessageTranscriptTranscriptType",
      "type_:ClientMessageTranscript",
      "type_:ClientMessageToolCallsToolWithToolCallListItem",
      "type_:ClientMessageToolCalls",
      "type_:ClientMessageToolCallsResult",
      "type_:ClientMessageUserInterrupted",
      "type_:ClientMessageLanguageChanged",
      "type_:ClientMessageVoiceInput",
      "type_:ClientInboundMessageAddMessage",
      "type_:ClientInboundMessageControlControl",
      "type_:ClientInboundMessageControl",
      "type_:ClientInboundMessageSay",
      "type_:ClientInboundMessageMessage",
      "type_:ClientInboundMessage",
      "type_:DeepgramTranscriberLanguage",
      "type_:DeepgramTranscriberModel",
      "type_:TransferMode",
      "type_:PunctuationBoundary"
    ],
    "webhooks": [],
    "websockets": []
  },
  "types": {
    "type_:ServerMessageMessage": {
      "description": "These are all the messages that can be sent to your server before, after and during the call. Configure the messages you'd like to receive in `assistant.serverMessages`.\n\nThe server where the message is sent is determined by the following precedence order:\n\n1. `tool.server.url` (if configured, and only for \"tool-calls\" message)\n2. `assistant.serverUrl` (if configure)\n3. `phoneNumber.serverUrl` (if configured)\n4. `org.serverUrl` (if configured)",
      "name": "ServerMessageMessage",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "assistant-request",
            "additionalProperties": { "extends": ["type_:ServerMessageAssistantRequest"], "properties": [] }
          },
          {
            "discriminantValue": "conversation-update",
            "additionalProperties": { "extends": ["type_:ServerMessageConversationUpdate"], "properties": [] }
          },
          {
            "discriminantValue": "end-of-call-report",
            "additionalProperties": { "extends": ["type_:ServerMessageEndOfCallReport"], "properties": [] }
          },
          {
            "discriminantValue": "hang",
            "additionalProperties": { "extends": ["type_:ServerMessageHang"], "properties": [] }
          },
          {
            "discriminantValue": "model-output",
            "additionalProperties": { "extends": ["type_:ServerMessageModelOutput"], "properties": [] }
          },
          {
            "discriminantValue": "phone-call-control",
            "additionalProperties": { "extends": ["type_:ServerMessagePhoneCallControl"], "properties": [] }
          },
          {
            "discriminantValue": "speech-update",
            "additionalProperties": { "extends": ["type_:ServerMessageSpeechUpdate"], "properties": [] }
          },
          {
            "discriminantValue": "status-update",
            "additionalProperties": { "extends": ["type_:ServerMessageStatusUpdate"], "properties": [] }
          },
          {
            "discriminantValue": "tool-calls",
            "additionalProperties": { "extends": ["type_:ServerMessageToolCalls"], "properties": [] }
          },
          {
            "discriminantValue": "transfer-destination-request",
            "additionalProperties": {
              "extends": ["type_:ServerMessageTransferDestinationRequest"],
              "properties": []
            }
          },
          {
            "discriminantValue": "transfer-update",
            "additionalProperties": { "extends": ["type_:ServerMessageTransferUpdate"], "properties": [] }
          },
          {
            "discriminantValue": "transcript",
            "additionalProperties": { "extends": ["type_:ServerMessageTranscript"], "properties": [] }
          },
          {
            "discriminantValue": "user-interrupted",
            "additionalProperties": { "extends": ["type_:ServerMessageUserInterrupted"], "properties": [] }
          },
          {
            "discriminantValue": "language-changed",
            "additionalProperties": { "extends": ["type_:ServerMessageLanguageChanged"], "properties": [] }
          },
          {
            "discriminantValue": "voice-input",
            "additionalProperties": { "extends": ["type_:ServerMessageVoiceInput"], "properties": [] }
          },
          {
            "discriminantValue": "voice-request",
            "additionalProperties": { "extends": ["type_:ServerMessageVoiceRequest"], "properties": [] }
          }
        ]
      }
    },
    "type_:ClientMessageMessage": {
      "description": "These are all the messages that can be sent to the client-side SDKs during the call. Configure the messages you'd like to receive in `assistant.clientMessages`.",
      "name": "ClientMessageMessage",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "conversation-update",
            "additionalProperties": { "extends": ["type_:ClientMessageConversationUpdate"], "properties": [] }
          },
          {
            "discriminantValue": "hang",
            "additionalProperties": { "extends": ["type_:ClientMessageHang"], "properties": [] }
          },
          {
            "discriminantValue": "metadata",
            "additionalProperties": { "extends": ["type_:ClientMessageMetadata"], "properties": [] }
          },
          {
            "discriminantValue": "model-output",
            "additionalProperties": { "extends": ["type_:ClientMessageModelOutput"], "properties": [] }
          },
          {
            "discriminantValue": "speech-update",
            "additionalProperties": { "extends": ["type_:ClientMessageSpeechUpdate"], "properties": [] }
          },
          {
            "discriminantValue": "transcript",
            "additionalProperties": { "extends": ["type_:ClientMessageTranscript"], "properties": [] }
          },
          {
            "discriminantValue": "tool-calls",
            "additionalProperties": { "extends": ["type_:ClientMessageToolCalls"], "properties": [] }
          },
          {
            "discriminantValue": "tool-calls-result",
            "additionalProperties": { "extends": ["type_:ClientMessageToolCallsResult"], "properties": [] }
          },
          {
            "discriminantValue": "user-interrupted",
            "additionalProperties": { "extends": ["type_:ClientMessageUserInterrupted"], "properties": [] }
          },
          {
            "discriminantValue": "language-changed",
            "additionalProperties": { "extends": ["type_:ClientMessageLanguageChanged"], "properties": [] }
          },
          {
            "discriminantValue": "voice-input",
            "additionalProperties": { "extends": ["type_:ClientMessageVoiceInput"], "properties": [] }
          }
        ]
      }
    },
    "type_:TransferDestinationNumber": {
      "name": "TransferDestinationNumber",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.\n\nUse cases:\n\n- `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.\n- `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.\n\nIf `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\\+?[a-zA-Z0-9]+$/`).\n\n@default true (E164 check is enabled)",
            "key": "numberE164CheckEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the phone number to transfer the call to.",
            "key": "number",
            "valueType": { "type": "primitive", "value": { "type": "string", "minLength": 3, "maxLength": 3 } }
          },
          {
            "description": "This is the extension to dial after transferring the call to the `number`.",
            "key": "extension",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string", "minLength": 1, "maxLength": 1 } }
            }
          },
          {
            "description": "This is the caller ID to use when transferring the call to the `number`.\n\nUsage:\n\n- If not provided, the caller ID will be the number the call is coming from. Example, +14151111111 calls in to and the assistant transfers out to +16470000000. +16470000000 will see +14151111111 as the caller.\n- To change this behavior, provide a `callerId`.\n- Set to '{{customer.number}}' to always use the customer's number as the caller ID.\n- Set to '{{phoneNumber.number}}' to always use the phone number of the assistant as the caller ID.\n- Set to any E164 number to always use that number as the caller ID. This needs to be a number that is owned or verified by your Transport provider like Twilio.\n\nFor Twilio, you can read up more here: https://www.twilio.com/docs/voice/twiml/dial#callerid",
            "key": "callerId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the message to say before transferring the call to the destination.\n\nIf this is not provided and transfer tool messages is not provided, default is \"Transferring the call now\".\n\nIf set to \"\", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.",
            "key": "message",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the description of the destination, used by the AI to choose when and how to transfer the call.",
            "key": "description",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TransferDestinationSip": {
      "name": "TransferDestinationSip",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the SIP URI to transfer the call to.",
            "key": "sipUri",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the message to say before transferring the call to the destination.\n\nIf this is not provided and transfer tool messages is not provided, default is \"Transferring the call now\".\n\nIf set to \"\", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.",
            "key": "message",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the description of the destination, used by the AI to choose when and how to transfer the call.",
            "key": "description",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateByoPhoneNumberDtoFallbackDestination": {
      "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
      "name": "CreateByoPhoneNumberDtoFallbackDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateByoPhoneNumberDto": {
      "name": "CreateByoPhoneNumberDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
            "key": "fallbackDestination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateByoPhoneNumberDtoFallbackDestination" }
            }
          },
          {
            "description": "This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.\n\nUse cases:\n\n- `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.\n- `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.\n\nIf `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\\+?[a-zA-Z0-9]+$/`).\n\n@default true (E164 check is enabled)",
            "key": "numberE164CheckEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the number of the customer.",
            "key": "number",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string", "minLength": 3, "maxLength": 3 } }
            }
          },
          {
            "description": "This is the credential of your own SIP trunk or Carrier (type `byo-sip-trunk`) which can be used to make calls to this phone number.\n\nYou can add the SIP trunk or Carrier credential in the Provider Credentials page on the Dashboard to get the credentialId.",
            "key": "credentialId",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the name of the phone number. This is just for your own reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the squad that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "squadId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the server URL where messages will be sent for calls on this number. This includes the `assistant-request` message.\n\nYou can see the shape of the messages sent in `ServerMessage`.\n\nThis overrides the `org.serverUrl`. Order of precedence: tool.server.url > assistant.serverUrl > phoneNumber.serverUrl > org.serverUrl.",
            "key": "serverUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the secret Vapi will send with every message to your server. It's sent as a header called x-vapi-secret.\n\nSame precedence logic as serverUrl.",
            "key": "serverUrlSecret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateTwilioPhoneNumberDtoFallbackDestination": {
      "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
      "name": "CreateTwilioPhoneNumberDtoFallbackDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateTwilioPhoneNumberDto": {
      "name": "CreateTwilioPhoneNumberDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
            "key": "fallbackDestination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateTwilioPhoneNumberDtoFallbackDestination" }
            }
          },
          {
            "description": "These are the digits of the phone number you own on your Twilio.",
            "key": "number",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the Twilio Account SID for the phone number.",
            "key": "twilioAccountSid",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the Twilio Auth Token for the phone number.",
            "key": "twilioAuthToken",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the name of the phone number. This is just for your own reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the squad that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "squadId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the server URL where messages will be sent for calls on this number. This includes the `assistant-request` message.\n\nYou can see the shape of the messages sent in `ServerMessage`.\n\nThis overrides the `org.serverUrl`. Order of precedence: tool.server.url > assistant.serverUrl > phoneNumber.serverUrl > org.serverUrl.",
            "key": "serverUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the secret Vapi will send with every message to your server. It's sent as a header called x-vapi-secret.\n\nSame precedence logic as serverUrl.",
            "key": "serverUrlSecret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateVonagePhoneNumberDtoFallbackDestination": {
      "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
      "name": "CreateVonagePhoneNumberDtoFallbackDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateVonagePhoneNumberDto": {
      "name": "CreateVonagePhoneNumberDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
            "key": "fallbackDestination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateVonagePhoneNumberDtoFallbackDestination" }
            }
          },
          {
            "description": "These are the digits of the phone number you own on your Vonage.",
            "key": "number",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the credential that is used to make outgoing calls, and do operations like call transfer and hang up.",
            "key": "credentialId",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the name of the phone number. This is just for your own reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the squad that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "squadId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the server URL where messages will be sent for calls on this number. This includes the `assistant-request` message.\n\nYou can see the shape of the messages sent in `ServerMessage`.\n\nThis overrides the `org.serverUrl`. Order of precedence: tool.server.url > assistant.serverUrl > phoneNumber.serverUrl > org.serverUrl.",
            "key": "serverUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the secret Vapi will send with every message to your server. It's sent as a header called x-vapi-secret.\n\nSame precedence logic as serverUrl.",
            "key": "serverUrlSecret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateVapiPhoneNumberDtoFallbackDestination": {
      "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
      "name": "CreateVapiPhoneNumberDtoFallbackDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateVapiPhoneNumberDto": {
      "name": "CreateVapiPhoneNumberDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
            "key": "fallbackDestination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateVapiPhoneNumberDtoFallbackDestination" }
            }
          },
          {
            "description": "This is the SIP URI of the phone number. You can SIP INVITE this. The assistant attached to this number will answer.\n\nThis is case-insensitive.",
            "key": "sipUri",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the name of the phone number. This is just for your own reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the squad that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "squadId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the server URL where messages will be sent for calls on this number. This includes the `assistant-request` message.\n\nYou can see the shape of the messages sent in `ServerMessage`.\n\nThis overrides the `org.serverUrl`. Order of precedence: tool.server.url > assistant.serverUrl > phoneNumber.serverUrl > org.serverUrl.",
            "key": "serverUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the secret Vapi will send with every message to your server. It's sent as a header called x-vapi-secret.\n\nSame precedence logic as serverUrl.",
            "key": "serverUrlSecret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:UserMessage": {
      "name": "UserMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "The role of the user in the conversation.",
            "key": "role",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The message content from the user.",
            "key": "message",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The timestamp when the message was sent.",
            "key": "time",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The timestamp when the message ended.",
            "key": "endTime",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The number of seconds from the start of the conversation.",
            "key": "secondsFromStart",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The duration of the message in seconds.",
            "key": "duration",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:SystemMessage": {
      "name": "SystemMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "The role of the system in the conversation.",
            "key": "role",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The message content from the system.",
            "key": "message",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The timestamp when the message was sent.",
            "key": "time",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The number of seconds from the start of the conversation.",
            "key": "secondsFromStart",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:BotMessage": {
      "name": "BotMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "The role of the bot in the conversation.",
            "key": "role",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The message content from the bot.",
            "key": "message",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The timestamp when the message was sent.",
            "key": "time",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The timestamp when the message ended.",
            "key": "endTime",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The number of seconds from the start of the conversation.",
            "key": "secondsFromStart",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The source of the message.",
            "key": "source",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "The duration of the message in seconds.",
            "key": "duration",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolCallMessage": {
      "name": "ToolCallMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "The role of the tool call in the conversation.",
            "key": "role",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The list of tool calls made during the conversation.",
            "key": "toolCalls",
            "valueType": {
              "type": "list",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          },
          {
            "description": "The message content for the tool call.",
            "key": "message",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The timestamp when the message was sent.",
            "key": "time",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The number of seconds from the start of the conversation.",
            "key": "secondsFromStart",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolCallResultMessage": {
      "name": "ToolCallResultMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "The role of the tool call result in the conversation.",
            "key": "role",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The ID of the tool call.",
            "key": "toolCallId",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The name of the tool that returned the result.",
            "key": "name",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The result of the tool call in JSON format.",
            "key": "result",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The timestamp when the message was sent.",
            "key": "time",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "The number of seconds from the start of the conversation.",
            "key": "secondsFromStart",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:OpenAiMessageRole": {
      "name": "OpenAiMessageRole",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "assistant" },
          { "value": "function" },
          { "value": "user" },
          { "value": "system" },
          { "value": "tool" }
        ]
      }
    },
    "type_:OpenAiMessage": {
      "name": "OpenAiMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "key": "content",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          { "key": "role", "valueType": { "type": "id", "value": "type_:OpenAiMessageRole" } }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ArtifactMessagesItem": {
      "name": "ArtifactMessagesItem",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "id", "value": "type_:UserMessage" }, "displayName": "User Message" },
          { "type": { "type": "id", "value": "type_:SystemMessage" }, "displayName": "System Message" },
          { "type": { "type": "id", "value": "type_:BotMessage" }, "displayName": "Bot Message" },
          { "type": { "type": "id", "value": "type_:ToolCallMessage" }, "displayName": "Tool Call Message" },
          {
            "type": { "type": "id", "value": "type_:ToolCallResultMessage" },
            "displayName": "Tool Call Result Message"
          }
        ]
      }
    },
    "type_:Artifact": {
      "name": "Artifact",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the messages that were spoken during the call.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:ArtifactMessagesItem" } }
            }
          },
          {
            "description": "These are the messages that were spoken during the call, formatted for OpenAI.",
            "key": "messagesOpenAIFormatted",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "This is the recording url for the call. To enable, set `assistant.artifactPlan.recordingEnabled`.",
            "key": "recordingUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the stereo recording url for the call. To enable, set `assistant.artifactPlan.recordingEnabled`.",
            "key": "stereoRecordingUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is video recording url for the call. To enable, set `assistant.artifactPlan.videoRecordingEnabled`.",
            "key": "videoRecordingUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is video recording start delay in ms. To enable, set `assistant.artifactPlan.videoRecordingEnabled`. This can be used to align the playback of the recording with artifact.messages timestamps.",
            "key": "videoRecordingStartDelaySeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the transcript of the call. This is derived from `artifact.messages` but provided for convenience.",
            "key": "transcript",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:DeepgramTranscriber": {
      "name": "DeepgramTranscriber",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the Deepgram model that will be used. A list of models can be found here: https://developers.deepgram.com/docs/models-languages-overview",
            "key": "model",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:DeepgramTranscriberModel" }
            }
          },
          {
            "description": "This is the language that will be set for the transcription. The list of languages Deepgram supports can be found here: https://developers.deepgram.com/docs/models-languages-overview",
            "key": "language",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:DeepgramTranscriberLanguage" }
            }
          },
          {
            "description": "This will be use smart format option provided by Deepgram. It's default disabled because it can sometimes format numbers as times but it's getting better.",
            "key": "smartFormat",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This enables or disables language detection. If true, swaps transcribers to detected language automatically. Defaults to false.",
            "key": "languageDetectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These keywords are passed to the transcription model to help it pick up use-case specific words. Anything that may not be a common word, like your company name, should be added here.",
            "key": "keywords",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the timeout after which Deepgram will send transcription on user silence. You can read in-depth documentation here: https://developers.deepgram.com/docs/endpointing.\n\nHere are the most important bits:\n\n- Defaults to 10. This is recommended for most use cases to optimize for latency.\n- 10 can cause some missing transcriptions since because of the shorter context. This mostly happens for one-word utterances. For those uses cases, it's recommended to try 300. It will add a bit of latency but the quality and reliability of the experience will be better.\n- If neither 10 nor 300 work, contact support@vapi.ai and we'll find another solution.\n\n@default 10",
            "key": "endpointing",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 10, "maximum": 500 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:GladiaTranscriberModel": {
      "name": "GladiaTranscriberModel",
      "shape": { "type": "enum", "values": [{ "value": "fast" }, { "value": "accurate" }] }
    },
    "type_:GladiaTranscriberLanguageBehaviour": {
      "name": "GladiaTranscriberLanguageBehaviour",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "manual" },
          { "value": "automatic single language" },
          { "value": "automatic multiple languages" }
        ]
      }
    },
    "type_:GladiaTranscriberLanguage": {
      "description": "Defines the language to use for the transcription. Required when languageBehaviour is 'manual'.",
      "name": "GladiaTranscriberLanguage",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "af" },
          { "value": "sq" },
          { "value": "am" },
          { "value": "ar" },
          { "value": "hy" },
          { "value": "as" },
          { "value": "az" },
          { "value": "ba" },
          { "value": "eu" },
          { "value": "be" },
          { "value": "bn" },
          { "value": "bs" },
          { "value": "br" },
          { "value": "bg" },
          { "value": "ca" },
          { "value": "zh" },
          { "value": "hr" },
          { "value": "cs" },
          { "value": "da" },
          { "value": "nl" },
          { "value": "en" },
          { "value": "et" },
          { "value": "fo" },
          { "value": "fi" },
          { "value": "fr" },
          { "value": "gl" },
          { "value": "ka" },
          { "value": "de" },
          { "value": "el" },
          { "value": "gu" },
          { "value": "ht" },
          { "value": "ha" },
          { "value": "haw" },
          { "value": "he" },
          { "value": "hi" },
          { "value": "hu" },
          { "value": "is" },
          { "value": "id" },
          { "value": "it" },
          { "value": "ja" },
          { "value": "jp" },
          { "value": "jv" },
          { "value": "kn" },
          { "value": "kk" },
          { "value": "km" },
          { "value": "ko" },
          { "value": "lo" },
          { "value": "la" },
          { "value": "lv" },
          { "value": "ln" },
          { "value": "lt" },
          { "value": "lb" },
          { "value": "mk" },
          { "value": "mg" },
          { "value": "ms" },
          { "value": "ml" },
          { "value": "mt" },
          { "value": "mi" },
          { "value": "mr" },
          { "value": "mn" },
          { "value": "mymr" },
          { "value": "ne" },
          { "value": "no" },
          { "value": "nn" },
          { "value": "oc" },
          { "value": "ps" },
          { "value": "fa" },
          { "value": "pl" },
          { "value": "pt" },
          { "value": "pa" },
          { "value": "ro" },
          { "value": "ru" },
          { "value": "sa" },
          { "value": "sr" },
          { "value": "sn" },
          { "value": "sd" },
          { "value": "si" },
          { "value": "sk" },
          { "value": "sl" },
          { "value": "so" },
          { "value": "es" },
          { "value": "su" },
          { "value": "sw" },
          { "value": "sv" },
          { "value": "tl" },
          { "value": "tg" },
          { "value": "ta" },
          { "value": "tt" },
          { "value": "te" },
          { "value": "th" },
          { "value": "bo" },
          { "value": "tr" },
          { "value": "tk" },
          { "value": "uk" },
          { "value": "ur" },
          { "value": "uz" },
          { "value": "vi" },
          { "value": "cy" },
          { "value": "yi" },
          { "value": "yo" }
        ]
      }
    },
    "type_:GladiaTranscriber": {
      "name": "GladiaTranscriber",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "key": "model",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:GladiaTranscriberModel" }
            }
          },
          {
            "key": "languageBehaviour",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:GladiaTranscriberLanguageBehaviour" }
            }
          },
          {
            "description": "Defines the language to use for the transcription. Required when languageBehaviour is 'manual'.",
            "key": "language",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:GladiaTranscriberLanguage" }
            }
          },
          {
            "description": "Provides a custom vocabulary to the model to improve accuracy of transcribing context specific words, technical terms, names, etc. If empty, this argument is ignored.\n⚠️ Warning ⚠️: Please be aware that the transcription_hint field has a character limit of 600. If you provide a transcription_hint longer than 600 characters, it will be automatically truncated to meet this limit.",
            "key": "transcriptionHint",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "If prosody is true, you will get a transcription that can contain prosodies i.e. (laugh) (giggles) (malefic laugh) (toss) (music)… Default value is false.",
            "key": "prosody",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "If true, audio will be pre-processed to improve accuracy but latency will increase. Default value is false.",
            "key": "audioEnhancer",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TalkscriberTranscriberLanguage": {
      "description": "This is the language that will be set for the transcription. The list of languages Whisper supports can be found here: https://github.com/openai/whisper/blob/main/whisper/tokenizer.py",
      "name": "TalkscriberTranscriberLanguage",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "en" },
          { "value": "zh" },
          { "value": "de" },
          { "value": "es" },
          { "value": "ru" },
          { "value": "ko" },
          { "value": "fr" },
          { "value": "ja" },
          { "value": "pt" },
          { "value": "tr" },
          { "value": "pl" },
          { "value": "ca" },
          { "value": "nl" },
          { "value": "ar" },
          { "value": "sv" },
          { "value": "it" },
          { "value": "id" },
          { "value": "hi" },
          { "value": "fi" },
          { "value": "vi" },
          { "value": "he" },
          { "value": "uk" },
          { "value": "el" },
          { "value": "ms" },
          { "value": "cs" },
          { "value": "ro" },
          { "value": "da" },
          { "value": "hu" },
          { "value": "ta" },
          { "value": "no" },
          { "value": "th" },
          { "value": "ur" },
          { "value": "hr" },
          { "value": "bg" },
          { "value": "lt" },
          { "value": "la" },
          { "value": "mi" },
          { "value": "ml" },
          { "value": "cy" },
          { "value": "sk" },
          { "value": "te" },
          { "value": "fa" },
          { "value": "lv" },
          { "value": "bn" },
          { "value": "sr" },
          { "value": "az" },
          { "value": "sl" },
          { "value": "kn" },
          { "value": "et" },
          { "value": "mk" },
          { "value": "br" },
          { "value": "eu" },
          { "value": "is" },
          { "value": "hy" },
          { "value": "ne" },
          { "value": "mn" },
          { "value": "bs" },
          { "value": "kk" },
          { "value": "sq" },
          { "value": "sw" },
          { "value": "gl" },
          { "value": "mr" },
          { "value": "pa" },
          { "value": "si" },
          { "value": "km" },
          { "value": "sn" },
          { "value": "yo" },
          { "value": "so" },
          { "value": "af" },
          { "value": "oc" },
          { "value": "ka" },
          { "value": "be" },
          { "value": "tg" },
          { "value": "sd" },
          { "value": "gu" },
          { "value": "am" },
          { "value": "yi" },
          { "value": "lo" },
          { "value": "uz" },
          { "value": "fo" },
          { "value": "ht" },
          { "value": "ps" },
          { "value": "tk" },
          { "value": "nn" },
          { "value": "mt" },
          { "value": "sa" },
          { "value": "lb" },
          { "value": "my" },
          { "value": "bo" },
          { "value": "tl" },
          { "value": "mg" },
          { "value": "as" },
          { "value": "tt" },
          { "value": "haw" },
          { "value": "ln" },
          { "value": "ha" },
          { "value": "ba" },
          { "value": "jw" },
          { "value": "su" },
          { "value": "yue" }
        ]
      }
    },
    "type_:TalkscriberTranscriber": {
      "name": "TalkscriberTranscriber",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the model that will be used for the transcription.",
            "key": "model",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "literal", "value": { "type": "stringLiteral", "value": "whisper" } }
            }
          },
          {
            "description": "This is the language that will be set for the transcription. The list of languages Whisper supports can be found here: https://github.com/openai/whisper/blob/main/whisper/tokenizer.py",
            "key": "language",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:TalkscriberTranscriberLanguage" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ConditionOperator": {
      "description": "This is the operator you want to use to compare the parameter and value.",
      "name": "ConditionOperator",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "eq" },
          { "value": "neq" },
          { "value": "gt" },
          { "value": "gte" },
          { "value": "lt" },
          { "value": "lte" }
        ]
      }
    },
    "type_:Condition": {
      "name": "Condition",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the value you want to compare against the parameter.",
            "key": "value",
            "valueType": { "type": "primitive", "value": { "type": "string", "regex": "ALLOWED_REGEX" } }
          },
          {
            "description": "This is the operator you want to use to compare the parameter and value.",
            "key": "operator",
            "valueType": { "type": "id", "value": "type_:ConditionOperator" }
          },
          {
            "description": "This is the name of the parameter that you want to check.",
            "key": "param",
            "valueType": { "type": "primitive", "value": { "type": "string", "regex": "ALLOWED_REGEX" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolMessageStart": {
      "name": "ToolMessageStart",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the content that the assistant says when this message is triggered.",
            "key": "content",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:Condition" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolMessageCompleteRole": {
      "description": "This is optional and defaults to \"assistant\".\n\nWhen role=assistant, `content` is said out loud.\n\nWhen role=system, `content` is passed to the model in a system message. Example:\nsystem: default one\nassistant:\nuser:\nassistant:\nuser:\nassistant:\nuser:\nassistant: tool called\ntool: your server response\n<--- system prompt as hint\n---> model generates response which is spoken\nThis is useful when you want to provide a hint to the model about what to say next.",
      "name": "ToolMessageCompleteRole",
      "shape": { "type": "enum", "values": [{ "value": "assistant" }, { "value": "system" }] }
    },
    "type_:ToolMessageComplete": {
      "name": "ToolMessageComplete",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is optional and defaults to \"assistant\".\n\nWhen role=assistant, `content` is said out loud.\n\nWhen role=system, `content` is passed to the model in a system message. Example:\nsystem: default one\nassistant:\nuser:\nassistant:\nuser:\nassistant:\nuser:\nassistant: tool called\ntool: your server response\n<--- system prompt as hint\n---> model generates response which is spoken\nThis is useful when you want to provide a hint to the model about what to say next.",
            "key": "role",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ToolMessageCompleteRole" }
            }
          },
          {
            "description": "This is an optional boolean that if true, the call will end after the message is spoken. Default is false.\n\nThis is ignored if `role` is set to `system`.\n\n@default false",
            "key": "endCallAfterSpokenEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the content that the assistant says when this message is triggered.",
            "key": "content",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:Condition" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolMessageFailed": {
      "name": "ToolMessageFailed",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is an optional boolean that if true, the call will end after the message is spoken. Default is false.\n\n@default false",
            "key": "endCallAfterSpokenEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the content that the assistant says when this message is triggered.",
            "key": "content",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:Condition" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolMessageDelayed": {
      "name": "ToolMessageDelayed",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "The number of milliseconds to wait for the server response before saying this message.",
            "key": "timingMilliseconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 100, "maximum": 20000 } }
            }
          },
          {
            "description": "This is the content that the assistant says when this message is triggered.",
            "key": "content",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:Condition" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:JsonSchemaType": {
      "description": "This is the type of output you'd like.\n\n`string`, `number`, `integer`, `boolean` are the primitive types and should be obvious.\n\n`array` and `object` are more interesting and quite powerful. They allow you to define nested structures.\n\nFor `array`, you can define the schema of the items in the array using the `items` property.\n\nFor `object`, you can define the properties of the object using the `properties` property.",
      "name": "JsonSchemaType",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "string" },
          { "value": "number" },
          { "value": "integer" },
          { "value": "boolean" },
          { "value": "array" },
          { "value": "object" }
        ]
      }
    },
    "type_:JsonSchema": {
      "name": "JsonSchema",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the type of output you'd like.\n\n`string`, `number`, `integer`, `boolean` are the primitive types and should be obvious.\n\n`array` and `object` are more interesting and quite powerful. They allow you to define nested structures.\n\nFor `array`, you can define the schema of the items in the array using the `items` property.\n\nFor `object`, you can define the properties of the object using the `properties` property.",
            "key": "type",
            "valueType": { "type": "id", "value": "type_:JsonSchemaType" }
          },
          {
            "description": "This is required if the type is \"array\". This is the schema of the items in the array.\n\nThis is of type JsonSchema. However, Swagger doesn't support circular references.",
            "key": "items",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          },
          {
            "description": "This is required if the type is \"object\". This specifies the properties of the object.\n\nThis is a map of string to JsonSchema. However, Swagger doesn't support circular references.",
            "key": "properties",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          },
          {
            "description": "This is the description to help the model understand what it needs to output.",
            "key": "description",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a list of properties that are required.\n\nThis only makes sense if the type is \"object\".",
            "key": "required",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:OpenAiFunctionParameters": {
      "name": "OpenAiFunctionParameters",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This must be set to 'object'. It instructs the model to return a JSON object containing the function call properties.",
            "key": "type",
            "valueType": { "type": "literal", "value": { "type": "stringLiteral", "value": "object" } }
          },
          {
            "description": "This provides a description of the properties required by the function.\nJSON Schema can be used to specify expectations for each property.\nRefer to [this doc](https://ajv.js.org/json-schema.html#json-data-type) for a comprehensive guide on JSON Schema.",
            "key": "properties",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "id", "value": "type_:JsonSchema" }
            }
          },
          {
            "description": "This specifies the properties that are required by the function.",
            "key": "required",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:OpenAiFunction": {
      "name": "OpenAiFunction",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the the name of the function to be called.\n\nMust be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.",
            "key": "name",
            "valueType": {
              "type": "primitive",
              "value": { "type": "string", "regex": "/^[a-zA-Z0-9_-]{1,64}$/" }
            }
          },
          {
            "key": "description",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "These are the parameters the functions accepts, described as a JSON Schema object.\n\nSee the [OpenAI guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema) for documentation about the format.\n\nOmitting parameters defines a function with an empty parameter list.",
            "key": "parameters",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:OpenAiFunctionParameters" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:Server": {
      "name": "Server",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the timeout in seconds for the request to your server. Defaults to 20 seconds.\n\n@default 20",
            "key": "timeoutSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 60 } }
            }
          },
          {
            "description": "API endpoint to send requests to.",
            "key": "url",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the secret you can set that Vapi will send with every request to your server. Will be sent as a header called x-vapi-secret.\n\nSame precedence logic as server.",
            "key": "secret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateDtmfToolDtoMessagesItem": {
      "name": "CreateDtmfToolDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateDtmfToolDto": {
      "name": "CreateDtmfToolDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateDtmfToolDtoMessagesItem" }
              }
            }
          },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateEndCallToolDtoMessagesItem": {
      "name": "CreateEndCallToolDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateEndCallToolDto": {
      "name": "CreateEndCallToolDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateEndCallToolDtoMessagesItem" }
              }
            }
          },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateVoicemailToolDtoMessagesItem": {
      "name": "CreateVoicemailToolDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateVoicemailToolDto": {
      "name": "CreateVoicemailToolDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateVoicemailToolDtoMessagesItem" }
              }
            }
          },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateFunctionToolDtoMessagesItem": {
      "name": "CreateFunctionToolDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateFunctionToolDto": {
      "name": "CreateFunctionToolDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateFunctionToolDtoMessagesItem" }
              }
            }
          },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:GhlToolMetadata": {
      "name": "GhlToolMetadata",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "key": "workflowId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "key": "locationId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateGhlToolDtoMessagesItem": {
      "name": "CreateGhlToolDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateGhlToolDto": {
      "name": "CreateGhlToolDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateGhlToolDtoMessagesItem" }
              }
            }
          },
          { "key": "metadata", "valueType": { "type": "id", "value": "type_:GhlToolMetadata" } },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:MakeToolMetadata": {
      "name": "MakeToolMetadata",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "key": "scenarioId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "key": "triggerHookId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateMakeToolDtoMessagesItem": {
      "name": "CreateMakeToolDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateMakeToolDto": {
      "name": "CreateMakeToolDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateMakeToolDtoMessagesItem" }
              }
            }
          },
          { "key": "metadata", "valueType": { "type": "id", "value": "type_:MakeToolMetadata" } },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TransferDestinationAssistant": {
      "name": "TransferDestinationAssistant",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the mode to use for the transfer. Default is `rolling-history`.\n\n- `rolling-history`: This is the default mode. It keeps the entire conversation history and appends the new assistant's system message on transfer.\n\n  Example:\n\n  Pre-transfer:\n  system: assistant1 system message\n  assistant: assistant1 first message\n  user: hey, good morning\n  assistant: how can i help?\n  user: i need help with my account\n  assistant: (destination.message)\n\n  Post-transfer:\n  system: assistant1 system message\n  assistant: assistant1 first message\n  user: hey, good morning\n  assistant: how can i help?\n  user: i need help with my account\n  assistant: (destination.message)\n  system: assistant2 system message\n  assistant: assistant2 first message (or model generated if firstMessageMode is set to `assistant-speaks-first-with-model-generated-message`)\n\n- `swap-system-message-in-history`: This replaces the original system message with the new assistant's system message on transfer.\n\n  Example:\n\n  Pre-transfer:\n  system: assistant1 system message\n  assistant: assistant1 first message\n  user: hey, good morning\n  assistant: how can i help?\n  user: i need help with my account\n  assistant: (destination.message)\n\n  Post-transfer:\n  system: assistant2 system message\n  assistant: assistant1 first message\n  user: hey, good morning\n  assistant: how can i help?\n  user: i need help with my account\n  assistant: (destination.message)\n  assistant: assistant2 first message (or model generated if firstMessageMode is set to `assistant-speaks-first-with-model-generated-message`)",
            "key": "transferMode",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:TransferMode" } }
          },
          {
            "description": "This is the assistant to transfer the call to.",
            "key": "assistantName",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the message to say before transferring the call to the destination.\n\nIf this is not provided and transfer tool messages is not provided, default is \"Transferring the call now\".\n\nIf set to \"\", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.",
            "key": "message",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the description of the destination, used by the AI to choose when and how to transfer the call.",
            "key": "description",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TransferDestinationStep": {
      "name": "TransferDestinationStep",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the step to transfer to.",
            "key": "stepName",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the message to say before transferring the call to the destination.\n\nIf this is not provided and transfer tool messages is not provided, default is \"Transferring the call now\".\n\nIf set to \"\", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.",
            "key": "message",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the description of the destination, used by the AI to choose when and how to transfer the call.",
            "key": "description",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateTransferCallToolDtoMessagesItem": {
      "name": "CreateTransferCallToolDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateTransferCallToolDtoDestinationsItem": {
      "name": "CreateTransferCallToolDtoDestinationsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "assistant",
            "additionalProperties": { "extends": ["type_:TransferDestinationAssistant"], "properties": [] }
          },
          {
            "discriminantValue": "step",
            "additionalProperties": { "extends": ["type_:TransferDestinationStep"], "properties": [] }
          },
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateTransferCallToolDto": {
      "name": "CreateTransferCallToolDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateTransferCallToolDtoMessagesItem" }
              }
            }
          },
          {
            "description": "These are the destinations that the call can be transferred to. If no destinations are provided, server.url will be used to get the transfer destination once the tool is called.",
            "key": "destinations",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateTransferCallToolDtoDestinationsItem" }
              }
            }
          },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:KnowledgeBase": {
      "name": "KnowledgeBase",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "key": "provider",
            "valueType": { "type": "literal", "value": { "type": "stringLiteral", "value": "canonical" } }
          },
          {
            "key": "topK",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 10 } }
            }
          },
          {
            "key": "fileIds",
            "valueType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AnyscaleModelToolsItem": {
      "name": "AnyscaleModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:AnyscaleModel": {
      "name": "AnyscaleModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:AnyscaleModelToolsItem" }
              }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AnthropicModelToolsItem": {
      "name": "AnthropicModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:AnthropicModelModel": {
      "description": "This is the Anthropic/Claude models that will be used.",
      "name": "AnthropicModelModel",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "claude-3-opus-20240229" },
          { "value": "claude-3-sonnet-20240229" },
          { "value": "claude-3-haiku-20240307" },
          { "value": "claude-3-5-sonnet-20240620" }
        ]
      }
    },
    "type_:AnthropicModel": {
      "name": "AnthropicModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:AnthropicModelToolsItem" }
              }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the Anthropic/Claude models that will be used.",
            "key": "model",
            "valueType": { "type": "id", "value": "type_:AnthropicModelModel" }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CustomLlmModelToolsItem": {
      "name": "CustomLlmModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:CustomLlmModelMetadataSendMode": {
      "description": "This determines whether metadata is sent in requests to the custom provider.\n\n- `off` will not send any metadata. payload will look like `{ messages }`\n- `variable` will send `assistant.metadata` as a variable on the payload. payload will look like `{ messages, metadata }`\n- `destructured` will send `assistant.metadata` fields directly on the payload. payload will look like `{ messages, ...metadata }`\n\nFurther, `variable` and `destructured` will send `call`, `phoneNumber`, and `customer` objects in the payload.\n\nDefault is `variable`.",
      "name": "CustomLlmModelMetadataSendMode",
      "shape": {
        "type": "enum",
        "values": [{ "value": "off" }, { "value": "variable" }, { "value": "destructured" }]
      }
    },
    "type_:CustomLlmModel": {
      "name": "CustomLlmModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CustomLlmModelToolsItem" }
              }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This determines whether metadata is sent in requests to the custom provider.\n\n- `off` will not send any metadata. payload will look like `{ messages }`\n- `variable` will send `assistant.metadata` as a variable on the payload. payload will look like `{ messages, metadata }`\n- `destructured` will send `assistant.metadata` fields directly on the payload. payload will look like `{ messages, ...metadata }`\n\nFurther, `variable` and `destructured` will send `call`, `phoneNumber`, and `customer` objects in the payload.\n\nDefault is `variable`.",
            "key": "metadataSendMode",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CustomLlmModelMetadataSendMode" }
            }
          },
          {
            "description": "These is the URL we'll use for the OpenAI client's `baseURL`. Ex. https://openrouter.ai/api/v1",
            "key": "url",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:DeepInfraModelToolsItem": {
      "name": "DeepInfraModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:DeepInfraModel": {
      "name": "DeepInfraModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:DeepInfraModelToolsItem" }
              }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:GroqModelToolsItem": {
      "name": "GroqModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:GroqModelModel": {
      "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
      "name": "GroqModelModel",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "llama-3.1-405b-reasoning" },
          { "value": "llama-3.1-70b-versatile" },
          { "value": "llama-3.1-8b-instant" },
          { "value": "mixtral-8x7b-32768" },
          { "value": "llama3-8b-8192" },
          { "value": "llama3-70b-8192" },
          { "value": "llama3-groq-8b-8192-tool-use-preview" },
          { "value": "llama3-groq-70b-8192-tool-use-preview" },
          { "value": "gemma-7b-it" },
          { "value": "gemma2-9b-it" }
        ]
      }
    },
    "type_:GroqModel": {
      "name": "GroqModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:GroqModelToolsItem" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "id", "value": "type_:GroqModelModel" }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:OpenAiModelToolsItem": {
      "name": "OpenAiModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:OpenAiModelModel": {
      "description": "This is the OpenAI model that will be used.",
      "name": "OpenAiModelModel",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "gpt-4o-mini" },
          { "value": "gpt-4o-mini-2024-07-18" },
          { "value": "gpt-4o" },
          { "value": "gpt-4o-2024-05-13" },
          { "value": "gpt-4o-2024-08-06" },
          { "value": "gpt-4-turbo" },
          { "value": "gpt-4-turbo-2024-04-09" },
          { "value": "gpt-4-turbo-preview" },
          { "value": "gpt-4-0125-preview" },
          { "value": "gpt-4-1106-preview" },
          { "value": "gpt-4" },
          { "value": "gpt-4-0613" },
          { "value": "gpt-3.5-turbo" },
          { "value": "gpt-3.5-turbo-0125" },
          { "value": "gpt-3.5-turbo-1106" },
          { "value": "gpt-3.5-turbo-16k" },
          { "value": "gpt-3.5-turbo-0613" }
        ]
      }
    },
    "type_:OpenAiModelFallbackModelsItem": {
      "name": "OpenAiModelFallbackModelsItem",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "gpt-4o-mini" },
          { "value": "gpt-4o-mini-2024-07-18" },
          { "value": "gpt-4o" },
          { "value": "gpt-4o-2024-05-13" },
          { "value": "gpt-4o-2024-08-06" },
          { "value": "gpt-4-turbo" },
          { "value": "gpt-4-turbo-2024-04-09" },
          { "value": "gpt-4-turbo-preview" },
          { "value": "gpt-4-0125-preview" },
          { "value": "gpt-4-1106-preview" },
          { "value": "gpt-4" },
          { "value": "gpt-4-0613" },
          { "value": "gpt-3.5-turbo" },
          { "value": "gpt-3.5-turbo-0125" },
          { "value": "gpt-3.5-turbo-1106" },
          { "value": "gpt-3.5-turbo-16k" },
          { "value": "gpt-3.5-turbo-0613" }
        ]
      }
    },
    "type_:OpenAiModel": {
      "name": "OpenAiModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiModelToolsItem" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the OpenAI model that will be used.",
            "key": "model",
            "valueType": { "type": "id", "value": "type_:OpenAiModelModel" }
          },
          {
            "description": "These are the fallback models that will be used if the primary model fails. This shouldn't be specified unless you have a specific reason to do so. Vapi will automatically find the fastest fallbacks that make sense.",
            "key": "fallbackModels",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:OpenAiModelFallbackModelsItem" }
              }
            }
          },
          {
            "key": "semanticCachingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:OpenRouterModelToolsItem": {
      "name": "OpenRouterModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:OpenRouterModel": {
      "name": "OpenRouterModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:OpenRouterModelToolsItem" }
              }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:PerplexityAiModelToolsItem": {
      "name": "PerplexityAiModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:PerplexityAiModel": {
      "name": "PerplexityAiModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:PerplexityAiModelToolsItem" }
              }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TogetherAiModelToolsItem": {
      "name": "TogetherAiModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:TogetherAiModel": {
      "name": "TogetherAiModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:TogetherAiModelToolsItem" }
              }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ModelBasedCondition": {
      "name": "ModelBasedCondition",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the instruction which should output a boolean value when passed to a model.\n\nYou can reference any variable in the context of the current block execution (step):\n\n- \"{{output.your-property-name}}\" for current step's output\n- \"{{input.your-property-name}}\" for current step's input\n- \"{{your-step-name.output.your-property-name}}\" for another step's output (in the same workflow; read caveat #1)\n- \"{{your-step-name.input.your-property-name}}\" for another step's input (in the same workflow; read caveat #1)\n- \"{{your-block-name.output.your-property-name}}\" for another block's output (in the same workflow; read caveat #2)\n- \"{{your-block-name.input.your-property-name}}\" for another block's input (in the same workflow; read caveat #2)\n- \"{{workflow.input.your-property-name}}\" for the current workflow's input\n- \"{{global.your-property-name}}\" for the global context\n\nYou can also talk about the current step's output or input directly:\n\n- \"{{output.your-property-name}} is greater than 10\"\n- \"{{input.your-property-name}} is greater than 10\"\n\nExamples:\n\n- \"{{input.age}} is greater than 10\"\n- \"{{input.age}} is greater than {{input.age2}}\"\n- \"{{output.age}} is greater than 10\"\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.input/output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.input/output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow with steps.",
            "key": "instruction",
            "valueType": { "type": "primitive", "value": { "type": "string", "minLength": 1, "maxLength": 1 } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:RuleBasedConditionOperator": {
      "description": "This is the operator you want to use to compare the left side and right side.\n\nThe operation becomes `(leftSide) operator (rightSide)`.",
      "name": "RuleBasedConditionOperator",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "eq" },
          { "value": "neq" },
          { "value": "gt" },
          { "value": "gte" },
          { "value": "lt" },
          { "value": "lte" }
        ]
      }
    },
    "type_:RuleBasedCondition": {
      "name": "RuleBasedCondition",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the operator you want to use to compare the left side and right side.\n\nThe operation becomes `(leftSide) operator (rightSide)`.",
            "key": "operator",
            "valueType": { "type": "id", "value": "type_:RuleBasedConditionOperator" }
          },
          {
            "description": "This is the left side of the operation.\n\nYou can reference any variable in the context of the current block execution (step):\n\n- \"{{output.your-property-name}}\" for current step's output\n- \"{{input.your-property-name}}\" for current step's input\n- \"{{your-step-name.output.your-property-name}}\" for another step's output (in the same workflow; read caveat #1)\n- \"{{your-step-name.input.your-property-name}}\" for another step's input (in the same workflow; read caveat #1)\n- \"{{your-block-name.output.your-property-name}}\" for another block's output (in the same workflow; read caveat #2)\n- \"{{your-block-name.input.your-property-name}}\" for another block's input (in the same workflow; read caveat #2)\n- \"{{workflow.input.your-property-name}}\" for the current workflow's input\n- \"{{global.your-property-name}}\" for the global context\n\nOr, you can use a constant:\n\n- \"1\"\n- \"text\"\n- \"true\"\n- \"false\"\n\nOr, you can mix and match with string interpolation:\n\n- \"{{your-property-name}}-{{input.your-property-name-2}}-1\"\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.input/output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.input/output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow with steps.",
            "key": "leftSide",
            "valueType": { "type": "primitive", "value": { "type": "string", "regex": "ALLOWED_REGEX" } }
          },
          {
            "description": "This is the right side of the operation.\n\nYou can reference any variable in the context of the current block execution (step):\n\n- \"{{output.your-property-name}}\" for current step's output\n- \"{{input.your-property-name}}\" for current step's input\n- \"{{your-step-name.output.your-property-name}}\" for another step's output (in the same workflow; read caveat #1)\n- \"{{your-step-name.input.your-property-name}}\" for another step's input (in the same workflow; read caveat #1)\n- \"{{your-block-name.output.your-property-name}}\" for another block's output (in the same workflow; read caveat #2)\n- \"{{your-block-name.input.your-property-name}}\" for another block's input (in the same workflow; read caveat #2)\n- \"{{workflow.input.your-property-name}}\" for the current workflow's input\n- \"{{global.your-property-name}}\" for the global context\n\nOr, you can use a constant:\n\n- \"1\"\n- \"text\"\n- \"true\"\n- \"false\"\n\nOr, you can mix and match with string interpolation:\n\n- \"{{your-property-name}}-{{input.your-property-name-2}}-1\"\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.input/output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.input/output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow with steps.",
            "key": "rightSide",
            "valueType": { "type": "primitive", "value": { "type": "string", "regex": "ALLOWED_REGEX" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:BlockStartMessageConditionsItem": {
      "name": "BlockStartMessageConditionsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "model-based",
            "additionalProperties": { "extends": ["type_:ModelBasedCondition"], "properties": [] }
          },
          {
            "discriminantValue": "rule-based",
            "additionalProperties": { "extends": ["type_:RuleBasedCondition"], "properties": [] }
          }
        ]
      }
    },
    "type_:BlockStartMessage": {
      "name": "BlockStartMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is an optional array of conditions that must be met for this message to be triggered.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:BlockStartMessageConditionsItem" }
              }
            }
          },
          {
            "description": "This is the content that the assistant will say when this message is triggered.",
            "key": "content",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:BlockCompleteMessageConditionsItem": {
      "name": "BlockCompleteMessageConditionsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "model-based",
            "additionalProperties": { "extends": ["type_:ModelBasedCondition"], "properties": [] }
          },
          {
            "discriminantValue": "rule-based",
            "additionalProperties": { "extends": ["type_:RuleBasedCondition"], "properties": [] }
          }
        ]
      }
    },
    "type_:BlockCompleteMessage": {
      "name": "BlockCompleteMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is an optional array of conditions that must be met for this message to be triggered.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:BlockCompleteMessageConditionsItem" }
              }
            }
          },
          {
            "description": "This is the content that the assistant will say when this message is triggered.",
            "key": "content",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateConversationBlockDtoMessagesItem": {
      "name": "CreateConversationBlockDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "block-start",
            "additionalProperties": { "extends": ["type_:BlockStartMessage"], "properties": [] }
          },
          {
            "discriminantValue": "block-complete",
            "additionalProperties": { "extends": ["type_:BlockCompleteMessage"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateConversationBlockDto": {
      "name": "CreateConversationBlockDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the pre-configured messages that will be spoken to the user while the block is running.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateConversationBlockDtoMessagesItem" }
              }
            }
          },
          {
            "description": "This is the input schema for the block. This is the input the block needs to run. It's given to the block as `steps[0].input`\n\nThese are accessible as variables:\n\n- ({{input.propertyName}}) in context of the block execution (step)\n- ({{stepName.input.propertyName}}) in context of the workflow",
            "key": "inputSchema",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:JsonSchema" } }
          },
          {
            "description": "This is the output schema for the block. This is the output the block will return to the workflow (`{{stepName.output}}`).\n\nThese are accessible as variables:\n\n- ({{output.propertyName}}) in context of the block execution (step)\n- ({{stepName.output.propertyName}}) in context of the workflow (read caveat #1)\n- ({{blockName.output.propertyName}}) in context of the workflow (read caveat #2)\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow with steps.",
            "key": "outputSchema",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:JsonSchema" } }
          },
          {
            "description": "This is the instruction to the model.\n\nYou can reference any variable in the context of the current block execution (step):\n\n- \"{{input.your-property-name}}\" for the current step's input\n- \"{{your-step-name.output.your-property-name}}\" for another step's output (in the same workflow; read caveat #1)\n- \"{{your-step-name.input.your-property-name}}\" for another step's input (in the same workflow; read caveat #1)\n- \"{{your-block-name.output.your-property-name}}\" for another block's output (in the same workflow; read caveat #2)\n- \"{{your-block-name.input.your-property-name}}\" for another block's input (in the same workflow; read caveat #2)\n- \"{{workflow.input.your-property-name}}\" for the current workflow's input\n- \"{{global.your-property-name}}\" for the global context\n\nThis can be as simple or as complex as you want it to be.\n\n- \"say hello and ask the user about their day!\"\n- \"collect the user's first and last name\"\n- \"user is {{input.firstName}} {{input.lastName}}. their age is {{input.age}}. ask them about their salary and if they might be interested in buying a house. we offer {{input.offer}}\"\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.output/input.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.output/input.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow with steps.",
            "key": "instruction",
            "valueType": { "type": "primitive", "value": { "type": "string", "minLength": 1, "maxLength": 1 } }
          },
          {
            "description": "This is the name of the block. This is just for your reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateToolCallBlockDtoMessagesItem": {
      "name": "CreateToolCallBlockDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "block-start",
            "additionalProperties": { "extends": ["type_:BlockStartMessage"], "properties": [] }
          },
          {
            "discriminantValue": "block-complete",
            "additionalProperties": { "extends": ["type_:BlockCompleteMessage"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateToolCallBlockDtoTool": {
      "description": "This is the tool that the block will call. To use an existing tool, use `toolId`.",
      "name": "CreateToolCallBlockDtoTool",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateToolCallBlockDto": {
      "name": "CreateToolCallBlockDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the pre-configured messages that will be spoken to the user while the block is running.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateToolCallBlockDtoMessagesItem" }
              }
            }
          },
          {
            "description": "This is the input schema for the block. This is the input the block needs to run. It's given to the block as `steps[0].input`\n\nThese are accessible as variables:\n\n- ({{input.propertyName}}) in context of the block execution (step)\n- ({{stepName.input.propertyName}}) in context of the workflow",
            "key": "inputSchema",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:JsonSchema" } }
          },
          {
            "description": "This is the output schema for the block. This is the output the block will return to the workflow (`{{stepName.output}}`).\n\nThese are accessible as variables:\n\n- ({{output.propertyName}}) in context of the block execution (step)\n- ({{stepName.output.propertyName}}) in context of the workflow (read caveat #1)\n- ({{blockName.output.propertyName}}) in context of the workflow (read caveat #2)\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow with steps.",
            "key": "outputSchema",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:JsonSchema" } }
          },
          {
            "description": "This is the tool that the block will call. To use an existing tool, use `toolId`.",
            "key": "tool",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateToolCallBlockDtoTool" }
            }
          },
          {
            "description": "This is the id of the tool that the block will call. To use a transient tool, use `tool`.",
            "key": "toolId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the name of the block. This is just for your reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:HandoffStepBlock": {
      "description": "This is the block to use. To use an existing block, use `blockId`.",
      "name": "HandoffStepBlock",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "conversation",
            "additionalProperties": { "extends": ["type_:CreateConversationBlockDto"], "properties": [] }
          },
          {
            "discriminantValue": "tool-call",
            "additionalProperties": { "extends": ["type_:CreateToolCallBlockDto"], "properties": [] }
          },
          {
            "description": "This is the CreateWorkflowBlockDTO object but Swagger does not display nested schemas correctly.",
            "discriminantValue": "workflow",
            "additionalProperties": { "extends": ["type_:CreateWorkflowBlockDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:HandoffStep": {
      "name": "HandoffStep",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the block to use. To use an existing block, use `blockId`.",
            "key": "block",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:HandoffStepBlock" } }
          },
          {
            "description": "These are the destinations that the step can go to after it's done.",
            "key": "destinations",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:StepDestination" } }
            }
          },
          {
            "description": "This is the name of the step.",
            "key": "name",
            "valueType": { "type": "primitive", "value": { "type": "string", "minLength": 1, "maxLength": 1 } }
          },
          {
            "description": "This is the id of the block to use. To use a transient block, use `block`.",
            "key": "blockId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the input to the block. You can use any key-value map as input to the block.\n\nExample:\n{\n\"name\": \"John Doe\",\n\"age\": 20\n}\n\nYou can reference any variable in the context of the current block:\n\n- \"{{your-step-name.output.your-property-name}}\" for another step's output (in the same workflow; read caveat #1)\n- \"{{your-step-name.input.your-property-name}}\" for another step's input (in the same workflow; read caveat #1)\n- \"{{your-block-name.output.your-property-name}}\" for another block's output (in the same workflow; read caveat #2)\n- \"{{your-block-name.input.your-property-name}}\" for another block's input (in the same workflow; read caveat #2)\n- \"{{workflow.input.your-property-name}}\" for the current workflow's input\n- \"{{global.your-property-name}}\" for the global context\n\nExample:\n{\n\"name\": \"{{my-tool-call-step.output.name}}\",\n\"age\": \"{{my-tool-call-step.input.age}}\",\n\"date\": \"{{workflow.input.date}}\"\n}\n\nYou can dynamically change the key name.\n\nExample:\n{\n\"{{my-tool-call-step.output.key-name-for-name}}\": \"{{name}}\",\n\"{{my-tool-call-step.input.key-name-for-age}}\": \"{{age}}\",\n\"{{workflow.input.key-name-for-date}}\": \"{{date}}\"\n}\n\nYou can represent the value as a string, number, boolean, array, or object.\n\nExample:\n{\n\"name\": \"john\",\n\"age\": 20,\n\"date\": \"2021-01-01\",\n\"metadata\": {\n\"unique-key\": \"{{my-tool-call-step.output.unique-key}}\"\n},\n\"array\": [\"A\", \"B\", \"C\"],\n}\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.input/output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.input/output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow.",
            "key": "input",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateWorkflowBlockDtoMessagesItem": {
      "name": "CreateWorkflowBlockDtoMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "block-start",
            "additionalProperties": { "extends": ["type_:BlockStartMessage"], "properties": [] }
          },
          {
            "discriminantValue": "block-complete",
            "additionalProperties": { "extends": ["type_:BlockCompleteMessage"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateWorkflowBlockDtoStepsItem": {
      "name": "CreateWorkflowBlockDtoStepsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "handoff",
            "additionalProperties": { "extends": ["type_:HandoffStep"], "properties": [] }
          },
          {
            "discriminantValue": "callback",
            "additionalProperties": { "extends": ["type_:CallbackStep"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateWorkflowBlockDto": {
      "name": "CreateWorkflowBlockDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the pre-configured messages that will be spoken to the user while the block is running.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateWorkflowBlockDtoMessagesItem" }
              }
            }
          },
          {
            "description": "This is the input schema for the block. This is the input the block needs to run. It's given to the block as `steps[0].input`\n\nThese are accessible as variables:\n\n- ({{input.propertyName}}) in context of the block execution (step)\n- ({{stepName.input.propertyName}}) in context of the workflow",
            "key": "inputSchema",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:JsonSchema" } }
          },
          {
            "description": "This is the output schema for the block. This is the output the block will return to the workflow (`{{stepName.output}}`).\n\nThese are accessible as variables:\n\n- ({{output.propertyName}}) in context of the block execution (step)\n- ({{stepName.output.propertyName}}) in context of the workflow (read caveat #1)\n- ({{blockName.output.propertyName}}) in context of the workflow (read caveat #2)\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow with steps.",
            "key": "outputSchema",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:JsonSchema" } }
          },
          {
            "description": "These are the steps in the workflow.",
            "key": "steps",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateWorkflowBlockDtoStepsItem" }
              }
            }
          },
          {
            "description": "This is the name of the block. This is just for your reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AssignmentMutationConditionsItem": {
      "name": "AssignmentMutationConditionsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "model-based",
            "additionalProperties": { "extends": ["type_:ModelBasedCondition"], "properties": [] }
          },
          {
            "discriminantValue": "rule-based",
            "additionalProperties": { "extends": ["type_:RuleBasedCondition"], "properties": [] }
          }
        ]
      }
    },
    "type_:AssignmentMutation": {
      "name": "AssignmentMutation",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is an optional array of conditions that must be met for this mutation to be triggered.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:AssignmentMutationConditionsItem" }
              }
            }
          },
          {
            "description": "This mutation assigns a new value to an existing or new variable.",
            "key": "type",
            "valueType": { "type": "literal", "value": { "type": "stringLiteral", "value": "assignment" } }
          },
          {
            "description": "This is the variable to assign a new value to.\n\nYou can reference any variable in the context of the current block execution (step):\n\n- \"output.your-property-name\" for current step's output\n- \"your-step-name.output.your-property-name\" for another step's output (in the same workflow; read caveat #1)\n- \"your-block-name.output.your-property-name\" for another block's output (in the same workflow; read caveat #2)\n- \"global.your-property-name\" for the global context\n\nThis needs to be the key path of the variable. If you use {{}}, it'll dereference that to the value of the variable before assignment. This can be useful if the path is dynamic. Example:\n\n- \"global.{{my-tool-call-step.output.my-key-name}}\"\n\nYou can also string interpolate multiple variables to get the key name:\n\n- \"global.{{my-tool-call-step.output.my-key-name-suffix}}-{{my-tool-call-step.output.my-key-name}}\"\n\nThe path to the new variable is created if it doesn't exist. Example:\n\n- \"global.this-does-not-exist.neither-does-this\" will create `this-does-not-exist` object with `neither-does-this` as a key\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow.",
            "key": "variable",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "The value to assign to the variable.\n\nYou can reference any variable in the context of the current block execution (step):\n\n- \"{{output.your-property-name}}\" for current step's output\n- \"{{your-step-name.output.your-property-name}}\" for another step's output (in the same workflow; read caveat #1)\n- \"{{your-block-name.output.your-property-name}}\" for another block's output (in the same workflow; read caveat #2)\n- \"{{global.your-property-name}}\" for the global context\n\nOr, you can use a constant:\n\n- \"1\"\n- \"text\"\n- \"true\"\n- \"false\"\n\nOr, you can mix and match with string interpolation:\n\n- \"{{your-property-name}}-{{input.your-property-name-2}}-1\"\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow.",
            "key": "value",
            "valueType": { "type": "primitive", "value": { "type": "string", "regex": "ALLOWED_REGEX" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CallbackStepBlock": {
      "description": "This is the block to use. To use an existing block, use `blockId`.",
      "name": "CallbackStepBlock",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "conversation",
            "additionalProperties": { "extends": ["type_:CreateConversationBlockDto"], "properties": [] }
          },
          {
            "discriminantValue": "tool-call",
            "additionalProperties": { "extends": ["type_:CreateToolCallBlockDto"], "properties": [] }
          },
          {
            "description": "This is the CreateWorkflowBlockDTO object but Swagger does not display nested schemas correctly.",
            "discriminantValue": "workflow",
            "additionalProperties": { "extends": ["type_:CreateWorkflowBlockDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:CallbackStep": {
      "name": "CallbackStep",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the block to use. To use an existing block, use `blockId`.",
            "key": "block",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CallbackStepBlock" } }
          },
          {
            "description": "This is the mutations to apply to the context after the step is done.",
            "key": "mutations",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:AssignmentMutation" } }
            }
          },
          {
            "description": "This is the name of the step.",
            "key": "name",
            "valueType": { "type": "primitive", "value": { "type": "string", "minLength": 1, "maxLength": 1 } }
          },
          {
            "description": "This is the id of the block to use. To use a transient block, use `block`.",
            "key": "blockId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the input to the block. You can use any key-value map as input to the block.\n\nExample:\n{\n\"name\": \"John Doe\",\n\"age\": 20\n}\n\nYou can reference any variable in the context of the current block:\n\n- \"{{your-step-name.output.your-property-name}}\" for another step's output (in the same workflow; read caveat #1)\n- \"{{your-step-name.input.your-property-name}}\" for another step's input (in the same workflow; read caveat #1)\n- \"{{your-block-name.output.your-property-name}}\" for another block's output (in the same workflow; read caveat #2)\n- \"{{your-block-name.input.your-property-name}}\" for another block's input (in the same workflow; read caveat #2)\n- \"{{workflow.input.your-property-name}}\" for the current workflow's input\n- \"{{global.your-property-name}}\" for the global context\n\nExample:\n{\n\"name\": \"{{my-tool-call-step.output.name}}\",\n\"age\": \"{{my-tool-call-step.input.age}}\",\n\"date\": \"{{workflow.input.date}}\"\n}\n\nYou can dynamically change the key name.\n\nExample:\n{\n\"{{my-tool-call-step.output.key-name-for-name}}\": \"{{name}}\",\n\"{{my-tool-call-step.input.key-name-for-age}}\": \"{{age}}\",\n\"{{workflow.input.key-name-for-date}}\": \"{{date}}\"\n}\n\nYou can represent the value as a string, number, boolean, array, or object.\n\nExample:\n{\n\"name\": \"john\",\n\"age\": 20,\n\"date\": \"2021-01-01\",\n\"metadata\": {\n\"unique-key\": \"{{my-tool-call-step.output.unique-key}}\"\n},\n\"array\": [\"A\", \"B\", \"C\"],\n}\n\nCaveats:\n\n1. a workflow can execute a step multiple times. example, if a loop is used in the graph. {{stepName.input/output.propertyName}} will reference the latest usage of the step.\n2. a workflow can execute a block multiple times. example, if a step is called multiple times or if a block is used in multiple steps. {{blockName.input/output.propertyName}} will reference the latest usage of the block. this liquid variable is just provided for convenience when creating blocks outside of a workflow.",
            "key": "input",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:StepDestinationConditionsItem": {
      "name": "StepDestinationConditionsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "model-based",
            "additionalProperties": { "extends": ["type_:ModelBasedCondition"], "properties": [] }
          },
          {
            "discriminantValue": "rule-based",
            "additionalProperties": { "extends": ["type_:RuleBasedCondition"], "properties": [] }
          }
        ]
      }
    },
    "type_:StepDestination": {
      "name": "StepDestination",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "key": "type",
            "valueType": { "type": "literal", "value": { "type": "stringLiteral", "value": "step" } }
          },
          {
            "description": "This is an optional array of conditions that must be met for this destination to be triggered. If empty, this is the default destination that the step transfers to.",
            "key": "conditions",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:StepDestinationConditionsItem" }
              }
            }
          },
          {
            "key": "stepName",
            "valueType": { "type": "primitive", "value": { "type": "string", "minLength": 1, "maxLength": 1 } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:VapiModelToolsItem": {
      "name": "VapiModelToolsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "dtmf",
            "additionalProperties": { "extends": ["type_:CreateDtmfToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "endCall",
            "additionalProperties": { "extends": ["type_:CreateEndCallToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "voicemail",
            "additionalProperties": { "extends": ["type_:CreateVoicemailToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:CreateFunctionToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:CreateGhlToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:CreateMakeToolDto"], "properties": [] }
          },
          {
            "discriminantValue": "transferCall",
            "additionalProperties": { "extends": ["type_:CreateTransferCallToolDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:VapiModelStepsItem": {
      "name": "VapiModelStepsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "handoff",
            "additionalProperties": { "extends": ["type_:HandoffStep"], "properties": [] }
          },
          {
            "discriminantValue": "callback",
            "additionalProperties": { "extends": ["type_:CallbackStep"], "properties": [] }
          }
        ]
      }
    },
    "type_:VapiModel": {
      "name": "VapiModel",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the starting state for the conversation.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "tools",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:VapiModelToolsItem" } }
            }
          },
          {
            "description": "These are the tools that the assistant can use during the call. To use transient tools, use `tools`.\n\nBoth `tools` and `toolIds` can be used together.",
            "key": "toolIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "key": "steps",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:VapiModelStepsItem" } }
            }
          },
          {
            "description": "This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b",
            "key": "model",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 2 } }
            }
          },
          {
            "description": "These are the options for the knowledge base.",
            "key": "knowledgeBase",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:KnowledgeBase" } }
          },
          {
            "description": "This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.",
            "key": "maxTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 50, "maximum": 10000 } }
            }
          },
          {
            "description": "This determines whether we detect user's emotion while they speak and send it as an additional info to model.\n\nDefault `false` because the model is usually are good at understanding the user's emotion from text.\n\n@default false",
            "key": "emotionRecognitionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.\n\nDefault is 0.\n\n@default 0",
            "key": "numFastTurns",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ExactReplacement": {
      "name": "ExactReplacement",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the key to replace.",
            "key": "key",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the value that will replace the match.",
            "key": "value",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:RegexOptionType": {
      "description": "This is the type of the regex option. Options are:\n\n- `ignore-case`: Ignores the case of the text being matched.\n- `whole-word`: Matches whole words only.\n- `multi-line`: Matches across multiple lines.",
      "name": "RegexOptionType",
      "shape": {
        "type": "enum",
        "values": [{ "value": "ignore-case" }, { "value": "whole-word" }, { "value": "multi-line" }]
      }
    },
    "type_:RegexOption": {
      "name": "RegexOption",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the type of the regex option. Options are:\n\n- `ignore-case`: Ignores the case of the text being matched.\n- `whole-word`: Matches whole words only.\n- `multi-line`: Matches across multiple lines.",
            "key": "type",
            "valueType": { "type": "id", "value": "type_:RegexOptionType" }
          },
          {
            "description": "This is whether to enable the option.\n\n@default false",
            "key": "enabled",
            "valueType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:RegexReplacement": {
      "name": "RegexReplacement",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the regex pattern to replace.",
            "key": "regex",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "These are the options for the regex replacement. Default all options are disabled.\n\n@default []",
            "key": "options",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:RegexOption" } }
            }
          },
          {
            "description": "This is the value that will replace the match.",
            "key": "value",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:FormatPlanReplacementsItem": {
      "name": "FormatPlanReplacementsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "exact",
            "additionalProperties": { "extends": ["type_:ExactReplacement"], "properties": [] }
          },
          {
            "discriminantValue": "regex",
            "additionalProperties": { "extends": ["type_:RegexReplacement"], "properties": [] }
          }
        ]
      }
    },
    "type_:FormatPlan": {
      "name": "FormatPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether the chunk is formatted before being sent to the voice provider. This helps with enunciation. This includes phone numbers, emails and addresses. Default `true`.\n\nUsage:\n\n- To rely on the voice provider's formatting logic, set this to `false`.\n- To use ElevenLabs's `enableSsmlParsing` feature, set this to `false`.\n\nIf `voice.chunkPlan.enabled` is `false`, this is automatically `false` since there's no chunk to format.\n\n@default true",
            "key": "enabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the cutoff after which a number is converted to individual digits instead of being spoken as words.\n\nExample:\n\n- If cutoff 2025, \"12345\" is converted to \"1 2 3 4 5\" while \"1200\" is converted to \"twelve hundred\".\n\nUsage:\n\n- If your use case doesn't involve IDs like zip codes, set this to a high value.\n- If your use case involves IDs that are shorter than 5 digits, set this to a lower value.\n\n@default 2025",
            "key": "numberToDigitsCutoff",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0 } }
            }
          },
          {
            "description": "These are the custom replacements you can make to the chunk before it is sent to the voice provider.\n\nUsage:\n\n- To replace a specific word or phrase with a different word or phrase, use the `ExactReplacement` type. Eg. `{ type: 'exact', key: 'hello', value: 'hi' }`\n- To replace a word or phrase that matches a pattern, use the `RegexReplacement` type. Eg. `{ type: 'regex', regex: '\\\\b[a-zA-Z]{5}\\\\b', value: 'hi' }`\n\n@default []",
            "key": "replacements",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:FormatPlanReplacementsItem" }
              }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ChunkPlan": {
      "name": "ChunkPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether the model output is chunked before being sent to the voice provider. Default `true`.\n\nUsage:\n\n- To rely on the voice provider's audio generation logic, set this to `false`.\n- If seeing issues with quality, set this to `true`.\n\nIf disabled, Vapi-provided audio control tokens like <flush /> will not work.\n\n@default true",
            "key": "enabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the minimum number of characters in a chunk.\n\nUsage:\n\n- To increase quality, set this to a higher value.\n- To decrease latency, set this to a lower value.\n\n@default 30",
            "key": "minCharacters",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 80 } }
            }
          },
          {
            "description": "These are the punctuations that are considered valid boundaries for a chunk to be created.\n\nUsage:\n\n- To increase quality, constrain to fewer boundaries.\n- To decrease latency, enable all.\n\nDefault is automatically set to balance the trade-off between quality and latency based on the provider.",
            "key": "punctuationBoundaries",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:PunctuationBoundary" } }
            }
          },
          {
            "description": "This is the plan for formatting the chunk before it is sent to the voice provider.",
            "key": "formatPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:FormatPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AzureVoiceId": {
      "description": "This is the provider-specific ID that will be used.",
      "name": "AzureVoiceId",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "andrew" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "brian" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "emma" } } },
          { "type": { "type": "primitive", "value": { "type": "string" } } }
        ]
      }
    },
    "type_:AzureVoice": {
      "name": "AzureVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:AzureVoiceId" }
          },
          {
            "description": "This is the speed multiplier that will be used.",
            "key": "speed",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0.5, "maximum": 2 } }
            }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CartesiaVoiceModel": {
      "description": "This is the model that will be used. This is optional and will default to the correct model for the voiceId.",
      "name": "CartesiaVoiceModel",
      "shape": { "type": "enum", "values": [{ "value": "sonic-english" }, { "value": "sonic-multilingual" }] }
    },
    "type_:CartesiaVoiceLanguage": {
      "description": "This is the language that will be used. This is optional and will default to the correct language for the voiceId.",
      "name": "CartesiaVoiceLanguage",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "de" },
          { "value": "en" },
          { "value": "es" },
          { "value": "fr" },
          { "value": "ja" },
          { "value": "pt" },
          { "value": "zh" }
        ]
      }
    },
    "type_:CartesiaVoice": {
      "name": "CartesiaVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the model that will be used. This is optional and will default to the correct model for the voiceId.",
            "key": "model",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CartesiaVoiceModel" } }
          },
          {
            "description": "This is the language that will be used. This is optional and will default to the correct language for the voiceId.",
            "key": "language",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CartesiaVoiceLanguage" }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:DeepgramVoiceId": {
      "description": "This is the provider-specific ID that will be used.",
      "name": "DeepgramVoiceId",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "asteria" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "luna" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "stella" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "athena" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "hera" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "orion" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "arcas" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "perseus" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "angus" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "orpheus" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "helios" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "zeus" } } },
          { "type": { "type": "primitive", "value": { "type": "string" } } }
        ]
      }
    },
    "type_:DeepgramVoice": {
      "name": "DeepgramVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:DeepgramVoiceId" }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ElevenLabsVoiceId": {
      "description": "This is the provider-specific ID that will be used. Ensure the Voice is present in your 11Labs Voice Library.",
      "name": "ElevenLabsVoiceId",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "burt" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "marissa" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "andrea" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "sarah" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "phillip" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "steve" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "joseph" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "myra" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "paula" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "ryan" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "drew" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "paul" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "mrb" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "matilda" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "mark" } } },
          { "type": { "type": "primitive", "value": { "type": "string" } } }
        ]
      }
    },
    "type_:ElevenLabsVoiceModel": {
      "description": "This is the model that will be used. Defaults to 'eleven_turbo_v2' if not specified.",
      "name": "ElevenLabsVoiceModel",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "eleven_multilingual_v2" },
          { "value": "eleven_turbo_v2" },
          { "value": "eleven_turbo_v2_5" },
          { "value": "eleven_monolingual_v1" }
        ]
      }
    },
    "type_:ElevenLabsVoice": {
      "name": "ElevenLabsVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used. Ensure the Voice is present in your 11Labs Voice Library.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:ElevenLabsVoiceId" }
          },
          {
            "description": "Defines the stability for voice settings.",
            "key": "stability",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 1 } }
            }
          },
          {
            "description": "Defines the similarity boost for voice settings.",
            "key": "similarityBoost",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 1 } }
            }
          },
          {
            "description": "Defines the style for voice settings.",
            "key": "style",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 1 } }
            }
          },
          {
            "description": "Defines the use speaker boost for voice settings.",
            "key": "useSpeakerBoost",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "Defines the optimize streaming latency for voice settings. Defaults to 3.",
            "key": "optimizeStreamingLatency",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 4 } }
            }
          },
          {
            "description": "This enables the use of https://elevenlabs.io/docs/speech-synthesis/prompting#pronunciation. Defaults to false to save latency.\n\n@default false",
            "key": "enableSsmlParsing",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the model that will be used. Defaults to 'eleven_turbo_v2' if not specified.",
            "key": "model",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ElevenLabsVoiceModel" }
            }
          },
          {
            "description": "This is the language (ISO 639-1) that is enforced for the model. Currently only Turbo v2.5 supports language enforcement. For other models, an error will be returned if language code is provided.",
            "key": "language",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:LMNTVoiceId": {
      "description": "This is the provider-specific ID that will be used.",
      "name": "LMNTVoiceId",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "lily" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "daniel" } } },
          { "type": { "type": "primitive", "value": { "type": "string" } } }
        ]
      }
    },
    "type_:LmntVoice": {
      "name": "LmntVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:LMNTVoiceId" }
          },
          {
            "description": "This is the speed multiplier that will be used.",
            "key": "speed",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0.25, "maximum": 2 } }
            }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:NeetsVoiceId": {
      "description": "This is the provider-specific ID that will be used.",
      "name": "NeetsVoiceId",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "vits" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "vits" } } },
          { "type": { "type": "primitive", "value": { "type": "string" } } }
        ]
      }
    },
    "type_:NeetsVoice": {
      "name": "NeetsVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:NeetsVoiceId" }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:OpenAIVoiceId": {
      "description": "This is the provider-specific ID that will be used.",
      "name": "OpenAIVoiceId",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "alloy" },
          { "value": "echo" },
          { "value": "fable" },
          { "value": "onyx" },
          { "value": "nova" },
          { "value": "shimmer" }
        ]
      }
    },
    "type_:OpenAiVoice": {
      "name": "OpenAiVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:OpenAIVoiceId" }
          },
          {
            "description": "This is the speed multiplier that will be used.",
            "key": "speed",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0.25, "maximum": 4 } }
            }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:PlayHtVoiceVoiceId": {
      "description": "This is the provider-specific ID that will be used.",
      "name": "PlayHtVoiceVoiceId",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "jennifer" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "melissa" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "will" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "chris" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "matt" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "jack" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "ruby" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "davis" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "donna" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "michael" } } },
          { "type": { "type": "primitive", "value": { "type": "string" } } }
        ]
      }
    },
    "type_:PlayHtVoiceEmotion": {
      "description": "An emotion to be applied to the speech.",
      "name": "PlayHtVoiceEmotion",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "female_happy" },
          { "value": "female_sad" },
          { "value": "female_angry" },
          { "value": "female_fearful" },
          { "value": "female_disgust" },
          { "value": "female_surprised" },
          { "value": "male_happy" },
          { "value": "male_sad" },
          { "value": "male_angry" },
          { "value": "male_fearful" },
          { "value": "male_disgust" },
          { "value": "male_surprised" }
        ]
      }
    },
    "type_:PlayHtVoice": {
      "name": "PlayHtVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:PlayHtVoiceVoiceId" }
          },
          {
            "description": "This is the speed multiplier that will be used.",
            "key": "speed",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0.1, "maximum": 5 } }
            }
          },
          {
            "description": "A floating point number between 0, exclusive, and 2, inclusive. If equal to null or not provided, the model's default temperature will be used. The temperature parameter controls variance. Lower temperatures result in more predictable results, higher temperatures allow each run to vary more, so the voice may sound less like the baseline voice.",
            "key": "temperature",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0.1, "maximum": 2 } }
            }
          },
          {
            "description": "An emotion to be applied to the speech.",
            "key": "emotion",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:PlayHtVoiceEmotion" } }
          },
          {
            "description": "A number between 1 and 6. Use lower numbers to reduce how unique your chosen voice will be compared to other voices.",
            "key": "voiceGuidance",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 6 } }
            }
          },
          {
            "description": "A number between 1 and 30. Use lower numbers to to reduce how strong your chosen emotion will be. Higher numbers will create a very emotional performance.",
            "key": "styleGuidance",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 30 } }
            }
          },
          {
            "description": "A number between 1 and 2. This number influences how closely the generated speech adheres to the input text. Use lower values to create more fluid speech, but with a higher chance of deviating from the input text. Higher numbers will make the generated speech more accurate to the input text, ensuring that the words spoken align closely with the provided text.",
            "key": "textGuidance",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 2 } }
            }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:RimeAIVoiceId": {
      "description": "This is the provider-specific ID that will be used.",
      "name": "RimeAIVoiceId",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "marsh" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "bayou" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "creek" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "brook" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "flower" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "spore" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "glacier" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "gulch" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "alpine" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "cove" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "lagoon" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "tundra" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "steppe" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "mesa" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "grove" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "rainforest" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "moraine" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "wildflower" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "peak" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "boulder" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "abbie" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "allison" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "ally" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "alona" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "amber" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "ana" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "antoine" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "armon" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "brenda" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "brittany" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "carol" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "colin" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "courtney" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "elena" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "elliot" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "eva" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "geoff" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "gerald" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "hank" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "helen" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "hera" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "jen" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "joe" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "joy" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "juan" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "kendra" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "kendrick" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "kenneth" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "kevin" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "kris" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "linda" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "madison" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "marge" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "marina" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "marissa" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "marta" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "maya" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "nicholas" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "nyles" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "phil" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "reba" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "rex" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "rick" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "ritu" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "rob" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "rodney" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "rohan" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "rosco" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "samantha" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "sandy" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "selena" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "seth" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "sharon" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "stan" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "tamra" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "tanya" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "tibur" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "tj" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "tyler" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "viv" } } },
          { "type": { "type": "literal", "value": { "type": "stringLiteral", "value": "yadira" } } },
          { "type": { "type": "primitive", "value": { "type": "string" } } }
        ]
      }
    },
    "type_:RimeAiVoiceModel": {
      "description": "This is the model that will be used. Defaults to 'v1' when not specified.",
      "name": "RimeAiVoiceModel",
      "shape": { "type": "enum", "values": [{ "value": "v1" }, { "value": "mist" }] }
    },
    "type_:RimeAiVoice": {
      "name": "RimeAiVoice",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether fillers are injected into the model output before inputting it into the voice provider.\n\nDefault `false` because you can achieve better results with prompting the model.",
            "key": "fillerInjectionEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the provider-specific ID that will be used.",
            "key": "voiceId",
            "valueType": { "type": "id", "value": "type_:RimeAIVoiceId" }
          },
          {
            "description": "This is the model that will be used. Defaults to 'v1' when not specified.",
            "key": "model",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:RimeAiVoiceModel" } }
          },
          {
            "description": "This is the speed multiplier that will be used.",
            "key": "speed",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0.1 } }
            }
          },
          {
            "description": "This is the plan for chunking the model output before it is sent to the voice provider.",
            "key": "chunkPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ChunkPlan" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TransportConfigurationTwilioRecordingChannels": {
      "description": "The number of channels in the final recording.\nCan be: `mono` or `dual`.\nThe default is `mono`.\n`mono` records both legs of the call in a single channel of the recording file.\n`dual` records each leg to a separate channel of the recording file.\nThe first channel of a dual-channel recording contains the parent call and the second channel contains the child call.\n\n@default 'mono'",
      "name": "TransportConfigurationTwilioRecordingChannels",
      "shape": { "type": "enum", "values": [{ "value": "mono" }, { "value": "dual" }] }
    },
    "type_:TransportConfigurationTwilio": {
      "name": "TransportConfigurationTwilio",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "key": "provider",
            "valueType": { "type": "literal", "value": { "type": "stringLiteral", "value": "twilio" } }
          },
          {
            "description": "The integer number of seconds that we should allow the phone to ring before assuming there is no answer.\nThe default is `60` seconds and the maximum is `600` seconds.\nFor some call flows, we will add a 5-second buffer to the timeout value you provide.\nFor this reason, a timeout value of 10 seconds could result in an actual timeout closer to 15 seconds.\nYou can set this to a short time, such as `15` seconds, to hang up before reaching an answering machine or voicemail.\n\n@default 60",
            "key": "timeout",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 600 } }
            }
          },
          {
            "description": "Whether to record the call.\nCan be `true` to record the phone call, or `false` to not.\nThe default is `false`.\n\n@default false",
            "key": "record",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "The number of channels in the final recording.\nCan be: `mono` or `dual`.\nThe default is `mono`.\n`mono` records both legs of the call in a single channel of the recording file.\n`dual` records each leg to a separate channel of the recording file.\nThe first channel of a dual-channel recording contains the parent call and the second channel contains the child call.\n\n@default 'mono'",
            "key": "recordingChannels",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:TransportConfigurationTwilioRecordingChannels" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TwilioVoicemailDetectionVoicemailDetectionTypesItem": {
      "name": "TwilioVoicemailDetectionVoicemailDetectionTypesItem",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "machine_start" },
          { "value": "human" },
          { "value": "fax" },
          { "value": "unknown" },
          { "value": "machine_end_beep" },
          { "value": "machine_end_silence" },
          { "value": "machine_end_other" }
        ]
      }
    },
    "type_:TwilioVoicemailDetection": {
      "name": "TwilioVoicemailDetection",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the provider to use for voicemail detection.",
            "key": "provider",
            "valueType": { "type": "literal", "value": { "type": "stringLiteral", "value": "twilio" } }
          },
          {
            "description": "These are the AMD messages from Twilio that are considered as voicemail. Default is ['machine_end_beep', 'machine_end_silence'].\n\n@default {Array} ['machine_end_beep', 'machine_end_silence']",
            "key": "voicemailDetectionTypes",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:TwilioVoicemailDetectionVoicemailDetectionTypesItem" }
              }
            }
          },
          {
            "description": "This sets whether the assistant should detect voicemail. Defaults to true.\n\n@default true",
            "key": "enabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "The number of seconds that Twilio should attempt to perform answering machine detection before timing out and returning AnsweredBy as unknown. Default is 30 seconds.\n\nIncreasing this value will provide the engine more time to make a determination. This can be useful when DetectMessageEnd is provided in the MachineDetection parameter and there is an expectation of long answering machine greetings that can exceed 30 seconds.\n\nDecreasing this value will reduce the amount of time the engine has to make a determination. This can be particularly useful when the Enable option is provided in the MachineDetection parameter and you want to limit the time for initial detection.\n\nCheck the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.\n\n@default 30",
            "key": "machineDetectionTimeout",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 3, "maximum": 59 } }
            }
          },
          {
            "description": "The number of milliseconds that is used as the measuring stick for the length of the speech activity. Durations lower than this value will be interpreted as a human, longer as a machine. Default is 2400 milliseconds.\n\nIncreasing this value will reduce the chance of a False Machine (detected machine, actually human) for a long human greeting (e.g., a business greeting) but increase the time it takes to detect a machine.\n\nDecreasing this value will reduce the chances of a False Human (detected human, actually machine) for short voicemail greetings. The value of this parameter may need to be reduced by more than 1000ms to detect very short voicemail greetings. A reduction of that significance can result in increased False Machine detections. Adjusting the MachineDetectionSpeechEndThreshold is likely the better approach for short voicemails. Decreasing MachineDetectionSpeechThreshold will also reduce the time it takes to detect a machine.\n\nCheck the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.\n\n@default 2400",
            "key": "machineDetectionSpeechThreshold",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1000, "maximum": 6000 } }
            }
          },
          {
            "description": "The number of milliseconds of silence after speech activity at which point the speech activity is considered complete. Default is 1200 milliseconds.\n\nIncreasing this value will typically be used to better address the short voicemail greeting scenarios. For short voicemails, there is typically 1000-2000ms of audio followed by 1200-2400ms of silence and then additional audio before the beep. Increasing the MachineDetectionSpeechEndThreshold to ~2500ms will treat the 1200-2400ms of silence as a gap in the greeting but not the end of the greeting and will result in a machine detection. The downsides of such a change include:\n\n- Increasing the delay for human detection by the amount you increase this parameter, e.g., a change of 1200ms to 2500ms increases human detection delay by 1300ms.\n- Cases where a human has two utterances separated by a period of silence (e.g. a \"Hello\", then 2000ms of silence, and another \"Hello\") may be interpreted as a machine.\n\nDecreasing this value will result in faster human detection. The consequence is that it can lead to increased False Human (detected human, actually machine) detections because a silence gap in a voicemail greeting (not necessarily just in short voicemail scenarios) can be incorrectly interpreted as the end of speech.\n\nCheck the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.\n\n@default 1200",
            "key": "machineDetectionSpeechEndThreshold",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 500, "maximum": 5000 } }
            }
          },
          {
            "description": "The number of milliseconds of initial silence after which an unknown AnsweredBy result will be returned. Default is 5000 milliseconds.\n\nIncreasing this value will result in waiting for a longer period of initial silence before returning an 'unknown' AMD result.\n\nDecreasing this value will result in waiting for a shorter period of initial silence before returning an 'unknown' AMD result.\n\nCheck the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.\n\n@default 5000",
            "key": "machineDetectionSilenceTimeout",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "primitive",
                "value": { "type": "double", "minimum": 2000, "maximum": 10000 }
              }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:SummaryPlan": {
      "name": "SummaryPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the messages used to generate the summary.\n\n@default: ` [ { \"role\": \"system\", \"content\": \"You are an expert note-taker. You will be given a transcript of a call. Summarize the call in 2-3 sentences. DO NOT return anything except the summary.\" }, { \"role\": \"user\", \"content\": \"Here is the transcript:\\n\\n{{transcript}}\\n\\n\" } ]`\n\nYou can customize by providing any messages you want.\n\nHere are the template variables available:\n\n- {{transcript}}: The transcript of the call from `call.artifact.transcript`- {{systemPrompt}}: The system prompt of the call from `assistant.model.messages[type=system].content`",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": {
                  "type": "map",
                  "keyType": { "type": "primitive", "value": { "type": "string" } },
                  "valueType": { "type": "unknown" }
                }
              }
            }
          },
          {
            "description": "This determines whether a summary is generated and stored in `call.analysis.summary`. Defaults to true.\n\nUsage:\n\n- If you want to disable the summary, set this to false.\n\n@default true",
            "key": "enabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is how long the request is tried before giving up. When request times out, `call.analysis.summary` will be empty.\n\nUsage:\n\n- To guarantee the summary is generated, set this value high. Note, this will delay the end of call report in cases where model is slow to respond.\n\n@default 5 seconds",
            "key": "timeoutSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 60 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:StructuredDataPlan": {
      "name": "StructuredDataPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the messages used to generate the structured data.\n\n@default: ` [ { \"role\": \"system\", \"content\": \"You are an expert data extractor. You will be given a transcript of a call. Extract structured data per the JSON Schema. DO NOT return anything except the structured data.\\n\\nJson Schema:\\\\n{{schema}}\\n\\nOnly respond with the JSON.\" }, { \"role\": \"user\", \"content\": \"Here is the transcript:\\n\\n{{transcript}}\\n\\n\" } ]`\n\nYou can customize by providing any messages you want.\n\nHere are the template variables available:\n\n- {{transcript}}: the transcript of the call from `call.artifact.transcript`- {{systemPrompt}}: the system prompt of the call from `assistant.model.messages[type=system].content`- {{schema}}: the schema of the structured data from `structuredDataPlan.schema`",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": {
                  "type": "map",
                  "keyType": { "type": "primitive", "value": { "type": "string" } },
                  "valueType": { "type": "unknown" }
                }
              }
            }
          },
          {
            "description": "This determines whether structured data is generated and stored in `call.analysis.structuredData`. Defaults to false.\n\nUsage:\n\n- If you want to extract structured data, set this to true and provide a `schema`.\n\n@default false",
            "key": "enabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the schema of the structured data. The output is stored in `call.analysis.structuredData`.\n\nComplete guide on JSON Schema can be found [here](https://ajv.js.org/json-schema.html#json-data-type).",
            "key": "schema",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:JsonSchema" } }
          },
          {
            "description": "This is how long the request is tried before giving up. When request times out, `call.analysis.structuredData` will be empty.\n\nUsage:\n\n- To guarantee the structured data is generated, set this value high. Note, this will delay the end of call report in cases where model is slow to respond.\n\n@default 5 seconds",
            "key": "timeoutSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 60 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:SuccessEvaluationPlanRubric": {
      "description": "This enforces the rubric of the evaluation. The output is stored in `call.analysis.successEvaluation`.\n\nOptions include:\n\n- 'NumericScale': A scale of 1 to 10.\n- 'DescriptiveScale': A scale of Excellent, Good, Fair, Poor.\n- 'Checklist': A checklist of criteria and their status.\n- 'Matrix': A grid that evaluates multiple criteria across different performance levels.\n- 'PercentageScale': A scale of 0% to 100%.\n- 'LikertScale': A scale of Strongly Agree, Agree, Neutral, Disagree, Strongly Disagree.\n- 'AutomaticRubric': Automatically break down evaluation into several criteria, each with its own score.\n- 'PassFail': A simple 'true' if call passed, 'false' if not.\n\nDefault is 'PassFail'.",
      "name": "SuccessEvaluationPlanRubric",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "NumericScale" },
          { "value": "DescriptiveScale" },
          { "value": "Checklist" },
          { "value": "Matrix" },
          { "value": "PercentageScale" },
          { "value": "LikertScale" },
          { "value": "AutomaticRubric" },
          { "value": "PassFail" }
        ]
      }
    },
    "type_:SuccessEvaluationPlan": {
      "name": "SuccessEvaluationPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This enforces the rubric of the evaluation. The output is stored in `call.analysis.successEvaluation`.\n\nOptions include:\n\n- 'NumericScale': A scale of 1 to 10.\n- 'DescriptiveScale': A scale of Excellent, Good, Fair, Poor.\n- 'Checklist': A checklist of criteria and their status.\n- 'Matrix': A grid that evaluates multiple criteria across different performance levels.\n- 'PercentageScale': A scale of 0% to 100%.\n- 'LikertScale': A scale of Strongly Agree, Agree, Neutral, Disagree, Strongly Disagree.\n- 'AutomaticRubric': Automatically break down evaluation into several criteria, each with its own score.\n- 'PassFail': A simple 'true' if call passed, 'false' if not.\n\nDefault is 'PassFail'.",
            "key": "rubric",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:SuccessEvaluationPlanRubric" }
            }
          },
          {
            "description": "These are the messages used to generate the success evaluation.\n\n@default: ` [ { \"role\": \"system\", \"content\": \"You are an expert call evaluator. You will be given a transcript of a call and the system prompt of the AI participant. Determine if the call was successful based on the objectives inferred from the system prompt. DO NOT return anything except the result.\\n\\nRubric:\\\\n{{rubric}}\\n\\nOnly respond with the result.\" }, { \"role\": \"user\", \"content\": \"Here is the transcript:\\n\\n{{transcript}}\\n\\n\" }, { \"role\": \"user\", \"content\": \"Here was the system prompt of the call:\\n\\n{{systemPrompt}}\\n\\n\" } ]`\n\nYou can customize by providing any messages you want.\n\nHere are the template variables available:\n\n- {{transcript}}: the transcript of the call from `call.artifact.transcript`- {{systemPrompt}}: the system prompt of the call from `assistant.model.messages[type=system].content`- {{rubric}}: the rubric of the success evaluation from `successEvaluationPlan.rubric`",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": {
                  "type": "map",
                  "keyType": { "type": "primitive", "value": { "type": "string" } },
                  "valueType": { "type": "unknown" }
                }
              }
            }
          },
          {
            "description": "This determines whether a success evaluation is generated and stored in `call.analysis.successEvaluation`. Defaults to true.\n\nUsage:\n\n- If you want to disable the success evaluation, set this to false.\n\n@default true",
            "key": "enabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is how long the request is tried before giving up. When request times out, `call.analysis.successEvaluation` will be empty.\n\nUsage:\n\n- To guarantee the success evaluation is generated, set this value high. Note, this will delay the end of call report in cases where model is slow to respond.\n\n@default 5 seconds",
            "key": "timeoutSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 60 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AnalysisPlan": {
      "name": "AnalysisPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the plan for generating the summary of the call. This outputs to `call.analysis.summary`.",
            "key": "summaryPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:SummaryPlan" } }
          },
          {
            "description": "This is the plan for generating the structured data from the call. This outputs to `call.analysis.structuredData`.",
            "key": "structuredDataPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:StructuredDataPlan" } }
          },
          {
            "description": "This is the plan for generating the success evaluation of the call. This outputs to `call.analysis.successEvaluation`.",
            "key": "successEvaluationPlan",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:SuccessEvaluationPlan" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TranscriptPlan": {
      "name": "TranscriptPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether the transcript is stored in `call.artifact.transcript`. Defaults to true.\n\n@default true",
            "key": "enabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the name of the assistant in the transcript. Defaults to 'AI'.\n\nUsage:\n\n- If you want to change the name of the assistant in the transcript, set this. Example, here is what the transcript would look like with `assistantName` set to 'Buyer':\n\n```\nUser: Hello, how are you?\nBuyer: I'm fine.\nUser: Do you want to buy a car?\nBuyer: No.\n```\n\n@default 'AI'",
            "key": "assistantName",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the name of the user in the transcript. Defaults to 'User'.\n\nUsage:\n\n- If you want to change the name of the user in the transcript, set this. Example, here is what the transcript would look like with `userName` set to 'Seller':\n\n```\nSeller: Hello, how are you?\nAI: I'm fine.\nSeller: Do you want to buy a car?\nAI: No.\n```\n\n@default 'User'",
            "key": "userName",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ArtifactPlan": {
      "name": "ArtifactPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether assistant's calls are recorded. Defaults to true.\n\nUsage:\n\n- If you don't want to record the calls, set this to false.\n- If you want to record the calls when `assistant.hipaaEnabled`, explicity set this to true and make sure to provide S3 or GCP credentials on the Provider Credentials page in the Dashboard.\n\nYou can find the recording at `call.artifact.recordingUrl` and `call.artifact.stereoRecordingUrl` after the call is ended.\n\n@default true",
            "key": "recordingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This determines whether the video is recorded during the call. Defaults to false. Only relevant for `webCall` type.\n\nYou can find the video recording at `call.artifact.videoRecordingUrl` after the call is ended.\n\n@default false",
            "key": "videoRecordingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the plan for `call.artifact.transcript`. To disable, set `transcriptPlan.enabled` to false.",
            "key": "transcriptPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:TranscriptPlan" } }
          },
          {
            "description": "This is the path where the recording will be uploaded. This is only used if you have provided S3 or GCP credentials on the Provider Credentials page in the Dashboard.\n\nIf credential.s3PathPrefix or credential.bucketPlan.path is set, this will append to it.\n\nUsage:\n\n- If you want to upload the recording to a specific path, set this to the path. Example: `/my-assistant-recordings`.\n- If you want to upload the recording to the root of the bucket, set this to `/`.\n\n@default '/'",
            "key": "recordingPath",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:MessagePlan": {
      "name": "MessagePlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This are the messages that the assistant will speak when the user hasn't responded for `idleTimeoutSeconds`. Each time the timeout is triggered, a random message will be chosen from this array.\n\nUsage:\n\n- If user gets distracted and doesn't respond for a while, this can be used to grab their attention.\n- If the transcriber doesn't pick up what the user said, this can be used to ask the user to repeat themselves. (From the perspective of the assistant, the conversation is idle since it didn't \"hear\" any user messages.)\n\n@default null (no idle message is spoken)",
            "key": "idleMessages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This determines the maximum number of times `idleMessages` can be spoken during the call.\n\n@default 3",
            "key": "idleMessageMaxSpokenCount",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 1, "maximum": 10 } }
            }
          },
          {
            "description": "This is the timeout in seconds before a message from `idleMessages` is spoken. The clock starts when the assistant finishes speaking and remains active until the user speaks.\n\n@default 10",
            "key": "idleTimeoutSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 5, "maximum": 30 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TranscriptionEndpointingPlan": {
      "name": "TranscriptionEndpointingPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "The minimum number of seconds to wait after transcription ending with punctuation before sending a request to the model. Defaults to 0.1.\n\nThis setting exists because the transcriber punctuates the transcription when it's more confident that customer has completed a thought.\n\n@default 0.1",
            "key": "onPunctuationSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 3 } }
            }
          },
          {
            "description": "The minimum number of seconds to wait after transcription ending without punctuation before sending a request to the model. Defaults to 1.5.\n\nThis setting exists to catch the cases where the transcriber was not confident enough to punctuate the transcription, but the customer is done and has been silent for a long time.\n\n@default 1.5",
            "key": "onNoPunctuationSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 3 } }
            }
          },
          {
            "description": "The minimum number of seconds to wait after transcription ending with a number before sending a request to the model. Defaults to 0.4.\n\nThis setting exists because the transcriber will sometimes punctuate the transcription ending with a number, even though the customer hasn't uttered the full number. This happens commonly for long numbers when the customer reads the number in chunks.\n\n@default 0.5",
            "key": "onNumberSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 3 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:StartSpeakingPlan": {
      "name": "StartSpeakingPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is how long assistant waits before speaking. Defaults to 0.4.\n\nThis is the minimum it will wait but if there is latency is the pipeline, this minimum will be exceeded. This is really a stopgap in case the pipeline is moving too fast.\n\nExample:\n\n- If model generates tokens and voice generates bytes within 100ms, the pipeline still waits 300ms before outputting speech.\n\nUsage:\n\n- If the customer is taking long pauses, set this to a higher value.\n- If the assistant is accidentally jumping in too much, set this to a higher value.\n\n@default 0.4",
            "key": "waitSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 5 } }
            }
          },
          {
            "description": "This determines if a customer speech is considered done (endpointing) using the VAP model on customer's speech. This is good for middle-of-thought detection.\n\nOnce an endpoint is triggered, the request is sent to `assistant.model`.\n\nDefault `false` since experimental.\n\n@default false",
            "key": "smartEndpointingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This determines how a customer speech is considered done (endpointing) using the transcription of customer's speech.\n\nOnce an endpoint is triggered, the request is sent to `assistant.model`.",
            "key": "transcriptionEndpointingPlan",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:TranscriptionEndpointingPlan" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:StopSpeakingPlan": {
      "name": "StopSpeakingPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the number of words that the customer has to say before the assistant will stop talking.\n\nWords like \"stop\", \"actually\", \"no\", etc. will always interrupt immediately regardless of this value.\n\nWords like \"okay\", \"yeah\", \"right\" will never interrupt.\n\nWhen set to 0, `voiceSeconds` is used in addition to the transcriptions to determine the customer has started speaking.\n\nDefaults to 0.\n\n@default 0",
            "key": "numWords",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 10 } }
            }
          },
          {
            "description": "This is the seconds customer has to speak before the assistant stops talking. This uses the VAD (Voice Activity Detection) spike to determine if the customer has started speaking.\n\nConsiderations:\n\n- A lower value might be more responsive but could potentially pick up non-speech sounds.\n- A higher value reduces false positives but might slightly delay the detection of speech onset.\n\nThis is only used if `numWords` is set to 0.\n\nDefaults to 0.2\n\n@default 0.2",
            "key": "voiceSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 0.5 } }
            }
          },
          {
            "description": "This is the seconds to wait before the assistant will start talking again after being interrupted.\n\nDefaults to 1.\n\n@default 1",
            "key": "backoffSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 0, "maximum": 10 } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:MonitorPlan": {
      "name": "MonitorPlan",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines whether the assistant's calls allow live listening. Defaults to true.\n\nFetch `call.monitor.listenUrl` to get the live listening URL.\n\n@default true",
            "key": "listenEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This determines whether the assistant's calls allow live control. Defaults to true.\n\nFetch `call.monitor.controlUrl` to get the live control URL.\n\nTo use, send any control message via a POST request to `call.monitor.controlUrl`. Here are the types of controls supported: https://docs.vapi.ai/api-reference/messages/client-inbound-message\n\n@default true",
            "key": "controlEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateAssistantDtoTranscriber": {
      "description": "These are the options for the assistant's transcriber.",
      "name": "CreateAssistantDtoTranscriber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "deepgram",
            "additionalProperties": { "extends": ["type_:DeepgramTranscriber"], "properties": [] }
          },
          {
            "discriminantValue": "gladia",
            "additionalProperties": { "extends": ["type_:GladiaTranscriber"], "properties": [] }
          },
          {
            "discriminantValue": "talkscriber",
            "additionalProperties": { "extends": ["type_:TalkscriberTranscriber"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateAssistantDtoModel": {
      "description": "These are the options for the assistant's LLM.",
      "name": "CreateAssistantDtoModel",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "anyscale",
            "additionalProperties": { "extends": ["type_:AnyscaleModel"], "properties": [] }
          },
          {
            "discriminantValue": "anthropic",
            "additionalProperties": { "extends": ["type_:AnthropicModel"], "properties": [] }
          },
          {
            "discriminantValue": "custom-llm",
            "additionalProperties": { "extends": ["type_:CustomLlmModel"], "properties": [] }
          },
          {
            "discriminantValue": "deepinfra",
            "additionalProperties": { "extends": ["type_:DeepInfraModel"], "properties": [] }
          },
          {
            "discriminantValue": "groq",
            "additionalProperties": { "extends": ["type_:GroqModel"], "properties": [] }
          },
          {
            "discriminantValue": "openai",
            "additionalProperties": { "extends": ["type_:OpenAiModel"], "properties": [] }
          },
          {
            "discriminantValue": "openrouter",
            "additionalProperties": { "extends": ["type_:OpenRouterModel"], "properties": [] }
          },
          {
            "discriminantValue": "perplexity-ai",
            "additionalProperties": { "extends": ["type_:PerplexityAiModel"], "properties": [] }
          },
          {
            "discriminantValue": "together-ai",
            "additionalProperties": { "extends": ["type_:TogetherAiModel"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:VapiModel"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateAssistantDtoVoice": {
      "description": "These are the options for the assistant's voice.",
      "name": "CreateAssistantDtoVoice",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "azure",
            "additionalProperties": { "extends": ["type_:AzureVoice"], "properties": [] }
          },
          {
            "discriminantValue": "cartesia",
            "additionalProperties": { "extends": ["type_:CartesiaVoice"], "properties": [] }
          },
          {
            "discriminantValue": "deepgram",
            "additionalProperties": { "extends": ["type_:DeepgramVoice"], "properties": [] }
          },
          {
            "discriminantValue": "11labs",
            "additionalProperties": { "extends": ["type_:ElevenLabsVoice"], "properties": [] }
          },
          {
            "discriminantValue": "lmnt",
            "additionalProperties": { "extends": ["type_:LmntVoice"], "properties": [] }
          },
          {
            "discriminantValue": "neets",
            "additionalProperties": { "extends": ["type_:NeetsVoice"], "properties": [] }
          },
          {
            "discriminantValue": "openai",
            "additionalProperties": { "extends": ["type_:OpenAiVoice"], "properties": [] }
          },
          {
            "discriminantValue": "playht",
            "additionalProperties": { "extends": ["type_:PlayHtVoice"], "properties": [] }
          },
          {
            "discriminantValue": "rime-ai",
            "additionalProperties": { "extends": ["type_:RimeAiVoice"], "properties": [] }
          }
        ]
      }
    },
    "type_:CreateAssistantDtoFirstMessageMode": {
      "description": "This is the mode for the first message. Default is 'assistant-speaks-first'.\n\nUse:\n\n- 'assistant-speaks-first' to have the assistant speak first.\n- 'assistant-waits-for-user' to have the assistant wait for the user to speak first.\n- 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).\n\n@default 'assistant-speaks-first'",
      "name": "CreateAssistantDtoFirstMessageMode",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "assistant-speaks-first" },
          { "value": "assistant-speaks-first-with-model-generated-message" },
          { "value": "assistant-waits-for-user" }
        ]
      }
    },
    "type_:CreateAssistantDtoClientMessagesItem": {
      "name": "CreateAssistantDtoClientMessagesItem",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "conversation-update" },
          { "value": "function-call" },
          { "value": "function-call-result" },
          { "value": "hang" },
          { "value": "language-changed" },
          { "value": "metadata" },
          { "value": "model-output" },
          { "value": "speech-update" },
          { "value": "status-update" },
          { "value": "transcript" },
          { "value": "tool-calls" },
          { "value": "tool-calls-result" },
          { "value": "user-interrupted" },
          { "value": "voice-input" }
        ]
      }
    },
    "type_:CreateAssistantDtoServerMessagesItem": {
      "name": "CreateAssistantDtoServerMessagesItem",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "conversation-update" },
          { "value": "end-of-call-report" },
          { "value": "function-call" },
          { "value": "hang" },
          { "value": "language-changed" },
          { "value": "model-output" },
          { "value": "phone-call-control" },
          { "value": "speech-update" },
          { "value": "status-update" },
          { "value": "transcript" },
          { "value": "tool-calls" },
          { "value": "transfer-destination-request" },
          { "value": "transfer-update" },
          { "value": "user-interrupted" },
          { "value": "voice-input" }
        ]
      }
    },
    "type_:CreateAssistantDtoBackgroundSound": {
      "description": "This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.",
      "name": "CreateAssistantDtoBackgroundSound",
      "shape": { "type": "enum", "values": [{ "value": "off" }, { "value": "office" }] }
    },
    "type_:CreateAssistantDto": {
      "name": "CreateAssistantDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the options for the assistant's transcriber.",
            "key": "transcriber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateAssistantDtoTranscriber" }
            }
          },
          {
            "description": "These are the options for the assistant's LLM.",
            "key": "model",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateAssistantDtoModel" }
            }
          },
          {
            "description": "These are the options for the assistant's voice.",
            "key": "voice",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateAssistantDtoVoice" }
            }
          },
          {
            "description": "This is the mode for the first message. Default is 'assistant-speaks-first'.\n\nUse:\n\n- 'assistant-speaks-first' to have the assistant speak first.\n- 'assistant-waits-for-user' to have the assistant wait for the user to speak first.\n- 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).\n\n@default 'assistant-speaks-first'",
            "key": "firstMessageMode",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateAssistantDtoFirstMessageMode" }
            }
          },
          {
            "description": "When this is enabled, no logs, recordings, or transcriptions will be stored. At the end of the call, you will still receive an end-of-call-report message to store on your server. Defaults to false.",
            "key": "hipaaEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be sent to your Client SDKs. Default is conversation-update,function-call,hang,model-output,speech-update,status-update,transcript,tool-calls,user-interrupted,voice-input. You can check the shape of the messages in ClientMessage schema.",
            "key": "clientMessages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateAssistantDtoClientMessagesItem" }
              }
            }
          },
          {
            "description": "These are the messages that will be sent to your Server URL. Default is conversation-update,end-of-call-report,function-call,hang,speech-update,status-update,tool-calls,transfer-destination-request,user-interrupted. You can check the shape of the messages in ServerMessage schema.",
            "key": "serverMessages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:CreateAssistantDtoServerMessagesItem" }
              }
            }
          },
          {
            "description": "How many seconds of silence to wait before ending the call. Defaults to 30.\n\n@default 30",
            "key": "silenceTimeoutSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 10, "maximum": 600 } }
            }
          },
          {
            "description": "This is the maximum number of seconds that the call will last. When the call reaches this duration, it will be ended.\n\n@default 600 (10 minutes)",
            "key": "maxDurationSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 10, "maximum": 21600 } }
            }
          },
          {
            "description": "This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.",
            "key": "backgroundSound",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CreateAssistantDtoBackgroundSound" }
            }
          },
          {
            "description": "This determines whether the model says 'mhmm', 'ahem' etc. while user is speaking.\n\nDefault `false` while in beta.\n\n@default false",
            "key": "backchannelingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This enables filtering of noise and background speech while the user is talking.\n\nDefault `false` while in beta.\n\n@default false",
            "key": "backgroundDenoisingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This determines whether the model's output is used in conversation history rather than the transcription of assistant's speech.\n\nDefault `false` while in beta.\n\n@default false",
            "key": "modelOutputInMessagesEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the configurations to be passed to the transport providers of assistant's calls, like Twilio. You can store multiple configurations for different transport providers. For a call, only the configuration matching the call transport provider is used.",
            "key": "transportConfigurations",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:TransportConfigurationTwilio" }
              }
            }
          },
          {
            "description": "This is the name of the assistant.\n\nThis is required when you want to transfer between assistants in a call.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the first message that the assistant will say. This can also be a URL to a containerized audio file (mp3, wav, etc.).\n\nIf unspecified, assistant will wait for user to speak and use the model to respond once they speak.",
            "key": "firstMessage",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "These are the settings to configure or disable voicemail detection. Alternatively, voicemail detection can be configured using the model.tools=[VoicemailTool].\nThis uses Twilio's built-in detection while the VoicemailTool relies on the model to detect if a voicemail was reached.\nYou can use neither of them, one of them, or both of them. By default, Twilio built-in detection is enabled while VoicemailTool is not.",
            "key": "voicemailDetection",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:TwilioVoicemailDetection" }
            }
          },
          {
            "description": "This is the message that the assistant will say if the call is forwarded to voicemail.\n\nIf unspecified, it will hang up.",
            "key": "voicemailMessage",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the message that the assistant will say if it ends the call.\n\nIf unspecified, it will hang up without saying anything.",
            "key": "endCallMessage",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This list contains phrases that, if spoken by the assistant, will trigger the call to be hung up. Case insensitive.",
            "key": "endCallPhrases",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is for metadata you want to store on the assistant.",
            "key": "metadata",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          },
          {
            "description": "This is the URL Vapi will communicate with via HTTP GET and POST Requests. This is used for retrieving context, function calling, and end-of-call reports.\n\nAll requests will be sent with the call object among other things relevant to that message. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: tool.server.url > assistant.serverUrl > phoneNumber.serverUrl > org.serverUrl",
            "key": "serverUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the secret you can set that Vapi will send with every request to your server. Will be sent as a header called x-vapi-secret.\n\nSame precedence logic as serverUrl.",
            "key": "serverUrlSecret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the plan for analysis of assistant's calls. Stored in `call.analysis`.",
            "key": "analysisPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:AnalysisPlan" } }
          },
          {
            "description": "This is the plan for artifacts generated during assistant's calls. Stored in `call.artifact`.\n\nNote: `recordingEnabled` is currently at the root level. It will be moved to `artifactPlan` in the future, but will remain backwards compatible.",
            "key": "artifactPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ArtifactPlan" } }
          },
          {
            "description": "This is the plan for static predefined messages that can be spoken by the assistant during the call, like `idleMessages`.\n\nNote: `firstMessage`, `voicemailMessage`, and `endCallMessage` are currently at the root level. They will be moved to `messagePlan` in the future, but will remain backwards compatible.",
            "key": "messagePlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:MessagePlan" } }
          },
          {
            "description": "This is the plan for when the assistant should start talking.\n\nYou should configure this if you're running into these issues:\n\n- The assistant is too slow to start talking after the customer is done speaking.\n- The assistant is too fast to start talking after the customer is done speaking.\n- The assistant is so fast that it's actually interrupting the customer.",
            "key": "startSpeakingPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:StartSpeakingPlan" } }
          },
          {
            "description": "This is the plan for when assistant should stop talking on customer interruption.\n\nYou should configure this if you're running into these issues:\n\n- The assistant is too slow to recognize customer's interruption.\n- The assistant is too fast to recognize customer's interruption.\n- The assistant is getting interrupted by phrases that are just acknowledgments.\n- The assistant is getting interrupted by background noises.\n- The assistant is not properly stopping -- it starts talking right after getting interrupted.",
            "key": "stopSpeakingPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:StopSpeakingPlan" } }
          },
          {
            "description": "This is the plan for real-time monitoring of the assistant's calls.\n\nUsage:\n\n- To enable live listening of the assistant's calls, set `monitorPlan.listenEnabled` to `true`.\n- To enable live control of the assistant's calls, set `monitorPlan.controlEnabled` to `true`.\n\nNote, `serverMessages`, `clientMessages`, `serverUrl` and `serverUrlSecret` are currently at the root level but will be moved to `monitorPlan` in the future. Will remain backwards compatible",
            "key": "monitorPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:MonitorPlan" } }
          },
          {
            "description": "These are the credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can provide a subset using this.",
            "key": "credentialIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateCustomerDto": {
      "name": "CreateCustomerDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.\n\nUse cases:\n\n- `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.\n- `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.\n\nIf `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\\+?[a-zA-Z0-9]+$/`).\n\n@default true (E164 check is enabled)",
            "key": "numberE164CheckEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This is the extension that will be dialed after the call is answered.",
            "key": "extension",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the number of the customer.",
            "key": "number",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string", "minLength": 3, "maxLength": 3 } }
            }
          },
          {
            "description": "This is the SIP URI of the customer.",
            "key": "sipUri",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the name of the customer. This is just for your own reference.\n\nFor SIP inbound calls, this is extracted from the `From` SIP header with format `\"Display Name\" <sip:username@domain>`.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TransportCost": {
      "name": "TransportCost",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the minutes of `transport` usage. This should match `call.endedAt` - `call.startedAt`.",
            "key": "minutes",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the cost of the component in USD.",
            "key": "cost",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:TranscriberCost": {
      "name": "TranscriberCost",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the transcriber that was used during the call.\n\nThis matches one of the below:\n\n- `call.assistant.transcriber`,\n- `call.assistantId->transcriber`,\n- `call.squad[n].assistant.transcriber`,\n- `call.squad[n].assistantId->transcriber`,\n- `call.squadId->[n].assistant.transcriber`,\n- `call.squadId->[n].assistantId->transcriber`.",
            "key": "transcriber",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          },
          {
            "description": "This is the minutes of `transcriber` usage. This should match `call.endedAt` - `call.startedAt` for single assistant calls, while squad calls will have multiple transcriber costs one for each assistant that was used.",
            "key": "minutes",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the cost of the component in USD.",
            "key": "cost",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ModelCost": {
      "name": "ModelCost",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the model that was used during the call.\n\nThis matches one of the following:\n\n- `call.assistant.model`,\n- `call.assistantId->model`,\n- `call.squad[n].assistant.model`,\n- `call.squad[n].assistantId->model`,\n- `call.squadId->[n].assistant.model`,\n- `call.squadId->[n].assistantId->model`.",
            "key": "model",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          },
          {
            "description": "This is the number of prompt tokens used in the call. These should be total prompt tokens used in the call for single assistant calls, while squad calls will have multiple model costs one for each assistant that was used.",
            "key": "promptTokens",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the number of completion tokens generated in the call. These should be total completion tokens used in the call for single assistant calls, while squad calls will have multiple model costs one for each assistant that was used.",
            "key": "completionTokens",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the cost of the component in USD.",
            "key": "cost",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:VoiceCost": {
      "name": "VoiceCost",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the voice that was used during the call.\n\nThis matches one of the following:\n\n- `call.assistant.voice`,\n- `call.assistantId->voice`,\n- `call.squad[n].assistant.voice`,\n- `call.squad[n].assistantId->voice`,\n- `call.squadId->[n].assistant.voice`,\n- `call.squadId->[n].assistantId->voice`.",
            "key": "voice",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          },
          {
            "description": "This is the number of characters that were generated during the call. These should be total characters used in the call for single assistant calls, while squad calls will have multiple voice costs one for each assistant that was used.",
            "key": "characters",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the cost of the component in USD.",
            "key": "cost",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:VapiCost": {
      "name": "VapiCost",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the minutes of Vapi usage. This should match `call.endedAt` - `call.startedAt`.",
            "key": "minutes",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the cost of the component in USD.",
            "key": "cost",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AnalysisCostAnalysisType": {
      "description": "This is the type of analysis performed.",
      "name": "AnalysisCostAnalysisType",
      "shape": {
        "type": "enum",
        "values": [{ "value": "summary" }, { "value": "structuredData" }, { "value": "successEvaluation" }]
      }
    },
    "type_:AnalysisCost": {
      "name": "AnalysisCost",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the type of analysis performed.",
            "key": "analysisType",
            "valueType": { "type": "id", "value": "type_:AnalysisCostAnalysisType" }
          },
          {
            "description": "This is the model that was used to perform the analysis.",
            "key": "model",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          },
          {
            "description": "This is the number of prompt tokens used in the analysis.",
            "key": "promptTokens",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the number of completion tokens generated in the analysis.",
            "key": "completionTokens",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          },
          {
            "description": "This is the cost of the component in USD.",
            "key": "cost",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AnalysisCostBreakdown": {
      "name": "AnalysisCostBreakdown",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the cost to summarize the call.",
            "key": "summary",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the number of prompt tokens used to summarize the call.",
            "key": "summaryPromptTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the number of completion tokens used to summarize the call.",
            "key": "summaryCompletionTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost to extract structured data from the call.",
            "key": "structuredData",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the number of prompt tokens used to extract structured data from the call.",
            "key": "structuredDataPromptTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the number of completion tokens used to extract structured data from the call.",
            "key": "structuredDataCompletionTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost to evaluate if the call was successful.",
            "key": "successEvaluation",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the number of prompt tokens used to evaluate if the call was successful.",
            "key": "successEvaluationPromptTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the number of completion tokens used to evaluate if the call was successful.",
            "key": "successEvaluationCompletionTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CostBreakdown": {
      "name": "CostBreakdown",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the cost of the transport provider, like Twilio or Vonage.",
            "key": "transport",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost of the speech-to-text service.",
            "key": "stt",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost of the language model.",
            "key": "llm",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost of the text-to-speech service.",
            "key": "tts",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost of Vapi.",
            "key": "vapi",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the total cost of the call.",
            "key": "total",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the LLM prompt tokens used for the call.",
            "key": "llmPromptTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the LLM completion tokens used for the call.",
            "key": "llmCompletionTokens",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the TTS characters used for the call.",
            "key": "ttsCharacters",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost of the analysis.",
            "key": "analysisCostBreakdown",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:AnalysisCostBreakdown" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:Analysis": {
      "name": "Analysis",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the summary of the call. Customize by setting `assistant.analysisPlan.summaryPrompt`.",
            "key": "summary",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the structured data extracted from the call. Customize by setting `assistant.analysisPlan.structuredDataPrompt` and/or `assistant.analysisPlan.structuredDataSchema`.",
            "key": "structuredData",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          },
          {
            "description": "This is the evaluation of the call. Customize by setting `assistant.analysisPlan.successEvaluationPrompt` and/or `assistant.analysisPlan.successEvaluationRubric`.",
            "key": "successEvaluation",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:Monitor": {
      "name": "Monitor",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the URL where the assistant's calls can be listened to in real-time. To enable, set `assistant.monitorPlan.listenEnabled` to `true`.",
            "key": "listenUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the URL where the assistant's calls can be controlled in real-time. To enable, set `assistant.monitorPlan.controlEnabled` to `true`.",
            "key": "controlUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:AssistantOverridesTranscriber": {
      "description": "These are the options for the assistant's transcriber.",
      "name": "AssistantOverridesTranscriber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "deepgram",
            "additionalProperties": { "extends": ["type_:DeepgramTranscriber"], "properties": [] }
          },
          {
            "discriminantValue": "gladia",
            "additionalProperties": { "extends": ["type_:GladiaTranscriber"], "properties": [] }
          },
          {
            "discriminantValue": "talkscriber",
            "additionalProperties": { "extends": ["type_:TalkscriberTranscriber"], "properties": [] }
          }
        ]
      }
    },
    "type_:AssistantOverridesModel": {
      "description": "These are the options for the assistant's LLM.",
      "name": "AssistantOverridesModel",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "anyscale",
            "additionalProperties": { "extends": ["type_:AnyscaleModel"], "properties": [] }
          },
          {
            "discriminantValue": "anthropic",
            "additionalProperties": { "extends": ["type_:AnthropicModel"], "properties": [] }
          },
          {
            "discriminantValue": "custom-llm",
            "additionalProperties": { "extends": ["type_:CustomLlmModel"], "properties": [] }
          },
          {
            "discriminantValue": "deepinfra",
            "additionalProperties": { "extends": ["type_:DeepInfraModel"], "properties": [] }
          },
          {
            "discriminantValue": "groq",
            "additionalProperties": { "extends": ["type_:GroqModel"], "properties": [] }
          },
          {
            "discriminantValue": "openai",
            "additionalProperties": { "extends": ["type_:OpenAiModel"], "properties": [] }
          },
          {
            "discriminantValue": "openrouter",
            "additionalProperties": { "extends": ["type_:OpenRouterModel"], "properties": [] }
          },
          {
            "discriminantValue": "perplexity-ai",
            "additionalProperties": { "extends": ["type_:PerplexityAiModel"], "properties": [] }
          },
          {
            "discriminantValue": "together-ai",
            "additionalProperties": { "extends": ["type_:TogetherAiModel"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:VapiModel"], "properties": [] }
          }
        ]
      }
    },
    "type_:AssistantOverridesVoice": {
      "description": "These are the options for the assistant's voice.",
      "name": "AssistantOverridesVoice",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "azure",
            "additionalProperties": { "extends": ["type_:AzureVoice"], "properties": [] }
          },
          {
            "discriminantValue": "cartesia",
            "additionalProperties": { "extends": ["type_:CartesiaVoice"], "properties": [] }
          },
          {
            "discriminantValue": "deepgram",
            "additionalProperties": { "extends": ["type_:DeepgramVoice"], "properties": [] }
          },
          {
            "discriminantValue": "11labs",
            "additionalProperties": { "extends": ["type_:ElevenLabsVoice"], "properties": [] }
          },
          {
            "discriminantValue": "lmnt",
            "additionalProperties": { "extends": ["type_:LmntVoice"], "properties": [] }
          },
          {
            "discriminantValue": "neets",
            "additionalProperties": { "extends": ["type_:NeetsVoice"], "properties": [] }
          },
          {
            "discriminantValue": "openai",
            "additionalProperties": { "extends": ["type_:OpenAiVoice"], "properties": [] }
          },
          {
            "discriminantValue": "playht",
            "additionalProperties": { "extends": ["type_:PlayHtVoice"], "properties": [] }
          },
          {
            "discriminantValue": "rime-ai",
            "additionalProperties": { "extends": ["type_:RimeAiVoice"], "properties": [] }
          }
        ]
      }
    },
    "type_:AssistantOverridesFirstMessageMode": {
      "description": "This is the mode for the first message. Default is 'assistant-speaks-first'.\n\nUse:\n\n- 'assistant-speaks-first' to have the assistant speak first.\n- 'assistant-waits-for-user' to have the assistant wait for the user to speak first.\n- 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).\n\n@default 'assistant-speaks-first'",
      "name": "AssistantOverridesFirstMessageMode",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "assistant-speaks-first" },
          { "value": "assistant-speaks-first-with-model-generated-message" },
          { "value": "assistant-waits-for-user" }
        ]
      }
    },
    "type_:AssistantOverridesClientMessagesItem": {
      "name": "AssistantOverridesClientMessagesItem",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "conversation-update" },
          { "value": "function-call" },
          { "value": "function-call-result" },
          { "value": "hang" },
          { "value": "language-changed" },
          { "value": "metadata" },
          { "value": "model-output" },
          { "value": "speech-update" },
          { "value": "status-update" },
          { "value": "transcript" },
          { "value": "tool-calls" },
          { "value": "tool-calls-result" },
          { "value": "user-interrupted" },
          { "value": "voice-input" }
        ]
      }
    },
    "type_:AssistantOverridesServerMessagesItem": {
      "name": "AssistantOverridesServerMessagesItem",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "conversation-update" },
          { "value": "end-of-call-report" },
          { "value": "function-call" },
          { "value": "hang" },
          { "value": "language-changed" },
          { "value": "model-output" },
          { "value": "phone-call-control" },
          { "value": "speech-update" },
          { "value": "status-update" },
          { "value": "transcript" },
          { "value": "tool-calls" },
          { "value": "transfer-destination-request" },
          { "value": "transfer-update" },
          { "value": "user-interrupted" },
          { "value": "voice-input" }
        ]
      }
    },
    "type_:AssistantOverridesBackgroundSound": {
      "description": "This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.",
      "name": "AssistantOverridesBackgroundSound",
      "shape": { "type": "enum", "values": [{ "value": "off" }, { "value": "office" }] }
    },
    "type_:AssistantOverrides": {
      "name": "AssistantOverrides",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the options for the assistant's transcriber.",
            "key": "transcriber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:AssistantOverridesTranscriber" }
            }
          },
          {
            "description": "These are the options for the assistant's LLM.",
            "key": "model",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:AssistantOverridesModel" }
            }
          },
          {
            "description": "These are the options for the assistant's voice.",
            "key": "voice",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:AssistantOverridesVoice" }
            }
          },
          {
            "description": "This is the mode for the first message. Default is 'assistant-speaks-first'.\n\nUse:\n\n- 'assistant-speaks-first' to have the assistant speak first.\n- 'assistant-waits-for-user' to have the assistant wait for the user to speak first.\n- 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).\n\n@default 'assistant-speaks-first'",
            "key": "firstMessageMode",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:AssistantOverridesFirstMessageMode" }
            }
          },
          {
            "description": "When this is enabled, no logs, recordings, or transcriptions will be stored. At the end of the call, you will still receive an end-of-call-report message to store on your server. Defaults to false.",
            "key": "hipaaEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be sent to your Client SDKs. Default is conversation-update,function-call,hang,model-output,speech-update,status-update,transcript,tool-calls,user-interrupted,voice-input. You can check the shape of the messages in ClientMessage schema.",
            "key": "clientMessages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:AssistantOverridesClientMessagesItem" }
              }
            }
          },
          {
            "description": "These are the messages that will be sent to your Server URL. Default is conversation-update,end-of-call-report,function-call,hang,speech-update,status-update,tool-calls,transfer-destination-request,user-interrupted. You can check the shape of the messages in ServerMessage schema.",
            "key": "serverMessages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:AssistantOverridesServerMessagesItem" }
              }
            }
          },
          {
            "description": "How many seconds of silence to wait before ending the call. Defaults to 30.\n\n@default 30",
            "key": "silenceTimeoutSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 10, "maximum": 600 } }
            }
          },
          {
            "description": "This is the maximum number of seconds that the call will last. When the call reaches this duration, it will be ended.\n\n@default 600 (10 minutes)",
            "key": "maxDurationSeconds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double", "minimum": 10, "maximum": 21600 } }
            }
          },
          {
            "description": "This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.",
            "key": "backgroundSound",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:AssistantOverridesBackgroundSound" }
            }
          },
          {
            "description": "This determines whether the model says 'mhmm', 'ahem' etc. while user is speaking.\n\nDefault `false` while in beta.\n\n@default false",
            "key": "backchannelingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This enables filtering of noise and background speech while the user is talking.\n\nDefault `false` while in beta.\n\n@default false",
            "key": "backgroundDenoisingEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "This determines whether the model's output is used in conversation history rather than the transcription of assistant's speech.\n\nDefault `false` while in beta.\n\n@default false",
            "key": "modelOutputInMessagesEnabled",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the configurations to be passed to the transport providers of assistant's calls, like Twilio. You can store multiple configurations for different transport providers. For a call, only the configuration matching the call transport provider is used.",
            "key": "transportConfigurations",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:TransportConfigurationTwilio" }
              }
            }
          },
          {
            "description": "These are values that will be used to replace the template variables in the assistant messages and other text-based fields.",
            "key": "variableValues",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          },
          {
            "description": "This is the name of the assistant.\n\nThis is required when you want to transfer between assistants in a call.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the first message that the assistant will say. This can also be a URL to a containerized audio file (mp3, wav, etc.).\n\nIf unspecified, assistant will wait for user to speak and use the model to respond once they speak.",
            "key": "firstMessage",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "These are the settings to configure or disable voicemail detection. Alternatively, voicemail detection can be configured using the model.tools=[VoicemailTool].\nThis uses Twilio's built-in detection while the VoicemailTool relies on the model to detect if a voicemail was reached.\nYou can use neither of them, one of them, or both of them. By default, Twilio built-in detection is enabled while VoicemailTool is not.",
            "key": "voicemailDetection",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:TwilioVoicemailDetection" }
            }
          },
          {
            "description": "This is the message that the assistant will say if the call is forwarded to voicemail.\n\nIf unspecified, it will hang up.",
            "key": "voicemailMessage",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the message that the assistant will say if it ends the call.\n\nIf unspecified, it will hang up without saying anything.",
            "key": "endCallMessage",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This list contains phrases that, if spoken by the assistant, will trigger the call to be hung up. Case insensitive.",
            "key": "endCallPhrases",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          },
          {
            "description": "This is for metadata you want to store on the assistant.",
            "key": "metadata",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          },
          {
            "description": "This is the URL Vapi will communicate with via HTTP GET and POST Requests. This is used for retrieving context, function calling, and end-of-call reports.\n\nAll requests will be sent with the call object among other things relevant to that message. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: tool.server.url > assistant.serverUrl > phoneNumber.serverUrl > org.serverUrl",
            "key": "serverUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the secret you can set that Vapi will send with every request to your server. Will be sent as a header called x-vapi-secret.\n\nSame precedence logic as serverUrl.",
            "key": "serverUrlSecret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the plan for analysis of assistant's calls. Stored in `call.analysis`.",
            "key": "analysisPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:AnalysisPlan" } }
          },
          {
            "description": "This is the plan for artifacts generated during assistant's calls. Stored in `call.artifact`.\n\nNote: `recordingEnabled` is currently at the root level. It will be moved to `artifactPlan` in the future, but will remain backwards compatible.",
            "key": "artifactPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ArtifactPlan" } }
          },
          {
            "description": "This is the plan for static predefined messages that can be spoken by the assistant during the call, like `idleMessages`.\n\nNote: `firstMessage`, `voicemailMessage`, and `endCallMessage` are currently at the root level. They will be moved to `messagePlan` in the future, but will remain backwards compatible.",
            "key": "messagePlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:MessagePlan" } }
          },
          {
            "description": "This is the plan for when the assistant should start talking.\n\nYou should configure this if you're running into these issues:\n\n- The assistant is too slow to start talking after the customer is done speaking.\n- The assistant is too fast to start talking after the customer is done speaking.\n- The assistant is so fast that it's actually interrupting the customer.",
            "key": "startSpeakingPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:StartSpeakingPlan" } }
          },
          {
            "description": "This is the plan for when assistant should stop talking on customer interruption.\n\nYou should configure this if you're running into these issues:\n\n- The assistant is too slow to recognize customer's interruption.\n- The assistant is too fast to recognize customer's interruption.\n- The assistant is getting interrupted by phrases that are just acknowledgments.\n- The assistant is getting interrupted by background noises.\n- The assistant is not properly stopping -- it starts talking right after getting interrupted.",
            "key": "stopSpeakingPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:StopSpeakingPlan" } }
          },
          {
            "description": "This is the plan for real-time monitoring of the assistant's calls.\n\nUsage:\n\n- To enable live listening of the assistant's calls, set `monitorPlan.listenEnabled` to `true`.\n- To enable live control of the assistant's calls, set `monitorPlan.controlEnabled` to `true`.\n\nNote, `serverMessages`, `clientMessages`, `serverUrl` and `serverUrlSecret` are currently at the root level but will be moved to `monitorPlan` in the future. Will remain backwards compatible",
            "key": "monitorPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:MonitorPlan" } }
          },
          {
            "description": "These are the credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can provide a subset using this.",
            "key": "credentialIds",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "primitive", "value": { "type": "string" } } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:SquadMemberDto": {
      "name": "SquadMemberDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This can be used to override the assistant's settings and provide values for it's template variables.",
            "key": "assistantOverrides",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:AssistantOverrides" } }
          },
          {
            "description": "These are the others assistants that this assistant can transfer to.\n\nIf the assistant already has transfer call tool, these destinations are just appended to existing ones.",
            "key": "assistantDestinations",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:TransferDestinationAssistant" }
              }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CreateSquadDto": {
      "name": "CreateSquadDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the name of the squad.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the list of assistants that make up the squad.\n\nThe call will start with the first assistant in the list.",
            "key": "members",
            "valueType": { "type": "list", "itemType": { "type": "id", "value": "type_:SquadMemberDto" } }
          },
          {
            "description": "This can be used to override all the assistants' settings and provide values for their template variables.\n\nBoth `membersOverrides` and `members[n].assistantOverrides` can be used together. First, `members[n].assistantOverrides` is applied. Then, `membersOverrides` is applied as a global override.",
            "key": "membersOverrides",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:AssistantOverrides" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ImportTwilioPhoneNumberDtoFallbackDestination": {
      "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
      "name": "ImportTwilioPhoneNumberDtoFallbackDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:ImportTwilioPhoneNumberDto": {
      "name": "ImportTwilioPhoneNumberDto",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the fallback destination an inbound call will be transferred to if:\n\n1. `assistantId` is not set\n2. `squadId` is not set\n3. and, `assistant-request` message to the `serverUrl` fails\n\nIf this is not set and above conditions are met, the inbound call is hung up with an error message.",
            "key": "fallbackDestination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ImportTwilioPhoneNumberDtoFallbackDestination" }
            }
          },
          {
            "description": "These are the digits of the phone number you own on your Twilio.",
            "availability": "Deprecated",
            "key": "twilioPhoneNumber",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is your Twilio Account SID that will be used to handle this phone number.",
            "key": "twilioAccountSid",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the Twilio Auth Token that will be used to handle this phone number.",
            "key": "twilioAuthToken",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the name of the phone number. This is just for your own reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the squad that will be used for incoming calls to this phone number.\n\nIf neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.",
            "key": "squadId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the server URL where messages will be sent for calls on this number. This includes the `assistant-request` message.\n\nYou can see the shape of the messages sent in `ServerMessage`.\n\nThis overrides the `org.serverUrl`. Order of precedence: tool.server.url > assistant.serverUrl > phoneNumber.serverUrl > org.serverUrl.",
            "key": "serverUrl",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the secret Vapi will send with every message to your server. It's sent as a header called x-vapi-secret.\n\nSame precedence logic as serverUrl.",
            "key": "serverUrlSecret",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:CallType": {
      "description": "This is the type of call.",
      "name": "CallType",
      "shape": {
        "type": "enum",
        "values": [{ "value": "inboundPhoneCall" }, { "value": "outboundPhoneCall" }, { "value": "webCall" }]
      }
    },
    "type_:CallCostsItem": {
      "name": "CallCostsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "transport",
            "additionalProperties": { "extends": ["type_:TransportCost"], "properties": [] }
          },
          {
            "discriminantValue": "transcriber",
            "additionalProperties": { "extends": ["type_:TranscriberCost"], "properties": [] }
          },
          {
            "discriminantValue": "model",
            "additionalProperties": { "extends": ["type_:ModelCost"], "properties": [] }
          },
          {
            "discriminantValue": "voice",
            "additionalProperties": { "extends": ["type_:VoiceCost"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:VapiCost"], "properties": [] }
          },
          {
            "discriminantValue": "analysis",
            "additionalProperties": { "extends": ["type_:AnalysisCost"], "properties": [] }
          }
        ]
      }
    },
    "type_:CallMessagesItem": {
      "name": "CallMessagesItem",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "id", "value": "type_:UserMessage" }, "displayName": "User Message" },
          { "type": { "type": "id", "value": "type_:SystemMessage" }, "displayName": "System Message" },
          { "type": { "type": "id", "value": "type_:BotMessage" }, "displayName": "Bot Message" },
          { "type": { "type": "id", "value": "type_:ToolCallMessage" }, "displayName": "Tool Call Message" },
          {
            "type": { "type": "id", "value": "type_:ToolCallResultMessage" },
            "displayName": "Tool Call Result Message"
          }
        ]
      }
    },
    "type_:CallPhoneCallProvider": {
      "description": "This is the provider of the call.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
      "name": "CallPhoneCallProvider",
      "shape": { "type": "enum", "values": [{ "value": "twilio" }, { "value": "vonage" }, { "value": "vapi" }] }
    },
    "type_:CallPhoneCallTransport": {
      "description": "This is the transport of the phone call.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
      "name": "CallPhoneCallTransport",
      "shape": { "type": "enum", "values": [{ "value": "sip" }, { "value": "pstn" }] }
    },
    "type_:CallStatus": {
      "description": "This is the status of the call.",
      "name": "CallStatus",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "queued" },
          { "value": "ringing" },
          { "value": "in-progress" },
          { "value": "forwarding" },
          { "value": "ended" }
        ]
      }
    },
    "type_:CallEndedReason": {
      "description": "This is the explanation for how the call ended.",
      "name": "CallEndedReason",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "assistant-error" },
          { "value": "assistant-not-found" },
          { "value": "db-error" },
          { "value": "no-server-available" },
          { "value": "license-check-failed" },
          { "value": "pipeline-error-openai-llm-failed" },
          { "value": "pipeline-error-azure-openai-llm-failed" },
          { "value": "pipeline-error-groq-llm-failed" },
          { "value": "pipeline-error-anthropic-llm-failed" },
          { "value": "pipeline-error-vapi-llm-failed" },
          { "value": "pipeline-error-vapi-400-bad-request-validation-failed" },
          { "value": "pipeline-error-vapi-401-unauthorized" },
          { "value": "pipeline-error-vapi-403-model-access-denied" },
          { "value": "pipeline-error-vapi-429-exceeded-quota" },
          { "value": "pipeline-error-vapi-500-server-error" },
          { "value": "pipeline-error-openai-voice-failed" },
          { "value": "pipeline-error-cartesia-voice-failed" },
          { "value": "pipeline-error-deepgram-transcriber-failed" },
          { "value": "pipeline-error-deepgram-voice-failed" },
          { "value": "pipeline-error-gladia-transcriber-failed" },
          { "value": "pipeline-error-eleven-labs-voice-failed" },
          { "value": "pipeline-error-playht-voice-failed" },
          { "value": "pipeline-error-lmnt-voice-failed" },
          { "value": "pipeline-error-azure-voice-failed" },
          { "value": "pipeline-error-rime-ai-voice-failed" },
          { "value": "pipeline-error-neets-voice-failed" },
          { "value": "pipeline-no-available-model" },
          { "value": "worker-shutdown" },
          { "value": "unknown-error" },
          { "value": "vonage-disconnected" },
          { "value": "vonage-failed-to-connect-call" },
          { "value": "phone-call-provider-bypass-enabled-but-no-call-received" },
          { "value": "vapifault-phone-call-worker-setup-socket-error" },
          { "value": "vapifault-phone-call-worker-worker-setup-socket-timeout" },
          { "value": "vapifault-phone-call-worker-could-not-find-call" },
          { "value": "vapifault-transport-never-connected" },
          { "value": "vapifault-web-call-worker-setup-failed" },
          { "value": "vapifault-transport-connected-but-call-not-active" },
          { "value": "assistant-not-invalid" },
          { "value": "assistant-not-provided" },
          { "value": "call-start-error-neither-assistant-nor-server-set" },
          { "value": "assistant-request-failed" },
          { "value": "assistant-request-returned-error" },
          { "value": "assistant-request-returned-unspeakable-error" },
          { "value": "assistant-request-returned-invalid-assistant" },
          { "value": "assistant-request-returned-no-assistant" },
          { "value": "assistant-request-returned-forwarding-phone-number" },
          { "value": "assistant-ended-call" },
          { "value": "assistant-said-end-call-phrase" },
          { "value": "assistant-forwarded-call" },
          { "value": "assistant-join-timed-out" },
          { "value": "customer-busy" },
          { "value": "customer-ended-call" },
          { "value": "customer-did-not-answer" },
          { "value": "customer-did-not-give-microphone-permission" },
          { "value": "assistant-said-message-with-end-call-enabled" },
          { "value": "exceeded-max-duration" },
          { "value": "manually-canceled" },
          { "value": "phone-call-provider-closed-websocket" },
          { "value": "pipeline-error-openai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-openai-401-unauthorized" },
          { "value": "pipeline-error-openai-403-model-access-denied" },
          { "value": "pipeline-error-openai-429-exceeded-quota" },
          { "value": "pipeline-error-openai-500-server-error" },
          { "value": "pipeline-error-azure-openai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-azure-openai-401-unauthorized" },
          { "value": "pipeline-error-azure-openai-403-model-access-denied" },
          { "value": "pipeline-error-azure-openai-429-exceeded-quota" },
          { "value": "pipeline-error-azure-openai-500-server-error" },
          { "value": "pipeline-error-groq-400-bad-request-validation-failed" },
          { "value": "pipeline-error-groq-401-unauthorized" },
          { "value": "pipeline-error-groq-403-model-access-denied" },
          { "value": "pipeline-error-groq-429-exceeded-quota" },
          { "value": "pipeline-error-groq-500-server-error" },
          { "value": "pipeline-error-anthropic-400-bad-request-validation-failed" },
          { "value": "pipeline-error-anthropic-401-unauthorized" },
          { "value": "pipeline-error-anthropic-403-model-access-denied" },
          { "value": "pipeline-error-anthropic-429-exceeded-quota" },
          { "value": "pipeline-error-anthropic-500-server-error" },
          { "value": "pipeline-error-together-ai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-together-ai-401-unauthorized" },
          { "value": "pipeline-error-together-ai-403-model-access-denied" },
          { "value": "pipeline-error-together-ai-429-exceeded-quota" },
          { "value": "pipeline-error-together-ai-500-server-error" },
          { "value": "pipeline-error-together-ai-llm-failed" },
          { "value": "pipeline-error-anyscale-400-bad-request-validation-failed" },
          { "value": "pipeline-error-anyscale-401-unauthorized" },
          { "value": "pipeline-error-anyscale-403-model-access-denied" },
          { "value": "pipeline-error-anyscale-429-exceeded-quota" },
          { "value": "pipeline-error-anyscale-500-server-error" },
          { "value": "pipeline-error-anyscale-llm-failed" },
          { "value": "pipeline-error-openrouter-400-bad-request-validation-failed" },
          { "value": "pipeline-error-openrouter-401-unauthorized" },
          { "value": "pipeline-error-openrouter-403-model-access-denied" },
          { "value": "pipeline-error-openrouter-429-exceeded-quota" },
          { "value": "pipeline-error-openrouter-500-server-error" },
          { "value": "pipeline-error-openrouter-llm-failed" },
          { "value": "pipeline-error-perplexity-ai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-perplexity-ai-401-unauthorized" },
          { "value": "pipeline-error-perplexity-ai-403-model-access-denied" },
          { "value": "pipeline-error-perplexity-ai-429-exceeded-quota" },
          { "value": "pipeline-error-perplexity-ai-500-server-error" },
          { "value": "pipeline-error-perplexity-ai-llm-failed" },
          { "value": "pipeline-error-deepinfra-400-bad-request-validation-failed" },
          { "value": "pipeline-error-deepinfra-401-unauthorized" },
          { "value": "pipeline-error-deepinfra-403-model-access-denied" },
          { "value": "pipeline-error-deepinfra-429-exceeded-quota" },
          { "value": "pipeline-error-deepinfra-500-server-error" },
          { "value": "pipeline-error-deepinfra-llm-failed" },
          { "value": "pipeline-error-runpod-400-bad-request-validation-failed" },
          { "value": "pipeline-error-runpod-401-unauthorized" },
          { "value": "pipeline-error-runpod-403-model-access-denied" },
          { "value": "pipeline-error-runpod-429-exceeded-quota" },
          { "value": "pipeline-error-runpod-500-server-error" },
          { "value": "pipeline-error-runpod-llm-failed" },
          { "value": "pipeline-error-custom-llm-400-bad-request-validation-failed" },
          { "value": "pipeline-error-custom-llm-401-unauthorized" },
          { "value": "pipeline-error-custom-llm-403-model-access-denied" },
          { "value": "pipeline-error-custom-llm-429-exceeded-quota" },
          { "value": "pipeline-error-custom-llm-500-server-error" },
          { "value": "pipeline-error-custom-llm-llm-failed" },
          { "value": "pipeline-error-cartesia-socket-hang-up" },
          { "value": "pipeline-error-cartesia-requested-payment" },
          { "value": "pipeline-error-cartesia-500-server-error" },
          { "value": "pipeline-error-cartesia-503-server-error" },
          { "value": "pipeline-error-cartesia-522-server-error" },
          { "value": "pipeline-error-custom-voice-failed" },
          { "value": "pipeline-error-eleven-labs-voice-not-found" },
          { "value": "pipeline-error-eleven-labs-quota-exceeded" },
          { "value": "pipeline-error-eleven-labs-unauthorized-access" },
          { "value": "pipeline-error-eleven-labs-unauthorized-to-access-model" },
          { "value": "pipeline-error-eleven-labs-professional-voices-only-for-creator-plus" },
          { "value": "pipeline-error-eleven-labs-blocked-free-plan-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-blocked-concurrent-requests-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-system-busy-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-voice-not-fine-tuned" },
          { "value": "pipeline-error-eleven-labs-invalid-api-key" },
          { "value": "pipeline-error-eleven-labs-invalid-voice-samples" },
          { "value": "pipeline-error-eleven-labs-voice-disabled-by-owner" },
          { "value": "pipeline-error-eleven-labs-blocked-account-in-probation" },
          { "value": "pipeline-error-eleven-labs-blocked-content-against-their-policy" },
          { "value": "pipeline-error-eleven-labs-missing-samples-for-voice-clone" },
          { "value": "pipeline-error-eleven-labs-voice-not-fine-tuned-and-cannot-be-used" },
          { "value": "pipeline-error-eleven-labs-voice-not-allowed-for-free-users" },
          { "value": "pipeline-error-eleven-labs-500-server-error" },
          { "value": "pipeline-error-eleven-labs-max-character-limit-exceeded" },
          { "value": "pipeline-error-playht-request-timed-out" },
          { "value": "pipeline-error-playht-invalid-voice" },
          { "value": "pipeline-error-playht-unexpected-error" },
          { "value": "pipeline-error-playht-out-of-credits" },
          { "value": "pipeline-error-playht-voice-must-be-a-valid-voice-manifest-uri" },
          { "value": "pipeline-error-playht-401-unauthorized" },
          { "value": "pipeline-error-playht-403-forbidden-out-of-characters" },
          { "value": "pipeline-error-playht-403-forbidden-api-access-not-available" },
          { "value": "pipeline-error-playht-429-exceeded-quota" },
          { "value": "pipeline-error-playht-502-gateway-error" },
          { "value": "pipeline-error-playht-504-gateway-error" },
          { "value": "pipeline-error-deepgram-403-model-access-denied" },
          { "value": "pipeline-error-deepgram-404-not-found" },
          { "value": "pipeline-error-deepgram-400-no-such-model-language-tier-combination" },
          { "value": "pipeline-error-deepgram-500-returning-invalid-json" },
          { "value": "sip-gateway-failed-to-connect-call" },
          { "value": "silence-timed-out" },
          { "value": "twilio-failed-to-connect-call" },
          { "value": "twilio-reported-customer-misdialed" },
          { "value": "voicemail" },
          { "value": "vonage-rejected" }
        ]
      }
    },
    "type_:CallDestination": {
      "description": "This is the destination where the call ended up being transferred to. If the call was not transferred, this will be empty.",
      "name": "CallDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:Call": {
      "name": "Call",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the type of call.",
            "key": "type",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CallType" } }
          },
          {
            "description": "These are the costs of individual components of the call in USD.",
            "key": "costs",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:CallCostsItem" } }
            }
          },
          {
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:CallMessagesItem" } }
            }
          },
          {
            "description": "This is the provider of the call.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
            "key": "phoneCallProvider",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CallPhoneCallProvider" }
            }
          },
          {
            "description": "This is the transport of the phone call.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
            "key": "phoneCallTransport",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:CallPhoneCallTransport" }
            }
          },
          {
            "description": "This is the status of the call.",
            "key": "status",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CallStatus" } }
          },
          {
            "description": "This is the explanation for how the call ended.",
            "key": "endedReason",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CallEndedReason" } }
          },
          {
            "description": "This is the destination where the call ended up being transferred to. If the call was not transferred, this will be empty.",
            "key": "destination",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CallDestination" } }
          },
          {
            "description": "This is the unique identifier for the call.",
            "key": "id",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the unique identifier for the org that this call belongs to.",
            "key": "orgId",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the ISO 8601 date-time string of when the call was created.",
            "key": "createdAt",
            "valueType": {
              "type": "primitive",
              "value": { "type": "datetime", "default": "1970-01-01T00:00:00.000Z" }
            }
          },
          {
            "description": "This is the ISO 8601 date-time string of when the call was last updated.",
            "key": "updatedAt",
            "valueType": {
              "type": "primitive",
              "value": { "type": "datetime", "default": "1970-01-01T00:00:00.000Z" }
            }
          },
          {
            "description": "This is the ISO 8601 date-time string of when the call was started.",
            "key": "startedAt",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "primitive",
                "value": { "type": "datetime", "default": "1970-01-01T00:00:00.000Z" }
              }
            }
          },
          {
            "description": "This is the ISO 8601 date-time string of when the call was ended.",
            "key": "endedAt",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "primitive",
                "value": { "type": "datetime", "default": "1970-01-01T00:00:00.000Z" }
              }
            }
          },
          {
            "description": "This is the cost of the call in USD.",
            "key": "cost",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "This is the cost of the call in USD.",
            "key": "costBreakdown",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CostBreakdown" } }
          },
          {
            "description": "This is a copy of assistant artifact plan. This isn't actually stored on the call but rather just returned in POST /call/web to enable artifact creation client side.",
            "key": "artifactPlan",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:ArtifactPlan" } }
          },
          {
            "description": "This is the analysis of the call. Configure in `assistant.analysisPlan`.",
            "key": "analysis",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Analysis" } }
          },
          {
            "description": "This is to real-time monitor the call. Configure in `assistant.monitorPlan`.",
            "key": "monitor",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Monitor" } }
          },
          {
            "description": "These are the artifacts created from the call. Configure in `assistant.artifactPlan`.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "The ID of the call as provided by the phone number service. callSid in Twilio. conversationUuid in Vonage.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
            "key": "phoneCallProviderId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "These are the overrides for the `assistant` or `assistantId`'s settings and template variables.",
            "key": "assistantOverrides",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:AssistantOverrides" } }
          },
          {
            "description": "This is the squad that will be used for the call. To use a transient squad, use `squad` instead.",
            "key": "squadId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a squad that will be used for the call. To use an existing squad, use `squadId` instead.",
            "key": "squad",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateSquadDto" } }
          },
          {
            "description": "This is the phone number that will be used for the call. To use a transient number, use `phoneNumber` instead.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
            "key": "phoneNumberId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the phone number that will be used for the call. To use an existing number, use `phoneNumberId` instead.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ImportTwilioPhoneNumberDto" }
            }
          },
          {
            "description": "This is the customer that will be called. To call a transient customer , use `customer` instead.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
            "key": "customerId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the customer that will be called. To call an existing customer, use `customerId` instead.\n\nOnly relevant for `outboundPhoneCall` and `inboundPhoneCall` type.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the name of the call. This is just for your own reference.",
            "key": "name",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageAssistantRequestPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageAssistantRequestPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageAssistantRequest": {
      "name": "ServerMessageAssistantRequest",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageAssistantRequestPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageConversationUpdatePhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageConversationUpdatePhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageConversationUpdateMessagesItem": {
      "name": "ServerMessageConversationUpdateMessagesItem",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "id", "value": "type_:UserMessage" }, "displayName": "User Message" },
          { "type": { "type": "id", "value": "type_:SystemMessage" }, "displayName": "System Message" },
          { "type": { "type": "id", "value": "type_:BotMessage" }, "displayName": "Bot Message" },
          { "type": { "type": "id", "value": "type_:ToolCallMessage" }, "displayName": "Tool Call Message" },
          {
            "type": { "type": "id", "value": "type_:ToolCallResultMessage" },
            "displayName": "Tool Call Result Message"
          }
        ]
      }
    },
    "type_:ServerMessageConversationUpdate": {
      "name": "ServerMessageConversationUpdate",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageConversationUpdatePhoneNumber" }
            }
          },
          {
            "description": "This is the most up-to-date conversation history at the time the message is sent.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:ServerMessageConversationUpdateMessagesItem" }
              }
            }
          },
          {
            "description": "This is the most up-to-date conversation history at the time the message is sent, formatted for OpenAI.",
            "key": "messagesOpenAIFormatted",
            "valueType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageEndOfCallReportPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageEndOfCallReportPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageEndOfCallReportEndedReason": {
      "description": "This is the reason the call ended. This can also be found at `call.endedReason` on GET /call/:id.",
      "name": "ServerMessageEndOfCallReportEndedReason",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "assistant-error" },
          { "value": "assistant-not-found" },
          { "value": "db-error" },
          { "value": "no-server-available" },
          { "value": "license-check-failed" },
          { "value": "pipeline-error-openai-llm-failed" },
          { "value": "pipeline-error-azure-openai-llm-failed" },
          { "value": "pipeline-error-groq-llm-failed" },
          { "value": "pipeline-error-anthropic-llm-failed" },
          { "value": "pipeline-error-vapi-llm-failed" },
          { "value": "pipeline-error-vapi-400-bad-request-validation-failed" },
          { "value": "pipeline-error-vapi-401-unauthorized" },
          { "value": "pipeline-error-vapi-403-model-access-denied" },
          { "value": "pipeline-error-vapi-429-exceeded-quota" },
          { "value": "pipeline-error-vapi-500-server-error" },
          { "value": "pipeline-error-openai-voice-failed" },
          { "value": "pipeline-error-cartesia-voice-failed" },
          { "value": "pipeline-error-deepgram-transcriber-failed" },
          { "value": "pipeline-error-deepgram-voice-failed" },
          { "value": "pipeline-error-gladia-transcriber-failed" },
          { "value": "pipeline-error-eleven-labs-voice-failed" },
          { "value": "pipeline-error-playht-voice-failed" },
          { "value": "pipeline-error-lmnt-voice-failed" },
          { "value": "pipeline-error-azure-voice-failed" },
          { "value": "pipeline-error-rime-ai-voice-failed" },
          { "value": "pipeline-error-neets-voice-failed" },
          { "value": "pipeline-no-available-model" },
          { "value": "worker-shutdown" },
          { "value": "unknown-error" },
          { "value": "vonage-disconnected" },
          { "value": "vonage-failed-to-connect-call" },
          { "value": "phone-call-provider-bypass-enabled-but-no-call-received" },
          { "value": "vapifault-phone-call-worker-setup-socket-error" },
          { "value": "vapifault-phone-call-worker-worker-setup-socket-timeout" },
          { "value": "vapifault-phone-call-worker-could-not-find-call" },
          { "value": "vapifault-transport-never-connected" },
          { "value": "vapifault-web-call-worker-setup-failed" },
          { "value": "vapifault-transport-connected-but-call-not-active" },
          { "value": "assistant-not-invalid" },
          { "value": "assistant-not-provided" },
          { "value": "call-start-error-neither-assistant-nor-server-set" },
          { "value": "assistant-request-failed" },
          { "value": "assistant-request-returned-error" },
          { "value": "assistant-request-returned-unspeakable-error" },
          { "value": "assistant-request-returned-invalid-assistant" },
          { "value": "assistant-request-returned-no-assistant" },
          { "value": "assistant-request-returned-forwarding-phone-number" },
          { "value": "assistant-ended-call" },
          { "value": "assistant-said-end-call-phrase" },
          { "value": "assistant-forwarded-call" },
          { "value": "assistant-join-timed-out" },
          { "value": "customer-busy" },
          { "value": "customer-ended-call" },
          { "value": "customer-did-not-answer" },
          { "value": "customer-did-not-give-microphone-permission" },
          { "value": "assistant-said-message-with-end-call-enabled" },
          { "value": "exceeded-max-duration" },
          { "value": "manually-canceled" },
          { "value": "phone-call-provider-closed-websocket" },
          { "value": "pipeline-error-openai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-openai-401-unauthorized" },
          { "value": "pipeline-error-openai-403-model-access-denied" },
          { "value": "pipeline-error-openai-429-exceeded-quota" },
          { "value": "pipeline-error-openai-500-server-error" },
          { "value": "pipeline-error-azure-openai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-azure-openai-401-unauthorized" },
          { "value": "pipeline-error-azure-openai-403-model-access-denied" },
          { "value": "pipeline-error-azure-openai-429-exceeded-quota" },
          { "value": "pipeline-error-azure-openai-500-server-error" },
          { "value": "pipeline-error-groq-400-bad-request-validation-failed" },
          { "value": "pipeline-error-groq-401-unauthorized" },
          { "value": "pipeline-error-groq-403-model-access-denied" },
          { "value": "pipeline-error-groq-429-exceeded-quota" },
          { "value": "pipeline-error-groq-500-server-error" },
          { "value": "pipeline-error-anthropic-400-bad-request-validation-failed" },
          { "value": "pipeline-error-anthropic-401-unauthorized" },
          { "value": "pipeline-error-anthropic-403-model-access-denied" },
          { "value": "pipeline-error-anthropic-429-exceeded-quota" },
          { "value": "pipeline-error-anthropic-500-server-error" },
          { "value": "pipeline-error-together-ai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-together-ai-401-unauthorized" },
          { "value": "pipeline-error-together-ai-403-model-access-denied" },
          { "value": "pipeline-error-together-ai-429-exceeded-quota" },
          { "value": "pipeline-error-together-ai-500-server-error" },
          { "value": "pipeline-error-together-ai-llm-failed" },
          { "value": "pipeline-error-anyscale-400-bad-request-validation-failed" },
          { "value": "pipeline-error-anyscale-401-unauthorized" },
          { "value": "pipeline-error-anyscale-403-model-access-denied" },
          { "value": "pipeline-error-anyscale-429-exceeded-quota" },
          { "value": "pipeline-error-anyscale-500-server-error" },
          { "value": "pipeline-error-anyscale-llm-failed" },
          { "value": "pipeline-error-openrouter-400-bad-request-validation-failed" },
          { "value": "pipeline-error-openrouter-401-unauthorized" },
          { "value": "pipeline-error-openrouter-403-model-access-denied" },
          { "value": "pipeline-error-openrouter-429-exceeded-quota" },
          { "value": "pipeline-error-openrouter-500-server-error" },
          { "value": "pipeline-error-openrouter-llm-failed" },
          { "value": "pipeline-error-perplexity-ai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-perplexity-ai-401-unauthorized" },
          { "value": "pipeline-error-perplexity-ai-403-model-access-denied" },
          { "value": "pipeline-error-perplexity-ai-429-exceeded-quota" },
          { "value": "pipeline-error-perplexity-ai-500-server-error" },
          { "value": "pipeline-error-perplexity-ai-llm-failed" },
          { "value": "pipeline-error-deepinfra-400-bad-request-validation-failed" },
          { "value": "pipeline-error-deepinfra-401-unauthorized" },
          { "value": "pipeline-error-deepinfra-403-model-access-denied" },
          { "value": "pipeline-error-deepinfra-429-exceeded-quota" },
          { "value": "pipeline-error-deepinfra-500-server-error" },
          { "value": "pipeline-error-deepinfra-llm-failed" },
          { "value": "pipeline-error-runpod-400-bad-request-validation-failed" },
          { "value": "pipeline-error-runpod-401-unauthorized" },
          { "value": "pipeline-error-runpod-403-model-access-denied" },
          { "value": "pipeline-error-runpod-429-exceeded-quota" },
          { "value": "pipeline-error-runpod-500-server-error" },
          { "value": "pipeline-error-runpod-llm-failed" },
          { "value": "pipeline-error-custom-llm-400-bad-request-validation-failed" },
          { "value": "pipeline-error-custom-llm-401-unauthorized" },
          { "value": "pipeline-error-custom-llm-403-model-access-denied" },
          { "value": "pipeline-error-custom-llm-429-exceeded-quota" },
          { "value": "pipeline-error-custom-llm-500-server-error" },
          { "value": "pipeline-error-custom-llm-llm-failed" },
          { "value": "pipeline-error-cartesia-socket-hang-up" },
          { "value": "pipeline-error-cartesia-requested-payment" },
          { "value": "pipeline-error-cartesia-500-server-error" },
          { "value": "pipeline-error-cartesia-503-server-error" },
          { "value": "pipeline-error-cartesia-522-server-error" },
          { "value": "pipeline-error-custom-voice-failed" },
          { "value": "pipeline-error-eleven-labs-voice-not-found" },
          { "value": "pipeline-error-eleven-labs-quota-exceeded" },
          { "value": "pipeline-error-eleven-labs-unauthorized-access" },
          { "value": "pipeline-error-eleven-labs-unauthorized-to-access-model" },
          { "value": "pipeline-error-eleven-labs-professional-voices-only-for-creator-plus" },
          { "value": "pipeline-error-eleven-labs-blocked-free-plan-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-blocked-concurrent-requests-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-system-busy-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-voice-not-fine-tuned" },
          { "value": "pipeline-error-eleven-labs-invalid-api-key" },
          { "value": "pipeline-error-eleven-labs-invalid-voice-samples" },
          { "value": "pipeline-error-eleven-labs-voice-disabled-by-owner" },
          { "value": "pipeline-error-eleven-labs-blocked-account-in-probation" },
          { "value": "pipeline-error-eleven-labs-blocked-content-against-their-policy" },
          { "value": "pipeline-error-eleven-labs-missing-samples-for-voice-clone" },
          { "value": "pipeline-error-eleven-labs-voice-not-fine-tuned-and-cannot-be-used" },
          { "value": "pipeline-error-eleven-labs-voice-not-allowed-for-free-users" },
          { "value": "pipeline-error-eleven-labs-500-server-error" },
          { "value": "pipeline-error-eleven-labs-max-character-limit-exceeded" },
          { "value": "pipeline-error-playht-request-timed-out" },
          { "value": "pipeline-error-playht-invalid-voice" },
          { "value": "pipeline-error-playht-unexpected-error" },
          { "value": "pipeline-error-playht-out-of-credits" },
          { "value": "pipeline-error-playht-voice-must-be-a-valid-voice-manifest-uri" },
          { "value": "pipeline-error-playht-401-unauthorized" },
          { "value": "pipeline-error-playht-403-forbidden-out-of-characters" },
          { "value": "pipeline-error-playht-403-forbidden-api-access-not-available" },
          { "value": "pipeline-error-playht-429-exceeded-quota" },
          { "value": "pipeline-error-playht-502-gateway-error" },
          { "value": "pipeline-error-playht-504-gateway-error" },
          { "value": "pipeline-error-deepgram-403-model-access-denied" },
          { "value": "pipeline-error-deepgram-404-not-found" },
          { "value": "pipeline-error-deepgram-400-no-such-model-language-tier-combination" },
          { "value": "pipeline-error-deepgram-500-returning-invalid-json" },
          { "value": "sip-gateway-failed-to-connect-call" },
          { "value": "silence-timed-out" },
          { "value": "twilio-failed-to-connect-call" },
          { "value": "twilio-reported-customer-misdialed" },
          { "value": "voicemail" },
          { "value": "vonage-rejected" }
        ]
      }
    },
    "type_:ServerMessageEndOfCallReportCostsItem": {
      "name": "ServerMessageEndOfCallReportCostsItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "transport",
            "additionalProperties": { "extends": ["type_:TransportCost"], "properties": [] }
          },
          {
            "discriminantValue": "transcriber",
            "additionalProperties": { "extends": ["type_:TranscriberCost"], "properties": [] }
          },
          {
            "discriminantValue": "model",
            "additionalProperties": { "extends": ["type_:ModelCost"], "properties": [] }
          },
          {
            "discriminantValue": "voice",
            "additionalProperties": { "extends": ["type_:VoiceCost"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:VapiCost"], "properties": [] }
          },
          {
            "discriminantValue": "analysis",
            "additionalProperties": { "extends": ["type_:AnalysisCost"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageEndOfCallReport": {
      "name": "ServerMessageEndOfCallReport",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageEndOfCallReportPhoneNumber" }
            }
          },
          {
            "description": "This is the reason the call ended. This can also be found at `call.endedReason` on GET /call/:id.",
            "key": "endedReason",
            "valueType": { "type": "id", "value": "type_:ServerMessageEndOfCallReportEndedReason" }
          },
          {
            "description": "This is the cost of the call in USD. This can also be found at `call.cost` on GET /call/:id.",
            "key": "cost",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "double" } }
            }
          },
          {
            "description": "These are the costs of individual components of the call in USD. This can also be found at `call.costs` on GET /call/:id.",
            "key": "costs",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:ServerMessageEndOfCallReportCostsItem" }
              }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "These are the artifacts from the call. This can also be found at `call.artifact` on GET /call/:id.",
            "key": "artifact",
            "valueType": { "type": "id", "value": "type_:Artifact" }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the analysis of the call. This can also be found at `call.analysis` on GET /call/:id.",
            "key": "analysis",
            "valueType": { "type": "id", "value": "type_:Analysis" }
          },
          {
            "description": "This is the ISO 8601 date-time string of when the call started. This can also be found at `call.startedAt` on GET /call/:id.",
            "key": "startedAt",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "primitive",
                "value": { "type": "datetime", "default": "1970-01-01T00:00:00.000Z" }
              }
            }
          },
          {
            "description": "This is the ISO 8601 date-time string of when the call ended. This can also be found at `call.endedAt` on GET /call/:id.",
            "key": "endedAt",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "primitive",
                "value": { "type": "datetime", "default": "1970-01-01T00:00:00.000Z" }
              }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageHangPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageHangPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageHang": {
      "name": "ServerMessageHang",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageHangPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageModelOutputPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageModelOutputPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageModelOutput": {
      "name": "ServerMessageModelOutput",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageModelOutputPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the output of the model. It can be a token or tool call.",
            "key": "output",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessagePhoneCallControlPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessagePhoneCallControlPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessagePhoneCallControlRequest": {
      "description": "This is the request to control the phone call.",
      "name": "ServerMessagePhoneCallControlRequest",
      "shape": { "type": "enum", "values": [{ "value": "forward" }, { "value": "hang-up" }] }
    },
    "type_:ServerMessagePhoneCallControlDestination": {
      "description": "This is the destination to forward the call to if the request is \"forward\".",
      "name": "ServerMessagePhoneCallControlDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessagePhoneCallControl": {
      "name": "ServerMessagePhoneCallControl",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessagePhoneCallControlPhoneNumber" }
            }
          },
          {
            "description": "This is the request to control the phone call.",
            "key": "request",
            "valueType": { "type": "id", "value": "type_:ServerMessagePhoneCallControlRequest" }
          },
          {
            "description": "This is the destination to forward the call to if the request is \"forward\".",
            "key": "destination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessagePhoneCallControlDestination" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageSpeechUpdatePhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageSpeechUpdatePhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageSpeechUpdateStatus": {
      "description": "This is the status of the speech update.",
      "name": "ServerMessageSpeechUpdateStatus",
      "shape": { "type": "enum", "values": [{ "value": "started" }, { "value": "stopped" }] }
    },
    "type_:ServerMessageSpeechUpdateRole": {
      "description": "This is the role which the speech update is for.",
      "name": "ServerMessageSpeechUpdateRole",
      "shape": { "type": "enum", "values": [{ "value": "assistant" }, { "value": "user" }] }
    },
    "type_:ServerMessageSpeechUpdate": {
      "name": "ServerMessageSpeechUpdate",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageSpeechUpdatePhoneNumber" }
            }
          },
          {
            "description": "This is the status of the speech update.",
            "key": "status",
            "valueType": { "type": "id", "value": "type_:ServerMessageSpeechUpdateStatus" }
          },
          {
            "description": "This is the role which the speech update is for.",
            "key": "role",
            "valueType": { "type": "id", "value": "type_:ServerMessageSpeechUpdateRole" }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageStatusUpdatePhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageStatusUpdatePhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageStatusUpdateStatus": {
      "description": "This is the status of the call.",
      "name": "ServerMessageStatusUpdateStatus",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "queued" },
          { "value": "ringing" },
          { "value": "in-progress" },
          { "value": "forwarding" },
          { "value": "ended" }
        ]
      }
    },
    "type_:ServerMessageStatusUpdateEndedReason": {
      "description": "This is the reason the call ended. This is only sent if the status is \"ended\".",
      "name": "ServerMessageStatusUpdateEndedReason",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "assistant-error" },
          { "value": "assistant-not-found" },
          { "value": "db-error" },
          { "value": "no-server-available" },
          { "value": "license-check-failed" },
          { "value": "pipeline-error-openai-llm-failed" },
          { "value": "pipeline-error-azure-openai-llm-failed" },
          { "value": "pipeline-error-groq-llm-failed" },
          { "value": "pipeline-error-anthropic-llm-failed" },
          { "value": "pipeline-error-vapi-llm-failed" },
          { "value": "pipeline-error-vapi-400-bad-request-validation-failed" },
          { "value": "pipeline-error-vapi-401-unauthorized" },
          { "value": "pipeline-error-vapi-403-model-access-denied" },
          { "value": "pipeline-error-vapi-429-exceeded-quota" },
          { "value": "pipeline-error-vapi-500-server-error" },
          { "value": "pipeline-error-openai-voice-failed" },
          { "value": "pipeline-error-cartesia-voice-failed" },
          { "value": "pipeline-error-deepgram-transcriber-failed" },
          { "value": "pipeline-error-deepgram-voice-failed" },
          { "value": "pipeline-error-gladia-transcriber-failed" },
          { "value": "pipeline-error-eleven-labs-voice-failed" },
          { "value": "pipeline-error-playht-voice-failed" },
          { "value": "pipeline-error-lmnt-voice-failed" },
          { "value": "pipeline-error-azure-voice-failed" },
          { "value": "pipeline-error-rime-ai-voice-failed" },
          { "value": "pipeline-error-neets-voice-failed" },
          { "value": "pipeline-no-available-model" },
          { "value": "worker-shutdown" },
          { "value": "unknown-error" },
          { "value": "vonage-disconnected" },
          { "value": "vonage-failed-to-connect-call" },
          { "value": "phone-call-provider-bypass-enabled-but-no-call-received" },
          { "value": "vapifault-phone-call-worker-setup-socket-error" },
          { "value": "vapifault-phone-call-worker-worker-setup-socket-timeout" },
          { "value": "vapifault-phone-call-worker-could-not-find-call" },
          { "value": "vapifault-transport-never-connected" },
          { "value": "vapifault-web-call-worker-setup-failed" },
          { "value": "vapifault-transport-connected-but-call-not-active" },
          { "value": "assistant-not-invalid" },
          { "value": "assistant-not-provided" },
          { "value": "call-start-error-neither-assistant-nor-server-set" },
          { "value": "assistant-request-failed" },
          { "value": "assistant-request-returned-error" },
          { "value": "assistant-request-returned-unspeakable-error" },
          { "value": "assistant-request-returned-invalid-assistant" },
          { "value": "assistant-request-returned-no-assistant" },
          { "value": "assistant-request-returned-forwarding-phone-number" },
          { "value": "assistant-ended-call" },
          { "value": "assistant-said-end-call-phrase" },
          { "value": "assistant-forwarded-call" },
          { "value": "assistant-join-timed-out" },
          { "value": "customer-busy" },
          { "value": "customer-ended-call" },
          { "value": "customer-did-not-answer" },
          { "value": "customer-did-not-give-microphone-permission" },
          { "value": "assistant-said-message-with-end-call-enabled" },
          { "value": "exceeded-max-duration" },
          { "value": "manually-canceled" },
          { "value": "phone-call-provider-closed-websocket" },
          { "value": "pipeline-error-openai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-openai-401-unauthorized" },
          { "value": "pipeline-error-openai-403-model-access-denied" },
          { "value": "pipeline-error-openai-429-exceeded-quota" },
          { "value": "pipeline-error-openai-500-server-error" },
          { "value": "pipeline-error-azure-openai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-azure-openai-401-unauthorized" },
          { "value": "pipeline-error-azure-openai-403-model-access-denied" },
          { "value": "pipeline-error-azure-openai-429-exceeded-quota" },
          { "value": "pipeline-error-azure-openai-500-server-error" },
          { "value": "pipeline-error-groq-400-bad-request-validation-failed" },
          { "value": "pipeline-error-groq-401-unauthorized" },
          { "value": "pipeline-error-groq-403-model-access-denied" },
          { "value": "pipeline-error-groq-429-exceeded-quota" },
          { "value": "pipeline-error-groq-500-server-error" },
          { "value": "pipeline-error-anthropic-400-bad-request-validation-failed" },
          { "value": "pipeline-error-anthropic-401-unauthorized" },
          { "value": "pipeline-error-anthropic-403-model-access-denied" },
          { "value": "pipeline-error-anthropic-429-exceeded-quota" },
          { "value": "pipeline-error-anthropic-500-server-error" },
          { "value": "pipeline-error-together-ai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-together-ai-401-unauthorized" },
          { "value": "pipeline-error-together-ai-403-model-access-denied" },
          { "value": "pipeline-error-together-ai-429-exceeded-quota" },
          { "value": "pipeline-error-together-ai-500-server-error" },
          { "value": "pipeline-error-together-ai-llm-failed" },
          { "value": "pipeline-error-anyscale-400-bad-request-validation-failed" },
          { "value": "pipeline-error-anyscale-401-unauthorized" },
          { "value": "pipeline-error-anyscale-403-model-access-denied" },
          { "value": "pipeline-error-anyscale-429-exceeded-quota" },
          { "value": "pipeline-error-anyscale-500-server-error" },
          { "value": "pipeline-error-anyscale-llm-failed" },
          { "value": "pipeline-error-openrouter-400-bad-request-validation-failed" },
          { "value": "pipeline-error-openrouter-401-unauthorized" },
          { "value": "pipeline-error-openrouter-403-model-access-denied" },
          { "value": "pipeline-error-openrouter-429-exceeded-quota" },
          { "value": "pipeline-error-openrouter-500-server-error" },
          { "value": "pipeline-error-openrouter-llm-failed" },
          { "value": "pipeline-error-perplexity-ai-400-bad-request-validation-failed" },
          { "value": "pipeline-error-perplexity-ai-401-unauthorized" },
          { "value": "pipeline-error-perplexity-ai-403-model-access-denied" },
          { "value": "pipeline-error-perplexity-ai-429-exceeded-quota" },
          { "value": "pipeline-error-perplexity-ai-500-server-error" },
          { "value": "pipeline-error-perplexity-ai-llm-failed" },
          { "value": "pipeline-error-deepinfra-400-bad-request-validation-failed" },
          { "value": "pipeline-error-deepinfra-401-unauthorized" },
          { "value": "pipeline-error-deepinfra-403-model-access-denied" },
          { "value": "pipeline-error-deepinfra-429-exceeded-quota" },
          { "value": "pipeline-error-deepinfra-500-server-error" },
          { "value": "pipeline-error-deepinfra-llm-failed" },
          { "value": "pipeline-error-runpod-400-bad-request-validation-failed" },
          { "value": "pipeline-error-runpod-401-unauthorized" },
          { "value": "pipeline-error-runpod-403-model-access-denied" },
          { "value": "pipeline-error-runpod-429-exceeded-quota" },
          { "value": "pipeline-error-runpod-500-server-error" },
          { "value": "pipeline-error-runpod-llm-failed" },
          { "value": "pipeline-error-custom-llm-400-bad-request-validation-failed" },
          { "value": "pipeline-error-custom-llm-401-unauthorized" },
          { "value": "pipeline-error-custom-llm-403-model-access-denied" },
          { "value": "pipeline-error-custom-llm-429-exceeded-quota" },
          { "value": "pipeline-error-custom-llm-500-server-error" },
          { "value": "pipeline-error-custom-llm-llm-failed" },
          { "value": "pipeline-error-cartesia-socket-hang-up" },
          { "value": "pipeline-error-cartesia-requested-payment" },
          { "value": "pipeline-error-cartesia-500-server-error" },
          { "value": "pipeline-error-cartesia-503-server-error" },
          { "value": "pipeline-error-cartesia-522-server-error" },
          { "value": "pipeline-error-custom-voice-failed" },
          { "value": "pipeline-error-eleven-labs-voice-not-found" },
          { "value": "pipeline-error-eleven-labs-quota-exceeded" },
          { "value": "pipeline-error-eleven-labs-unauthorized-access" },
          { "value": "pipeline-error-eleven-labs-unauthorized-to-access-model" },
          { "value": "pipeline-error-eleven-labs-professional-voices-only-for-creator-plus" },
          { "value": "pipeline-error-eleven-labs-blocked-free-plan-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-blocked-concurrent-requests-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-system-busy-and-requested-upgrade" },
          { "value": "pipeline-error-eleven-labs-voice-not-fine-tuned" },
          { "value": "pipeline-error-eleven-labs-invalid-api-key" },
          { "value": "pipeline-error-eleven-labs-invalid-voice-samples" },
          { "value": "pipeline-error-eleven-labs-voice-disabled-by-owner" },
          { "value": "pipeline-error-eleven-labs-blocked-account-in-probation" },
          { "value": "pipeline-error-eleven-labs-blocked-content-against-their-policy" },
          { "value": "pipeline-error-eleven-labs-missing-samples-for-voice-clone" },
          { "value": "pipeline-error-eleven-labs-voice-not-fine-tuned-and-cannot-be-used" },
          { "value": "pipeline-error-eleven-labs-voice-not-allowed-for-free-users" },
          { "value": "pipeline-error-eleven-labs-500-server-error" },
          { "value": "pipeline-error-eleven-labs-max-character-limit-exceeded" },
          { "value": "pipeline-error-playht-request-timed-out" },
          { "value": "pipeline-error-playht-invalid-voice" },
          { "value": "pipeline-error-playht-unexpected-error" },
          { "value": "pipeline-error-playht-out-of-credits" },
          { "value": "pipeline-error-playht-voice-must-be-a-valid-voice-manifest-uri" },
          { "value": "pipeline-error-playht-401-unauthorized" },
          { "value": "pipeline-error-playht-403-forbidden-out-of-characters" },
          { "value": "pipeline-error-playht-403-forbidden-api-access-not-available" },
          { "value": "pipeline-error-playht-429-exceeded-quota" },
          { "value": "pipeline-error-playht-502-gateway-error" },
          { "value": "pipeline-error-playht-504-gateway-error" },
          { "value": "pipeline-error-deepgram-403-model-access-denied" },
          { "value": "pipeline-error-deepgram-404-not-found" },
          { "value": "pipeline-error-deepgram-400-no-such-model-language-tier-combination" },
          { "value": "pipeline-error-deepgram-500-returning-invalid-json" },
          { "value": "sip-gateway-failed-to-connect-call" },
          { "value": "silence-timed-out" },
          { "value": "twilio-failed-to-connect-call" },
          { "value": "twilio-reported-customer-misdialed" },
          { "value": "voicemail" },
          { "value": "vonage-rejected" }
        ]
      }
    },
    "type_:ServerMessageStatusUpdateMessagesItem": {
      "name": "ServerMessageStatusUpdateMessagesItem",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "id", "value": "type_:UserMessage" }, "displayName": "User Message" },
          { "type": { "type": "id", "value": "type_:SystemMessage" }, "displayName": "System Message" },
          { "type": { "type": "id", "value": "type_:BotMessage" }, "displayName": "Bot Message" },
          { "type": { "type": "id", "value": "type_:ToolCallMessage" }, "displayName": "Tool Call Message" },
          {
            "type": { "type": "id", "value": "type_:ToolCallResultMessage" },
            "displayName": "Tool Call Result Message"
          }
        ]
      }
    },
    "type_:ServerMessageStatusUpdateDestination": {
      "description": "This is the destination the call is being transferred to. This is only sent if the status is \"forwarding\".",
      "name": "ServerMessageStatusUpdateDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageStatusUpdate": {
      "name": "ServerMessageStatusUpdate",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageStatusUpdatePhoneNumber" }
            }
          },
          {
            "description": "This is the status of the call.",
            "key": "status",
            "valueType": { "type": "id", "value": "type_:ServerMessageStatusUpdateStatus" }
          },
          {
            "description": "This is the reason the call ended. This is only sent if the status is \"ended\".",
            "key": "endedReason",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageStatusUpdateEndedReason" }
            }
          },
          {
            "description": "These are the conversation messages of the call. This is only sent if the status is \"forwarding\".",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:ServerMessageStatusUpdateMessagesItem" }
              }
            }
          },
          {
            "description": "These are the conversation messages of the call. This is only sent if the status is \"forwarding\".",
            "key": "messagesOpenAIFormatted",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
            }
          },
          {
            "description": "This is the destination the call is being transferred to. This is only sent if the status is \"forwarding\".",
            "key": "destination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageStatusUpdateDestination" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the transcript of the call. This is only sent if the status is \"forwarding\".",
            "key": "transcript",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the inbound phone call debugging artifacts. This is only sent if the status is \"ended\" and there was an error accepting the inbound phone call.\n\nThis will include any errors related to the \"assistant-request\" if one was made.",
            "key": "inboundPhoneCallDebuggingArtifacts",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "map",
                "keyType": { "type": "primitive", "value": { "type": "string" } },
                "valueType": { "type": "unknown" }
              }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolCallFunction": {
      "name": "ToolCallFunction",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the name of the function the model called.",
            "key": "name",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "These are the arguments that the function was called with.",
            "key": "arguments",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolCall": {
      "name": "ToolCall",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the type of tool the model called.",
            "key": "type",
            "valueType": { "type": "literal", "value": { "type": "stringLiteral", "value": "function" } }
          },
          {
            "description": "This is the function the model called.",
            "key": "function",
            "valueType": { "type": "id", "value": "type_:ToolCallFunction" }
          },
          {
            "description": "This is the unique identifier for the tool call.",
            "key": "id",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:FunctionToolWithToolCallMessagesItem": {
      "name": "FunctionToolWithToolCallMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:FunctionToolWithToolCall": {
      "name": "FunctionToolWithToolCall",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:FunctionToolWithToolCallMessagesItem" }
              }
            }
          },
          { "key": "toolCall", "valueType": { "type": "id", "value": "type_:ToolCall" } },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:GhlToolWithToolCallMessagesItem": {
      "name": "GhlToolWithToolCallMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:GhlToolWithToolCall": {
      "name": "GhlToolWithToolCall",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:GhlToolWithToolCallMessagesItem" }
              }
            }
          },
          { "key": "toolCall", "valueType": { "type": "id", "value": "type_:ToolCall" } },
          { "key": "metadata", "valueType": { "type": "id", "value": "type_:GhlToolMetadata" } },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:MakeToolWithToolCallMessagesItem": {
      "name": "MakeToolWithToolCallMessagesItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-start",
            "additionalProperties": { "extends": ["type_:ToolMessageStart"], "properties": [] }
          },
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          },
          {
            "discriminantValue": "request-response-delayed",
            "additionalProperties": { "extends": ["type_:ToolMessageDelayed"], "properties": [] }
          }
        ]
      }
    },
    "type_:MakeToolWithToolCall": {
      "name": "MakeToolWithToolCall",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This determines if the tool is async.\n\nIf async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.\n\nIf sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.\n\nDefaults to synchronous (`false`).",
            "key": "async",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          },
          {
            "description": "These are the messages that will be spoken to the user as the tool is running.\n\nFor some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:MakeToolWithToolCallMessagesItem" }
              }
            }
          },
          { "key": "toolCall", "valueType": { "type": "id", "value": "type_:ToolCall" } },
          { "key": "metadata", "valueType": { "type": "id", "value": "type_:MakeToolMetadata" } },
          {
            "description": "This is the function definition of the tool.\n\nFor `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.\n\nAn example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument \"reason\". Then, in `messages` array, you can have many \"request-complete\" messages. One of these messages will be triggered if the `messages[].conditions` matches the \"reason\" argument.",
            "key": "function",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:OpenAiFunction" } }
          },
          {
            "description": "This is the server that will be hit when this tool is requested by the model.\n\nAll requests will be sent with the call object among other things. You can find more details in the Server URL documentation.\n\nThis overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.",
            "key": "server",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Server" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageToolCallsPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageToolCallsPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageToolCallsToolWithToolCallListItem": {
      "name": "ServerMessageToolCallsToolWithToolCallListItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:FunctionToolWithToolCall"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:GhlToolWithToolCall"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:MakeToolWithToolCall"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageToolCalls": {
      "name": "ServerMessageToolCalls",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageToolCallsPhoneNumber" }
            }
          },
          {
            "description": "This is the list of tools calls that the model is requesting along with the original tool configuration.",
            "key": "toolWithToolCallList",
            "valueType": {
              "type": "list",
              "itemType": { "type": "id", "value": "type_:ServerMessageToolCallsToolWithToolCallListItem" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the list of tool calls that the model is requesting.",
            "key": "toolCallList",
            "valueType": { "type": "list", "itemType": { "type": "id", "value": "type_:ToolCall" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageTransferDestinationRequestPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageTransferDestinationRequestPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageTransferDestinationRequest": {
      "name": "ServerMessageTransferDestinationRequest",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageTransferDestinationRequestPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageTransferUpdatePhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageTransferUpdatePhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageTransferUpdateDestination": {
      "description": "This is the destination of the transfer.",
      "name": "ServerMessageTransferUpdateDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "assistant",
            "additionalProperties": { "extends": ["type_:TransferDestinationAssistant"], "properties": [] }
          },
          {
            "discriminantValue": "step",
            "additionalProperties": { "extends": ["type_:TransferDestinationStep"], "properties": [] }
          },
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageTransferUpdate": {
      "name": "ServerMessageTransferUpdate",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageTransferUpdatePhoneNumber" }
            }
          },
          {
            "description": "This is the destination of the transfer.",
            "key": "destination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageTransferUpdateDestination" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the assistant that the call is being transferred to. This is only sent if `destination.type` is \"assistant\".",
            "key": "toAssistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the assistant that the call is being transferred from. This is only sent if `destination.type` is \"assistant\".",
            "key": "fromAssistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageTranscriptPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageTranscriptPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageTranscriptRole": {
      "description": "This is the role for which the transcript is for.",
      "name": "ServerMessageTranscriptRole",
      "shape": { "type": "enum", "values": [{ "value": "assistant" }, { "value": "user" }] }
    },
    "type_:ServerMessageTranscriptTranscriptType": {
      "description": "This is the type of the transcript.",
      "name": "ServerMessageTranscriptTranscriptType",
      "shape": { "type": "enum", "values": [{ "value": "partial" }, { "value": "final" }] }
    },
    "type_:ServerMessageTranscript": {
      "name": "ServerMessageTranscript",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageTranscriptPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the role for which the transcript is for.",
            "key": "role",
            "valueType": { "type": "id", "value": "type_:ServerMessageTranscriptRole" }
          },
          {
            "description": "This is the type of the transcript.",
            "key": "transcriptType",
            "valueType": { "type": "id", "value": "type_:ServerMessageTranscriptTranscriptType" }
          },
          {
            "description": "This is the transcript content.",
            "key": "transcript",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageUserInterruptedPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageUserInterruptedPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageUserInterrupted": {
      "name": "ServerMessageUserInterrupted",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageUserInterruptedPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageLanguageChangedPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageLanguageChangedPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageLanguageChanged": {
      "name": "ServerMessageLanguageChanged",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageLanguageChangedPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the language the transcriber is switched to.",
            "key": "language",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageVoiceInputPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageVoiceInputPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageVoiceInput": {
      "name": "ServerMessageVoiceInput",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageVoiceInputPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the voice input content",
            "key": "input",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageVoiceRequestPhoneNumber": {
      "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
      "name": "ServerMessageVoiceRequestPhoneNumber",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "provider",
        "variants": [
          {
            "discriminantValue": "byo-phone-number",
            "additionalProperties": { "extends": ["type_:CreateByoPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "twilio",
            "additionalProperties": { "extends": ["type_:CreateTwilioPhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vonage",
            "additionalProperties": { "extends": ["type_:CreateVonagePhoneNumberDto"], "properties": [] }
          },
          {
            "discriminantValue": "vapi",
            "additionalProperties": { "extends": ["type_:CreateVapiPhoneNumberDto"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageVoiceRequest": {
      "name": "ServerMessageVoiceRequest",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the phone number associated with the call.\n\nThis matches one of the following:\n\n- `call.phoneNumber`,\n- `call.phoneNumberId`.",
            "key": "phoneNumber",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageVoiceRequestPhoneNumber" }
            }
          },
          {
            "description": "This is the ISO-8601 formatted timestamp of when the message was sent.",
            "key": "timestamp",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a live version of the `call.artifact`.\n\nThis matches what is stored on `call.artifact` after the call.",
            "key": "artifact",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Artifact" } }
          },
          {
            "description": "This is the assistant that is currently active. This is provided for convenience.\n\nThis matches one of the following:\n\n- `call.assistant`,\n- `call.assistantId`,\n- `call.squad[n].assistant`,\n- `call.squad[n].assistantId`,\n- `call.squadId->[n].assistant`,\n- `call.squadId->[n].assistantId`.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "This is the customer associated with the call.\n\nThis matches one of the following:\n\n- `call.customer`,\n- `call.customerId`.",
            "key": "customer",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateCustomerDto" } }
          },
          {
            "description": "This is the call object.\n\nThis matches what was returned in POST /call.\n\nNote: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.",
            "key": "call",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:Call" } }
          },
          {
            "description": "This is the text to be synthesized.",
            "key": "text",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the sample rate to be synthesized.",
            "key": "sampleRate",
            "valueType": { "type": "primitive", "value": { "type": "double" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageResponseAssistantRequestDestination": {
      "description": "This is the destination to transfer the inbound call to. This will immediately transfer without using any assistants.\n\nIf this is sent, `assistantId`, `assistant`, `squadId`, and `squad` are ignored.",
      "name": "ServerMessageResponseAssistantRequestDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageResponseAssistantRequest": {
      "name": "ServerMessageResponseAssistantRequest",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the destination to transfer the inbound call to. This will immediately transfer without using any assistants.\n\nIf this is sent, `assistantId`, `assistant`, `squadId`, and `squad` are ignored.",
            "key": "destination",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "id", "value": "type_:ServerMessageResponseAssistantRequestDestination" }
            }
          },
          {
            "description": "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead.",
            "key": "assistantId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead.\n\nIf you're unsure why you're getting an invalid assistant, try logging your response and send the JSON blob to POST /assistant which will return the validation errors.",
            "key": "assistant",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateAssistantDto" } }
          },
          {
            "description": "These are the overrides for the `assistant` or `assistantId`'s settings and template variables.",
            "key": "assistantOverrides",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:AssistantOverrides" } }
          },
          {
            "description": "This is the squad that will be used for the call. To use a transient squad, use `squad` instead.",
            "key": "squadId",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is a squad that will be used for the call. To use an existing squad, use `squadId` instead.",
            "key": "squad",
            "valueType": { "type": "optional", "itemType": { "type": "id", "value": "type_:CreateSquadDto" } }
          },
          {
            "description": "This is the error if the call shouldn't be accepted. This is spoken to the customer.\n\nIf this is sent, `assistantId`, `assistant`, `squadId`, `squad`, and `destination` are ignored.",
            "key": "error",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ToolCallResultMessageItem": {
      "name": "ToolCallResultMessageItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "request-complete",
            "additionalProperties": { "extends": ["type_:ToolMessageComplete"], "properties": [] }
          },
          {
            "discriminantValue": "request-failed",
            "additionalProperties": { "extends": ["type_:ToolMessageFailed"], "properties": [] }
          }
        ]
      }
    },
    "type_:ToolCallResult": {
      "name": "ToolCallResult",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the message that will be spoken to the user.\n\nIf this is not returned, assistant will speak:\n\n1. a `request-complete` or `request-failed` message from `tool.messages`, if it exists\n2. a response generated by the model, if not",
            "key": "message",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:ToolCallResultMessageItem" }
              }
            }
          },
          {
            "description": "This is the name of the function the model called.",
            "key": "name",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the unique identifier for the tool call.",
            "key": "toolCallId",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          },
          {
            "description": "This is the result if the tool call was successful. This is added to the conversation history.\n\nFurther, if this is returned, assistant will speak:\n\n1. the `message`, if it exists and is of type `request-complete`\n2. a `request-complete` message from `tool.messages`, if it exists\n3. a response generated by the model, if neither exist",
            "key": "result",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the error if the tool call was not successful. This is added to the conversation history.\n\nFurther, if this is returned, assistant will speak:\n\n1. the `message`, if it exists and is of type `request-failed`\n2. a `request-failed` message from `tool.messages`, if it exists\n3. a response generated by the model, if neither exist",
            "key": "error",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageResponseToolCalls": {
      "name": "ServerMessageResponseToolCalls",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the results of the \"tool-calls\" message.",
            "key": "results",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "list", "itemType": { "type": "id", "value": "type_:ToolCallResult" } }
            }
          },
          {
            "description": "This is the error message if the tool call was not successful.",
            "key": "error",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageResponseTransferDestinationRequestDestination": {
      "description": "This is the destination you'd like the call to be transferred to.",
      "name": "ServerMessageResponseTransferDestinationRequestDestination",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "assistant",
            "additionalProperties": { "extends": ["type_:TransferDestinationAssistant"], "properties": [] }
          },
          {
            "discriminantValue": "step",
            "additionalProperties": { "extends": ["type_:TransferDestinationStep"], "properties": [] }
          },
          {
            "discriminantValue": "number",
            "additionalProperties": { "extends": ["type_:TransferDestinationNumber"], "properties": [] }
          },
          {
            "discriminantValue": "sip",
            "additionalProperties": { "extends": ["type_:TransferDestinationSip"], "properties": [] }
          }
        ]
      }
    },
    "type_:ServerMessageResponseTransferDestinationRequest": {
      "name": "ServerMessageResponseTransferDestinationRequest",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the destination you'd like the call to be transferred to.",
            "key": "destination",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "id",
                "value": "type_:ServerMessageResponseTransferDestinationRequestDestination"
              }
            }
          },
          {
            "description": "This is the error message if the transfer should not be made.",
            "key": "error",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageResponseVoiceRequest": {
      "name": "ServerMessageResponseVoiceRequest",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "DO NOT respond to a `voice-request` webhook with this schema of { data }. This schema just exists to document what the response should look like. Follow these instructions:\n\nHere is what the request will look like:\n\nPOST https://{assistant.voice.server.url}\nContent-Type: application/json\n\n{\n\"messsage\": {\n\"type\": \"voice-request\",\n\"text\": \"Hello, world!\",\n\"sampleRate\": 24000,\n...other metadata about the call...\n}\n}\n\nThe expected response is 1-channel 16-bit raw PCM audio at the sample rate specified in the request. Here is how the response will be piped to the transport:\n\n```\nresponse.on('data', (chunk: Buffer) => {\n  outputStream.write(chunk);\n});\n```",
            "key": "data",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ServerMessageResponseMessageResponse": {
      "description": "This is the response that is expected from the server to the message.\n\nNote: Most messages don't expect a response. Only \"assistant-request\", \"tool-calls\" and \"transfer-destination-request\" do.",
      "name": "ServerMessageResponseMessageResponse",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          {
            "type": { "type": "id", "value": "type_:ServerMessageResponseAssistantRequest" },
            "displayName": "Server Message Response Assistant Request"
          },
          {
            "type": { "type": "id", "value": "type_:ServerMessageResponseToolCalls" },
            "displayName": "Server Message Response Tool Calls"
          },
          {
            "type": { "type": "id", "value": "type_:ServerMessageResponseTransferDestinationRequest" },
            "displayName": "Server Message Response Transfer Destination Request"
          },
          {
            "type": { "type": "id", "value": "type_:ServerMessageResponseVoiceRequest" },
            "displayName": "Server Message Response Voice Request"
          }
        ]
      }
    },
    "type_:ServerMessageResponse": {
      "name": "ServerMessageResponse",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the response that is expected from the server to the message.\n\nNote: Most messages don't expect a response. Only \"assistant-request\", \"tool-calls\" and \"transfer-destination-request\" do.",
            "key": "messageResponse",
            "valueType": { "type": "id", "value": "type_:ServerMessageResponseMessageResponse" }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageConversationUpdateMessagesItem": {
      "name": "ClientMessageConversationUpdateMessagesItem",
      "shape": {
        "type": "undiscriminatedUnion",
        "variants": [
          { "type": { "type": "id", "value": "type_:UserMessage" }, "displayName": "User Message" },
          { "type": { "type": "id", "value": "type_:SystemMessage" }, "displayName": "System Message" },
          { "type": { "type": "id", "value": "type_:BotMessage" }, "displayName": "Bot Message" },
          { "type": { "type": "id", "value": "type_:ToolCallMessage" }, "displayName": "Tool Call Message" },
          {
            "type": { "type": "id", "value": "type_:ToolCallResultMessage" },
            "displayName": "Tool Call Result Message"
          }
        ]
      }
    },
    "type_:ClientMessageConversationUpdate": {
      "name": "ClientMessageConversationUpdate",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the most up-to-date conversation history at the time the message is sent.",
            "key": "messages",
            "valueType": {
              "type": "optional",
              "itemType": {
                "type": "list",
                "itemType": { "type": "id", "value": "type_:ClientMessageConversationUpdateMessagesItem" }
              }
            }
          },
          {
            "description": "This is the most up-to-date conversation history at the time the message is sent, formatted for OpenAI.",
            "key": "messagesOpenAIFormatted",
            "valueType": { "type": "list", "itemType": { "type": "id", "value": "type_:OpenAiMessage" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageHang": {
      "name": "ClientMessageHang",
      "shape": { "type": "object", "extends": [], "properties": [], "extraProperties": { "type": "unknown" } }
    },
    "type_:ClientMessageMetadata": {
      "name": "ClientMessageMetadata",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the metadata content",
            "key": "metadata",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageModelOutput": {
      "name": "ClientMessageModelOutput",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the output of the model. It can be a token or tool call.",
            "key": "output",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageSpeechUpdateStatus": {
      "description": "This is the status of the speech update.",
      "name": "ClientMessageSpeechUpdateStatus",
      "shape": { "type": "enum", "values": [{ "value": "started" }, { "value": "stopped" }] }
    },
    "type_:ClientMessageSpeechUpdateRole": {
      "description": "This is the role which the speech update is for.",
      "name": "ClientMessageSpeechUpdateRole",
      "shape": { "type": "enum", "values": [{ "value": "assistant" }, { "value": "user" }] }
    },
    "type_:ClientMessageSpeechUpdate": {
      "name": "ClientMessageSpeechUpdate",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the status of the speech update.",
            "key": "status",
            "valueType": { "type": "id", "value": "type_:ClientMessageSpeechUpdateStatus" }
          },
          {
            "description": "This is the role which the speech update is for.",
            "key": "role",
            "valueType": { "type": "id", "value": "type_:ClientMessageSpeechUpdateRole" }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageTranscriptRole": {
      "description": "This is the role for which the transcript is for.",
      "name": "ClientMessageTranscriptRole",
      "shape": { "type": "enum", "values": [{ "value": "assistant" }, { "value": "user" }] }
    },
    "type_:ClientMessageTranscriptTranscriptType": {
      "description": "This is the type of the transcript.",
      "name": "ClientMessageTranscriptTranscriptType",
      "shape": { "type": "enum", "values": [{ "value": "partial" }, { "value": "final" }] }
    },
    "type_:ClientMessageTranscript": {
      "name": "ClientMessageTranscript",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the role for which the transcript is for.",
            "key": "role",
            "valueType": { "type": "id", "value": "type_:ClientMessageTranscriptRole" }
          },
          {
            "description": "This is the type of the transcript.",
            "key": "transcriptType",
            "valueType": { "type": "id", "value": "type_:ClientMessageTranscriptTranscriptType" }
          },
          {
            "description": "This is the transcript content.",
            "key": "transcript",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageToolCallsToolWithToolCallListItem": {
      "name": "ClientMessageToolCallsToolWithToolCallListItem",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "function",
            "additionalProperties": { "extends": ["type_:FunctionToolWithToolCall"], "properties": [] }
          },
          {
            "discriminantValue": "ghl",
            "additionalProperties": { "extends": ["type_:GhlToolWithToolCall"], "properties": [] }
          },
          {
            "discriminantValue": "make",
            "additionalProperties": { "extends": ["type_:MakeToolWithToolCall"], "properties": [] }
          }
        ]
      }
    },
    "type_:ClientMessageToolCalls": {
      "name": "ClientMessageToolCalls",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the list of tools calls that the model is requesting along with the original tool configuration.",
            "key": "toolWithToolCallList",
            "valueType": {
              "type": "list",
              "itemType": { "type": "id", "value": "type_:ClientMessageToolCallsToolWithToolCallListItem" }
            }
          },
          {
            "description": "This is the list of tool calls that the model is requesting.",
            "key": "toolCallList",
            "valueType": { "type": "list", "itemType": { "type": "id", "value": "type_:ToolCall" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageToolCallsResult": {
      "name": "ClientMessageToolCallsResult",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the result of the tool call.",
            "key": "toolCallResult",
            "valueType": {
              "type": "map",
              "keyType": { "type": "primitive", "value": { "type": "string" } },
              "valueType": { "type": "unknown" }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageUserInterrupted": {
      "name": "ClientMessageUserInterrupted",
      "shape": { "type": "object", "extends": [], "properties": [], "extraProperties": { "type": "unknown" } }
    },
    "type_:ClientMessageLanguageChanged": {
      "name": "ClientMessageLanguageChanged",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the language the transcriber is switched to.",
            "key": "language",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientMessageVoiceInput": {
      "name": "ClientMessageVoiceInput",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the voice input content",
            "key": "input",
            "valueType": { "type": "primitive", "value": { "type": "string" } }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientInboundMessageAddMessage": {
      "name": "ClientInboundMessageAddMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the message to add to the conversation.",
            "key": "message",
            "valueType": { "type": "id", "value": "type_:OpenAiMessage" }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientInboundMessageControlControl": {
      "description": "This is the control action",
      "name": "ClientInboundMessageControlControl",
      "shape": {
        "type": "enum",
        "values": [{ "value": "mute-assistant" }, { "value": "unmute-assistant" }, { "value": "say-first-message" }]
      }
    },
    "type_:ClientInboundMessageControl": {
      "name": "ClientInboundMessageControl",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the control action",
            "key": "control",
            "valueType": { "type": "id", "value": "type_:ClientInboundMessageControlControl" }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientInboundMessageSay": {
      "name": "ClientInboundMessageSay",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "This is the content to say.",
            "key": "content",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "string" } }
            }
          },
          {
            "description": "This is the flag to end call after content is spoken.",
            "key": "endCallAfterSpoken",
            "valueType": {
              "type": "optional",
              "itemType": { "type": "primitive", "value": { "type": "boolean", "default": false } }
            }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:ClientInboundMessageMessage": {
      "description": "These are the messages that can be sent from client-side SDKs to control the call.",
      "name": "ClientInboundMessageMessage",
      "shape": {
        "type": "discriminatedUnion",
        "discriminant": "type",
        "variants": [
          {
            "discriminantValue": "add-message",
            "additionalProperties": { "extends": ["type_:ClientInboundMessageAddMessage"], "properties": [] }
          },
          {
            "discriminantValue": "control",
            "additionalProperties": { "extends": ["type_:ClientInboundMessageControl"], "properties": [] }
          },
          {
            "discriminantValue": "say",
            "additionalProperties": { "extends": ["type_:ClientInboundMessageSay"], "properties": [] }
          }
        ]
      }
    },
    "type_:ClientInboundMessage": {
      "name": "ClientInboundMessage",
      "shape": {
        "type": "object",
        "extends": [],
        "properties": [
          {
            "description": "These are the messages that can be sent from client-side SDKs to control the call.",
            "key": "message",
            "valueType": { "type": "id", "value": "type_:ClientInboundMessageMessage" }
          }
        ],
        "extraProperties": { "type": "unknown" }
      }
    },
    "type_:DeepgramTranscriberLanguage": {
      "name": "DeepgramTranscriberLanguage",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "bg" },
          { "value": "ca" },
          { "value": "cs" },
          { "value": "da" },
          { "value": "da-DK" },
          { "value": "de" },
          { "value": "de-CH" },
          { "value": "el" },
          { "value": "en" },
          { "value": "en-AU" },
          { "value": "en-GB" },
          { "value": "en-IN" },
          { "value": "en-NZ" },
          { "value": "en-US" },
          { "value": "es" },
          { "value": "es-419" },
          { "value": "es-LATAM" },
          { "value": "et" },
          { "value": "fi" },
          { "value": "fr" },
          { "value": "fr-CA" },
          { "value": "hi" },
          { "value": "hi-Latn" },
          { "value": "hu" },
          { "value": "id" },
          { "value": "it" },
          { "value": "ja" },
          { "value": "ko" },
          { "value": "ko-KR" },
          { "value": "lt" },
          { "value": "lv" },
          { "value": "ms" },
          { "value": "multi" },
          { "value": "nl" },
          { "value": "nl-BE" },
          { "value": "no" },
          { "value": "pl" },
          { "value": "pt" },
          { "value": "pt-BR" },
          { "value": "ro" },
          { "value": "ru" },
          { "value": "sk" },
          { "value": "sv" },
          { "value": "sv-SE" },
          { "value": "ta" },
          { "value": "taq" },
          { "value": "th" },
          { "value": "th-TH" },
          { "value": "tr" },
          { "value": "uk" },
          { "value": "vi" },
          { "value": "zh" },
          { "value": "zh-CN" },
          { "value": "zh-Hans" },
          { "value": "zh-Hant" },
          { "value": "zh-TW" }
        ]
      }
    },
    "type_:DeepgramTranscriberModel": {
      "name": "DeepgramTranscriberModel",
      "shape": {
        "type": "enum",
        "values": [
          { "value": "nova-2" },
          { "value": "nova-2-general" },
          { "value": "nova-2-meeting" },
          { "value": "nova-2-phonecall" },
          { "value": "nova-2-finance" },
          { "value": "nova-2-conversationalai" },
          { "value": "nova-2-voicemail" },
          { "value": "nova-2-video" },
          { "value": "nova-2-medical" },
          { "value": "nova-2-drivethru" },
          { "value": "nova-2-automotive" },
          { "value": "nova" },
          { "value": "nova-general" },
          { "value": "nova-phonecall" },
          { "value": "nova-medical" },
          { "value": "enhanced" },
          { "value": "enhanced-general" },
          { "value": "enhanced-meeting" },
          { "value": "enhanced-phonecall" },
          { "value": "enhanced-finance" },
          { "value": "base" },
          { "value": "base-general" },
          { "value": "base-meeting" },
          { "value": "base-phonecall" },
          { "value": "base-finance" },
          { "value": "base-conversationalai" },
          { "value": "base-voicemail" },
          { "value": "base-video" }
        ]
      }
    },
    "type_:TransferMode": {
      "name": "TransferMode",
      "shape": {
        "type": "enum",
        "values": [{ "value": "rolling-history" }, { "value": "swap-system-message-in-history" }]
      }
    },
    "type_:PunctuationBoundary": {
      "name": "PunctuationBoundary",
      "shape": {
        "type": "enum",
        "values": [
          { "description": "。", "value": "。" },
          { "description": "，", "value": "，" },
          { "description": ".", "value": "." },
          { "description": "!", "value": "!" },
          { "description": "?", "value": "?" },
          { "description": ";", "value": ";" },
          { "description": ")", "value": ")" },
          { "description": "،", "value": "،" },
          { "description": "۔", "value": "۔" },
          { "description": "।", "value": "।" },
          { "description": "॥", "value": "॥" },
          { "description": "|", "value": "|" },
          { "description": "||", "value": "||" },
          { "description": ",", "value": "," },
          { "description": ":", "value": ":" }
        ]
      }
    }
  },
  "subpackages": {},
  "auth": { "type": "bearerAuth", "tokenName": "apiKey" },
  "hasMultipleBaseUrls": false,
  "globalHeaders": []
}
