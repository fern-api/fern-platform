[
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.welcome.welcome-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/welcome/welcome",
    "pathname": "/help-center/welcome/welcome",
    "title": "Welcome to Vellum ‚Äì AI product development platform",
    "breadcrumb": [
      {
        "title": "Welcome",
        "pathname": "/help-center/welcome"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover Vellum for prompt engineering, semantic search, and more. Get resources and support for all major LLM providers.",
    "content": "Welcome üëã Vellum helps bring LLM-powered features to production with tools for prompt engineering,\nsemantic search, version control, quantitative testing, and performance monitoring across\nall major LLM providers and open source models.\nHere you'll find resources and guides for the Vellum platform and our APIs. Please don't hesitate to contact\nus at support@vellum.ai if you can't find what you're looking for."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.welcome.getting-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/welcome/getting-support",
    "pathname": "/help-center/welcome/getting-support",
    "title": "Vellum's Help Center",
    "breadcrumb": [
      {
        "title": "Welcome",
        "pathname": "/help-center/welcome"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover ways to contact the Vellum team and receive assistance with your LLM features.",
    "content": "Having trouble some trouble using Vellum? Don't worry, we're here to help ‚Äì there are many ways to get unstuck!"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.welcome.getting-support--email-us-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/welcome/getting-support",
    "pathname": "/help-center/welcome/getting-support",
    "title": "üìß Email us",
    "breadcrumb": [
      {
        "title": "Welcome",
        "pathname": "/help-center/welcome"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#-email-us",
    "content": "We respond quickly to emails, so don't hesitate to reach out to us at support@vellum.ai. When you do, please describe your use case and the specific problem you're encountering so we can better assist you.",
    "hierarchy": {
      "h0": {
        "title": "Vellum's Help Center"
      },
      "h2": {
        "id": "-email-us",
        "title": "üìß Email us"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.welcome.getting-support-help-center-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/welcome/getting-support",
    "pathname": "/help-center/welcome/getting-support",
    "title": "‚ùìHelp Center",
    "breadcrumb": [
      {
        "title": "Welcome",
        "pathname": "/help-center/welcome"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#help-center",
    "content": "If you prefer a self-service option, check out the articles here in our Help Center. We have plenty of articles with detailed explanations, screenshots, and videos to help you troubleshoot common issues. We're constantly adding new resources, so be sure to check back often!",
    "hierarchy": {
      "h0": {
        "title": "Vellum's Help Center"
      },
      "h2": {
        "id": "help-center",
        "title": "‚ùìHelp Center"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.welcome.getting-support--discord-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/welcome/getting-support",
    "pathname": "/help-center/welcome/getting-support",
    "title": "üßë‚Äçüíª Discord",
    "breadcrumb": [
      {
        "title": "Welcome",
        "pathname": "/help-center/welcome"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#-discord",
    "content": "Another great way to get help and connect with other Vellum users is to join our Discord community. Our community is a great resource for getting advice and tips from other Vellum users. We're constantly monitoring Discord and answering questions to help you get unstuck. We're all here to help each other out, so don't hesitate to join and start chatting!",
    "hierarchy": {
      "h0": {
        "title": "Vellum's Help Center"
      },
      "h2": {
        "id": "-discord",
        "title": "üßë‚Äçüíª Discord"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Prompt Engineering",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how Vellum's prompt engineering enhances LLMs with dynamic templates, jinja templating, and function calling for smarter prompts.",
    "content": "Prompts are the \"instructions\" that you give to Large Language Models (LLMs) to generate a response.\nIf you've used ChatGPT, then you've actually already interacted with an LLM that was provided with a\nPrompt on how it should respond in a helpful, polite manner!\nWhen building your own AI-powered application, you'll very likely need to come up with your own Prompts.\nFurthermore, Prompts are rarely static strings. Instead, most Prompts are \"templates\" with dynamic\nsections whose contents are determined at runtime. For example, you might need to include information about\nthe user that's interacting with your application, some relevant section of a knowledge base, etc.\nVellum encourages the development of dynamic prompts by providing a powerful\nprompt syntax that supports variable substitution, jinja templating, and function calling.\nAt a high level, you define \"Input Variables\" and reference those variables in your Prompt.\nYou can experiment with different values for these variables via \"Scenarios\" to determine\nwhat the LLM's output would be.\nYou can reference input variables in your Prompt in one of two ways using different types\nof \"blocks.\"\nRich Text Blocks: Great for most use-cases where a simple variable substitution is needed.\nBegin type {{  or / to get a dropdown of available variables.\n\nJinja Blocks: Used for more complex use-cases where you need the power of Jinja templating syntax\nto perform conditional logic, loops, etc."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-rich-text-blocks-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Rich Text Blocks",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#rich-text-blocks",
    "content": "Most of the time, you'll use Rich Text blocks for simple variable substitution.\nThese blocks are easy to use and are great for most use-cases. You can reference\nvariables by typing {{  or / to get a dropdown of available variables.\nHere's an example of a Rich Text block:\nRich Text Block Example",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "rich-text-blocks",
        "title": "Rich Text Blocks"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-jinja-blocks-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Jinja Blocks",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#jinja-blocks",
    "content": "Jinja is a powerful templating syntax useful for dynamic content.\nIn its most basic form, you might use it to reference Prompt Variables.\nHowever, if all you need is variable substitution, consider using a Rich\nText block instead.\nBelow are the most common things you‚Äôre likely to want to do,\nbut you can find jinja‚Äôs complete documentation\nhere.",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "jinja-blocks",
        "title": "Jinja Blocks"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-variables-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Variables",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#variables",
    "content": "Reference variables using double-curly-brackets. For example,\n\n\nYou are a {{ personality_type }} AI assistant.\n\n\nNote that all prompt variables are treated as strings!",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "jinja-blocks",
        "title": "Jinja Blocks"
      },
      "h3": {
        "id": "variables",
        "title": "Variables"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-conditionals-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Conditionals",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#conditionals",
    "content": "Perform conditional logic based on your input variables using if/else statements",
    "code_snippets": [
      {
        "code": "You are a {{ personality_type }} AI assistant.\n{% if personality_type == \"rude\" %}\nYou end every message with a frowning emoji.\n{% else %}\nYou end every message with a smiling emoji.\n{% endif %}"
      },
      {
        "code": "You are a {{ personality_type }} AI assistant.\n{% if personality_type == \"rude\" %}\nYou end every message with a frowning emoji.\n{% else %}\nYou end every message with a smiling emoji.\n{% endif %}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "jinja-blocks",
        "title": "Jinja Blocks"
      },
      "h3": {
        "id": "conditionals",
        "title": "Conditionals"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-comments-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Comments",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#comments",
    "content": "You can use jinja to leave comments in your prompt that don‚Äôt use up any\ntokens when compiled and sent to the LLM. For example,",
    "code_snippets": [
      {
        "code": "{# This is a comment #}\nHello, world!"
      },
      {
        "code": "{# This is a comment #}\nHello, world!"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "jinja-blocks",
        "title": "Jinja Blocks"
      },
      "h3": {
        "id": "comments",
        "title": "Comments"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-json-inputs-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "JSON Inputs",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#json-inputs",
    "content": "Vellum supports JSON input variables. When you supply a JSON variable, you can use this trick to access specific key/value pairs.\nFor example, say you have a variable called traits whose value in a Scenario looked like:\nThen you can access \"happy go lucky\" by using a Jinja template block and referencing the JSON variable like so:",
    "code_snippets": [
      {
        "lang": "json",
        "code": "{\n  \"hair_color\": \"brown\",\n  \"personality\": \"happy go lucky\"\n}"
      },
      {
        "code": "You are a {{ traits.personality }} AI assistant.\n"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "jinja-blocks",
        "title": "Jinja Blocks"
      },
      "h3": {
        "id": "json-inputs",
        "title": "JSON Inputs"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-casting-variable-types-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Casting Variable Types",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#casting-variable-types",
    "content": "Vellum currently treats all input variables to prompts as strings. However, you may use jinja filters to convert your variables to specific types and then use them accordingly. For example:",
    "code_snippets": [
      {
        "code": "You are an AI chat bot working at the registry of motor vehicles.\nThe person who just stepped up to the counter\n{% if age | float > 16 %}\nis of legal driving age.\n{% else %}\nisn't yet old enough to drive.\n{% endif %}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "jinja-blocks",
        "title": "Jinja Blocks"
      },
      "h3": {
        "id": "casting-variable-types",
        "title": "Casting Variable Types"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-blocks-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Blocks",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#blocks",
    "content": "Vellum uses blocks to separate key pieces of a prompt, such as System/Assistant/User messages of a Chat model¬†(e.g. gpt-3.5-turbo or claude-v1) or the special $chat_history variable.\nBlocks are more noticeable when using a Chat model than when using a Text model.",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "blocks",
        "title": "Blocks"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-chat-model-example-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Chat Model Example",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#chat-model-example",
    "content": "Here‚Äôs what a sequence of blocks might look like for a Chat model\nChat Model Prompt",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "blocks",
        "title": "Blocks"
      },
      "h3": {
        "id": "chat-model-example",
        "title": "Chat Model Example"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-text-model-example-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Text Model Example",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#text-model-example",
    "content": "Text models typically use a single block, which might look like this:\nText Model Prompt",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "blocks",
        "title": "Blocks"
      },
      "h3": {
        "id": "text-model-example",
        "title": "Text Model Example"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-switching-from-chat--text-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Switching from Chat ‚Üî Text Models",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#switching-from-chat--text-models",
    "content": "When switching from a Chat Model to a Text model, blocks are converted as best they can be.\nChat ‚Üí Text\nHere‚Äôs an example going from Chat to Text.\nConverting from Chat Models to Text Models\nText ‚Üí Chat\nHere‚Äôs an example going from Text to Chat.\nConverting from Text Models to Chat Models",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "blocks",
        "title": "Blocks"
      },
      "h3": {
        "id": "switching-from-chat--text-models",
        "title": "Switching from Chat ‚Üî Text Models"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-function-calling-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Function Calling",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#function-calling",
    "content": "Function Calling allows you to provide function definitions within your prompts the the model could use in deciding how to respond with each user prompt. It‚Äôs best to think of functions as a type of classifier prompt that pushes to model to respond with either:\nThe name of one of those functions, with associated parameter values.\n\nA standard text response.\n\n\nThis definitive response from the model allows developers building LLM features into their applications to know when to call a function or when to return a message to the user. This removes the need to try parsing JSONs are other formats from the LLM text response, leading to more stable user experiences.\nTo define a function, you first need to choose a model that supports function calling and click the + Add ‚Üí Function button at the bottom of your prompt:\nAdd Prompt Block Button\nThen, click the block that‚Äôs created and a modal will appear where you can start defining your function! There are three important sections to consider:\nName - This is a single identifier that the model will use to instruct you which function to call next\n\nDescription - This is a natural language description of what your function does. This is the part most used by the model to decide which function to call and should be considered counting towards your token count.\n\nParameters - The set of parameters your functions accept. Each parameter will also have a Name, Description, & Type that the model uses to decide what values the function should be called with.\n\n\nFunction Placeholder\nEdit Function Dialog\nWhen you then call the model with a prompt along with these function definitions, the model will then decide whether it makes sense to call one of the defined functions or return the standard text response. If it decides to call a defined function, the response will be a JSON directing which function to call and with which parameter values:\nFunction Call Response\nNotice that in this example, the model is directing us to call the get_current_weather function with the location parameter set to Boston, MA. At this point, it is up to the app developer to actually invoke the function - the model itself does not have access to the execution logic. These functions should represent public or private APIs that the app developer supports and could invoke once instructed by the model.\nOnce the function is called and a response is observed, the response should be fed back to the LLM as a function message so that the model knows what was the outcome of calling that function. The model will then be able to use the response of that function when deciding how to respond next in order to satisfy the original prompt.\nAssistant Response Following FUnction Call\nNotice that we need to specify the original response from the model as an assistant message, before following up with a function message. The final output from the model then represents its understanding of the user‚Äôs prompt and the output of the function it had access to.\nOnce you have reached this point, you‚Äôll have everything you‚Äôll need to add functions to models! Function calling is best used for incorporating the following types of data into your prompts:\nRuntime or recent data - New data that has become available that the developer‚Äôs APIs have access to but the model was not trained on\n\nProprietary data - Data the developer has collected that is specialized to their business proposition that gives their application a comparative advantage\n\nWeighted data - Data that the model already has been trained on but that the developer would like to re-prioritize based on some special insights that could be inferred from their API",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h2": {
        "id": "blocks",
        "title": "Blocks"
      },
      "h3": {
        "id": "function-calling",
        "title": "Function Calling"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-previewing-compiled-prompts-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Previewing Compiled Prompts",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#previewing-compiled-prompts",
    "content": "Given the powerful and dynamic nature of Vellum‚Äôs prompt syntax, you may want to see what the final, compiled payload sent to the model provider after all variable substitutions and jinja templating is applied. You can do this in the Playground UI like so:\nPreviewing Compiled Prompts",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h1": {
        "id": "previewing-compiled-prompts",
        "title": "Previewing Compiled Prompts"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompt-engineering-viewing-prompt-usage-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompt-engineering",
    "pathname": "/help-center/prompts/prompt-engineering",
    "title": "Viewing Prompt Usage",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#viewing-prompt-usage",
    "content": "You can view how much token, character or compute time usage your prompts are costing you by enabling the \"Track Usage\" toggle in your Prompt Sandbox's settings.\nUsage Tracking Sandbox",
    "hierarchy": {
      "h0": {
        "title": "Prompt Engineering"
      },
      "h1": {
        "id": "viewing-prompt-usage",
        "title": "Viewing Prompt Usage"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.collaboration-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/collaboration",
    "pathname": "/help-center/prompts/collaboration",
    "title": "Collaborate on Prompts with Vellum Prompt Playground",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Explore Vellum Prompt Playground for rapid iteration, collaboration, and sharing of model-generated prompts. Save, tag, and track progress easily.",
    "content": "The Vellum Prompt Playground is a powerful tool for rapid iteration and\ncollaboration between multiple models and prompts. Save, tag,\nand share your work with ease using the features outlined below."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.collaboration-history-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/collaboration",
    "pathname": "/help-center/prompts/collaboration",
    "title": "History",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#history",
    "content": "Every model-generated response and respective prompt are saved\nas history items, giving you access to a detailed record of your\nwork. To access history items, simply activate the toggle button\nlocated at the top right of the Playground, and all history items\nwill appear on the left side of your screen.\nPlayground History",
    "hierarchy": {
      "h0": {
        "title": "Collaborate on Prompts with Vellum Prompt Playground"
      },
      "h3": {
        "id": "history",
        "title": "History"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.collaboration-tracking-progress-collaborating-and-tagging-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/collaboration",
    "pathname": "/help-center/prompts/collaboration",
    "title": "Tracking Progress, Collaborating, and Tagging",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#tracking-progress-collaborating-and-tagging",
    "content": "The Playground is designed to help you iterate on prompts and model\nproviders until you find the perfect fit for your needs. With the\nhistory feature, you can keep track of your team's work in an organized\nway by only keeping the iterations you choose to, through the save button.\nEveryone working on the same sandbox can see each other's history items,\nand you can also tag them to keep better track of your work.\nTagging History",
    "hierarchy": {
      "h0": {
        "title": "Collaborate on Prompts with Vellum Prompt Playground"
      },
      "h3": {
        "id": "tracking-progress-collaborating-and-tagging",
        "title": "Tracking Progress, Collaborating, and Tagging"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.collaboration-share-your-work-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/collaboration",
    "pathname": "/help-center/prompts/collaboration",
    "title": "Share Your Work",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#share-your-work",
    "content": "At any point in time, you can easily share your work with anyone in\nyour organization through a URL by using the ‚Äúinvite‚Äù button located\nat the top right of the page.\nInviting Teammates",
    "hierarchy": {
      "h0": {
        "title": "Collaborate on Prompts with Vellum Prompt Playground"
      },
      "h3": {
        "id": "share-your-work",
        "title": "Share Your Work"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.custom-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/custom-models",
    "pathname": "/help-center/prompts/custom-models",
    "title": "Integrate Custom Models in Your Vellum Workspace Easily",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to add both private and public custom models to your Vellum workspace for enhanced functionality and domain-specific advantages.",
    "content": "Vellum supports several of the industry's most popular models by default available in your workspace right away. However, you may wish to use a custom model that gives your business some additional advantage not provided by these off the shelf models, such as higher rate limits or more domain-specific training. These models can also be set up for use within Vellum!\nCustom models fall under two categories: private models and public models. Both could be added via the Models tab within Vellum."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.custom-models-adding-private-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/custom-models",
    "pathname": "/help-center/prompts/custom-models",
    "title": "Adding Private Models",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#adding-private-models",
    "content": "Private models are new instances of models that were created by you outside of Vellum and are looking to integrate into the platform. When you navigate to the models page, the supported types of private models will be accessible from a section on the top of the page:\nAdding Private Custom Models\nClicking on one of the templates will take you to an onboarding flow on how to connect your private model to Vellum. Once you've completed the pre-requisite steps and add in the requested form info, your model should be successfully added to your workspace!\nWe currently support the following private Model Templates:\nOpenAI models hosted on Azure\n\nOpenAI fine-tuned models\n\nFine-tuned models hosted on Fireworks AI",
    "hierarchy": {
      "h0": {
        "title": "Integrate Custom Models in Your Vellum Workspace Easily"
      },
      "h2": {
        "id": "adding-private-models",
        "title": "Adding Private Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.custom-models-adding-public-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/custom-models",
    "pathname": "/help-center/prompts/custom-models",
    "title": "Adding Public Models",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#adding-public-models",
    "content": "Public models are shared instances of models that are hosted by model providers and are granted access to them by various authentication schemes, most commonly via an API Token. Some are enabled in your workspace by default when you create a new workspace in Vellum. To find other public models not yet enabled in your workspace, navigate to the models page and scroll down to the Available Models section:\nAdding Public Custom Models\nTo help filter the options, you could select just Available in the drop down on the right or use the search bar to look for the specific model of interest.\nWhile most of these models require just adding your API key from the relevant model provider, some like those from AWS Bedrock will require some additional steps taken within your account. These directions will be laid out within each model's onboarding modal when you click to enable them in your workspace.",
    "hierarchy": {
      "h0": {
        "title": "Integrate Custom Models in Your Vellum Workspace Easily"
      },
      "h2": {
        "id": "adding-public-models",
        "title": "Adding Public Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.custom-models-request-a-model-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/custom-models",
    "pathname": "/help-center/prompts/custom-models",
    "title": "Request a Model",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#request-a-model",
    "content": "Don't see a custom model listed here but want to try it within Vellum? Reach out to us on Slack for support!",
    "hierarchy": {
      "h0": {
        "title": "Integrate Custom Models in Your Vellum Workspace Easily"
      },
      "h2": {
        "id": "request-a-model",
        "title": "Request a Model"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.images-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/images",
    "pathname": "/help-center/prompts/images",
    "title": "Leverage Images in Your Vellum Prompts and Workflows",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to send images to multimodal models like GPT-4 Turbo with Vision from within Vellum‚Äôs UI",
    "content": "Leverage the power of multimodal models to process both natural language and visual inputs within your LLM-applications using Vellum.\nVellum supports images for OpenAI‚Äôs vision models like GPT-4 Turbo with Vision - both via API and in the Vellum UI.\nImages in Vellum UI\nRead on to learn how to get started using images in Vellum!"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.images-using-images-in-the-ui-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/images",
    "pathname": "/help-center/prompts/images",
    "title": "Using Images in the UI",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#using-images-in-the-ui",
    "content": "Vellum supports images as inputs to both your Prompts and Workflows. In either Sandbox, you can add images inside of scenario Chat History messages.\nBegin by selecting the correct model, GPT-4 Turbo with vision, in your Prompt. In Workflows, you can set the model within a Prompt Node. Before you do, you'll want to add a Chat History block as an input to your Workflow first.\nVision Model Selection\nNext, add a Chat History block and some messages to your template so you can drag images within them.\nHere's how to do it:\nIn the Prompt Sandbox, add a Chat History block by typing in $chat_history. This is a special Prompt Variable name that will add an empty Chat History block component in each scenario\nPrompt Sandbox Steps\n\nIn the Workflow Sandbox, a Chat History block can be added directly from the \"Add\" dropdown on the bottom left of the Input Variables modal. After adding this block, configure your Prompt Node to use Chat History as an input\nWorkflow Sandbox Steps\n\n\nNow you're ready to add images! Drag and drop a valid image into a Chat History message that's being used as an input to define a Prompt or Workflow scenario. This converts the Chat Message into a draggable array that can be easily re-ordered and can contain multiple image and/or text items.\n\n\nValid image URLs: Images must have their absolute path including the image\nfiletype in their URL and must be publicly visible (example:\nhttps://storage.googleapis.com/vellum-public/help-docs/release-tags-on-deploy.png)\nHere‚Äôs what images look like in the Prompt Sandbox:\nImages in Prompt Scenarios\nAnd images in the Workflow Sandbox:\nImages in Workflow Scenarios\nOnce you‚Äôve added in your image, you can configure its settings by clicking the small gear icon to the right of the image. Here you'll be able to adjust things like the Image Detail which can have a big impact on token usage (more on that below).\nImage Configuration Steps\nYou can also switch out an image you‚Äôve dragged in for a new one by updating the image URL in the settings.\nImage Configuration Modal",
    "hierarchy": {
      "h0": {
        "title": "Leverage Images in Your Vellum Prompts and Workflows"
      },
      "h2": {
        "id": "using-images-in-the-ui",
        "title": "Using Images in the UI"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.images-image-specifications-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/images",
    "pathname": "/help-center/prompts/images",
    "title": "Image Specifications",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#image-specifications",
    "content": "Here are some important model specifications for GPT-4 Turbo with Vision to keep in mind as you‚Äôre incorporating images into your Prompts and Workflows:\nNumber of Images: No set limit\nThere is no fixed number here but token and image size restrictions still apply to determine the number of images that can be sent\n\nImage Size: Less than 32MB\nFor prompts and workflows with multiple images, the combined image size should not exceed this limit\n\nSupported Image Formats:\nJPEG (.jpeg / .jpg)\n\nPNG (.png)\n\nNon-animated GIF (.gif)\n\nWEBP (.webp)\n\n\n\nOther Notes:\nGPT-4 Turbo with Vision does not currently support tool calls so be sure there are no function blocks in your $chat_history messages\n\nThe Vellum UI currently supports only publicly hosted image urls. To send a base64 image file, you can use Vellum's API instead.\nHere's a short example on how to send an image to the model, using Vellum's Python SDK:",
    "code_snippets": [
      {
        "lang": "python",
        "code": "image_link = \"https://storage.googleapis.com/vellum-public/help-docs/add_prompt_block_button.png\"\nresponse = client.execute_prompt(\n    prompt_deployment_name=\"github-loom-demo\",\n    inputs=[\n        PromptDeploymentInputRequest_ChatHistory(\n            name=\"$chat_history\",\n            value=[\n                ChatMessageRequest(\n                    role=ChatMessageRole.USER,\n                    content={\n                        \"type\": \"ARRAY\",\n                        \"value\": [\n                            {\"type\": \"STRING\", \"value\": \"What's in this image?\"},\n                            {\"type\": \"IMAGE\", \"value\": {\"src\": image_link}},\n                        ],\n                    },\n                )\n            ],\n            type=VellumVariableType.CHAT_HISTORY,\n        ),\n    ],\n)\nprint(response.outputs[0].value)"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Leverage Images in Your Vellum Prompts and Workflows"
      },
      "h2": {
        "id": "image-specifications",
        "title": "Image Specifications"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.images-image-detail-and-token-usage-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/images",
    "pathname": "/help-center/prompts/images",
    "title": "Image Detail and Token Usage",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#image-detail-and-token-usage",
    "content": "When working with image models, token usage is an important factor to consider. For GPT-4 Turbo with Vision, the two main factors for token count are the image‚Äôs size and it‚Äôs detail setting.\nThere are three possible settings for the image detail: low, high, or auto\nIn Vellum, we default the detail to be low to prevent unintended token usage. OpenAI's default setting is auto where the model decides whether to use low or high detail based on the size of the input image.\nImage Details\nThe low setting processes a lower resolution 512x512 version of the image. With low, the response time is faster and there‚Äôs a fixed token consumption per image. At the time of this writing, that amount is 85 tokens. The low setting is great when the fine details of the image are not required.\nThe high setting on the other hand is the high resolution mode. In this mode, the input image is tiled and a detailed segment is created from it. Token usage is calculated based on the number of these segments which correlates to the image size. High resolution allows for a more comprehensive interpretation of your image.\nYou can learn more about the image detail setting and OpenAI Vision models on their site\n\n\nAre you looking for greater multimodal model support in Vellum beyond\ngpt-4-vision-preview? Please don't hesitate to let us know at\nsupport@vellum.ai!",
    "hierarchy": {
      "h0": {
        "title": "Leverage Images in Your Vellum Prompts and Workflows"
      },
      "h2": {
        "id": "image-detail-and-token-usage",
        "title": "Image Detail and Token Usage"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompting-tips-and-examples",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompting-tips-and-examples",
    "pathname": "/help-center/prompts/prompting-tips-and-examples",
    "title": "Prompting Tips and Examples",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn prompting techniques for common use-cases."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.prompts.prompting-tips-and-examples-producing-json-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/prompts/prompting-tips-and-examples",
    "pathname": "/help-center/prompts/prompting-tips-and-examples",
    "title": "Producing JSON",
    "breadcrumb": [
      {
        "title": "Prompts",
        "pathname": "/help-center/prompts"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#producing-json",
    "content": "You can efficiently specify the shape of JSON objects you'd like your LLM to produce with the following recipe:\nNote the code fencing used here to add descriptions for the key-value pairs so the model knows what to extract.\nWe also provide a default value so we can handle that downstream in our system rather than getting inconsistent values from the LLM when the data is not found.",
    "code_snippets": [
      {
        "lang": "plaintext",
        "code": "Provide a JSON response for the following transcript information and use the formatting\nbelow:\n \n```\n{\n  \"meeting_type\": \"board meeting\" || \"special meeting\" || \"work session\" // if none, return \"general\",\n  \"speakers\": string[], // list of speaker names\n  \"meeting_location\": \"virtual\" || \"in_person\",\n  \"date\": \"datetime\", // ISO 8601 format with date and time and default to \"null\" if datetime is unknown\n  \"summary\": \"string\" // concise description of key topics\n}\n```\n \nTranscript:\n\"\"\"\n[transcript contents go here]\n\"\"\""
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Prompting Tips and Examples"
      },
      "h2": {
        "id": "producing-json",
        "title": "Producing JSON"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.introduction-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/introduction",
    "pathname": "/help-center/workflows/introduction",
    "title": "Build multi-step AI apps with Vellum‚Äôs Worfklows",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how Vellum Workflows streamline LLM call chains with a low-code interface, easy testing, and versioned deployments.",
    "content": "Vellum Workflows help you quickly prototype, deploy, version, and monitor complex chains of LLM calls and the business logic that tie them together.\nIt provides a low-code interface for defining these chains so that you get rapid feedback on how they work across a variety of test cases that you define. Once you‚Äôre happy with the Workflow, you can ‚Äúdeploy‚Äù it and hit an API to invoke that Workflow from your application.\nOnce deployed, future changes to the Workflow definition are versioned and invocations made from your application are logged. For a given invocation, you can view the inputs, outputs, and latency of each step along the way."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.introduction-concepts-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/introduction",
    "pathname": "/help-center/workflows/introduction",
    "title": "Concepts",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#concepts",
    "content": "Workflows make heavy use of the following concepts:\nInput Variables\n\nScenarios\n\nNodes\n\nEdges\n\nFinal Outputs\n\n\nLet‚Äôs take a look at each",
    "hierarchy": {
      "h0": {
        "title": "Build multi-step AI apps with Vellum‚Äôs Worfklows"
      },
      "h1": {
        "id": "concepts",
        "title": "Concepts"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.introduction-input-variables-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/introduction",
    "pathname": "/help-center/workflows/introduction",
    "title": "Input Variables",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#input-variables",
    "content": "The behavior of most Workflows depend on 1 or more dynamic Input. For example, you could define a single Input named query that your Workflow depends on.\nWorkflow Input Variables",
    "hierarchy": {
      "h0": {
        "title": "Build multi-step AI apps with Vellum‚Äôs Worfklows"
      },
      "h1": {
        "id": "concepts",
        "title": "Concepts"
      },
      "h3": {
        "id": "input-variables",
        "title": "Input Variables"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.introduction-scenarios-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/introduction",
    "pathname": "/help-center/workflows/introduction",
    "title": "Scenarios",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#scenarios",
    "content": "A Scenario is a set of values for your Input Variables. In the above example, we have Scenario 1 which assigns a value of What is fine tuning? to the query Input Variable.\nYou can define as many Scenarios as you want and swap between them to test that your Workflows behaves the way you expect for each.",
    "hierarchy": {
      "h0": {
        "title": "Build multi-step AI apps with Vellum‚Äôs Worfklows"
      },
      "h1": {
        "id": "concepts",
        "title": "Concepts"
      },
      "h3": {
        "id": "scenarios",
        "title": "Scenarios"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.introduction-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/introduction",
    "pathname": "/help-center/workflows/introduction",
    "title": "Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#nodes",
    "content": "Nodes are the steps in your Workflow where some action will take place. Some Nodes generate Outputs, whereas some Nodes are used purely to direct the flow of execution.\nFor example, the Prompt Node is used to pass Input Variables into a Prompt and execute an LLM. It generates an output that can then be used as an input to other downstream Nodes.\nWorkflow Nodes",
    "hierarchy": {
      "h0": {
        "title": "Build multi-step AI apps with Vellum‚Äôs Worfklows"
      },
      "h1": {
        "id": "concepts",
        "title": "Concepts"
      },
      "h3": {
        "id": "nodes",
        "title": "Nodes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.introduction-edges-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/introduction",
    "pathname": "/help-center/workflows/introduction",
    "title": "Edges",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#edges",
    "content": "Edges connect Nodes and define the order in which they are executed. The are represented as the lines in between Nodes.\nWorkflow Edges\nNote that a Node has access to the output data from all upstream Nodes, not just the Node(s) that it‚Äôs directly connected to via an Edge.",
    "hierarchy": {
      "h0": {
        "title": "Build multi-step AI apps with Vellum‚Äôs Worfklows"
      },
      "h1": {
        "id": "concepts",
        "title": "Concepts"
      },
      "h3": {
        "id": "edges",
        "title": "Edges"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.introduction-final-output-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/introduction",
    "pathname": "/help-center/workflows/introduction",
    "title": "Final Output",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#final-output",
    "content": "There‚Äôs a special Node called a ‚ÄúFinal Output Node.‚Äù They‚Äôre used to indicate which Node output you actually care about and want to surface as the overall output for the Workflow.\nIn the below example, I have a Final Output Node named final-output that subscribes to a string output that comes from the OpenAI Help Center Prompt Node.\nWorkflow Final Output\nFinal Output Nodes are particularly important when you Deploy a Workflow and invoke it via API. By default, only the data that Final Output Nodes subscribe to will be returned by the API.\nNote that you can have as many Final Output Nodes in a Workflow and can assign each a name to differentiate the data associated with each in API calls.",
    "hierarchy": {
      "h0": {
        "title": "Build multi-step AI apps with Vellum‚Äôs Worfklows"
      },
      "h1": {
        "id": "concepts",
        "title": "Concepts"
      },
      "h3": {
        "id": "final-output",
        "title": "Final Output"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.experimentation",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/experimentation",
    "pathname": "/help-center/workflows/experimentation",
    "title": "Streamline AI App Development with Vellum's Workflows",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how Vellum's Workflows simplifies building AI apps by managing complex LLM call chains and business logic easily."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.experimentation-about-workflows-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/experimentation",
    "pathname": "/help-center/workflows/experimentation",
    "title": "About Workflows",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#about-workflows",
    "content": "Workflows help you quickly prototype, deploy, and manage complex chains of LLM calls and business logic. We solve the \"whack-a-mole\" problem encountered by companies that use popular open source frameworks to build AI applications, but are scared to make changes for fear of introducing regressions in production.\nThe Workflows UI consists of a graphical app builder where you can string together various nodes and test various input values through this system. Each prompt can also be tested extensively through Playground & Test Suites. When implemented effectively, Workflows can help you build advanced LLM applications",
    "hierarchy": {
      "h0": {
        "title": "Streamline AI App Development with Vellum's Workflows"
      },
      "h2": {
        "id": "about-workflows",
        "title": "About Workflows"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.experimentation-connecting-workflow-nodes-and-defining-variables-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/experimentation",
    "pathname": "/help-center/workflows/experimentation",
    "title": "Connecting Workflow Nodes and Defining Variables",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#connecting-workflow-nodes-and-defining-variables",
    "content": "Workflow nodes are connected by linking the output of one node to the input of another node. For any node the variables can be populated either by the results of an upstream node or the values of global variables.\nWhen 2 nodes are successfully connected there‚Äôs a solid purple line between the nodes and the connection points turn blue. Here‚Äôs an example of a workflow that‚Äôs connected successfully:\nConnecting Workflow Nodes and Defining Variables",
    "hierarchy": {
      "h0": {
        "title": "Streamline AI App Development with Vellum's Workflows"
      },
      "h2": {
        "id": "connecting-workflow-nodes-and-defining-variables",
        "title": "Connecting Workflow Nodes and Defining Variables"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.experimentation-running-a-workflow-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/experimentation",
    "pathname": "/help-center/workflows/experimentation",
    "title": "Running a Workflow",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#running-a-workflow",
    "content": "Each variable in a node can either take the value of an upstream node or the value can be defined globally. To define them globally, you can populate them in the Input Variables dropdown before running a workflow. You can define as many scenarios as you want, each scenario is a unique set of input values that will be sent to the workflow.\nVariables can be added one-by-one using the Add button or automatically using Auto-Add. Auto-Add looks at all the variables in the workflow and adds them to the scenario.\nWorkflow Inputs\nOnce all the variables are selected for each prompt (either as values of upstream nodes or defined globally), you are now ready to Run your workflow!\nWhen you Run the Workflow (purple button on the top right corner), you will see the execution path of the Workflow in green and the intermediate results at each step of the workflow. If the results at the end of the Workflow look surprising then may be a good idea to check what the responses look like at each step.\nHere‚Äôs an example of a workflow that‚Äôs executed successfully:\nExecuted Workflow",
    "hierarchy": {
      "h0": {
        "title": "Streamline AI App Development with Vellum's Workflows"
      },
      "h2": {
        "id": "running-a-workflow",
        "title": "Running a Workflow"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.experimentation-node-mocking-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/experimentation",
    "pathname": "/help-center/workflows/experimentation",
    "title": "Node Mocking",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#node-mocking",
    "content": "Workflow development is best done iteratively. However, this can become prohibitively expensive both in terms of token consumption and runtime if there are Prompt Nodes defined early in the Workflow that you have to frequently re-run just to get to the part of the Workflow that you actually want to test. To help speed up Workflow development, you can mock out the execution of a given node. This will skip the node's execution and return the hard-coded output(s) you define rather than running the node itself.\nWorkflow Node Mocking\nOnce defined, you can easily toggle the mock on and off to go back and forth between mocking the node and actually executing the Prompt to see your Workflow work end-to-end. This also allows you to save your mocks without needing to delete them when you'd like to actually execute the node. During a workflow run, nodes that are mocked will be outlined in yellow to differentiate from nodes that are actually executed.\nWorkflow Node Mocking\nThese mocks are only defined within the context of Workflow Sandboxes, and are defined per Scenario. They do not get deployed with your Workflow Deployments and do not affect behavior when invoking Workflow Deployment APIs.\nThe following nodes support mocking:\nPrompt Nodes\n\nSubworkflow Nodes\n\n\nCheck out the video below for a full demo of Workflow Node Mocking.",
    "hierarchy": {
      "h0": {
        "title": "Streamline AI App Development with Vellum's Workflows"
      },
      "h2": {
        "id": "node-mocking",
        "title": "Node Mocking"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Build Powerful Workflows with Vellum Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover the different types of Workflow Nodes provided by Vellum to build complex LLM Workflows with ease."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-supported-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Supported Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#supported-nodes",
    "content": "Vellum offers over a dozen Node types that you can use to build any Workflow you can imagine. On this page, we'll outline the purpose of each Node.\nFor additional examples of Node usage, check out our Common Workflow Architectures, which we update regularly.",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "supported-nodes",
        "title": "Supported Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-quick-reference-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Quick Reference",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#quick-reference",
    "content": "Node Description \nPrompt Node Invoke LLMs with your prompts, optionally using variables from other nodes \nTemplating Node Apply Jinja templating to perform lightweight data transformations \nSearch Node Search against a Document Index, great for RAG \nAPI Node Make an HTTP request to an API endpoint \nCode Execution Node Run custom Python or Typescript code \nSubworkflow Node Makes Workflows reusable and more maintanable as they get more complex \nMap Node Iterate over an array, executing a sub-workflow for each item \nGuardrail Node Run an inline evaluation using a pre-defined Metric \nConditional Node Branch your workflow based on a condition, also useful for error handling \nMerge Node Wait for one or multiple branches to complete before continuing \nFinal Output Node Exposes values you can use in your application, you may have more than one! \nError Node Stop workflow execution and raise an error \nNote Node A simple node that displays text to help annotate your Workflow",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-prompt-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Prompt Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-nodes",
    "content": "A core part of any LLM application. This node represents a call to a Large Language Model. Similar to Vellum Prompts, you can use models from any of the major providers or open source community, including: OpenAI, Anthropic, Meta, Cohere, Google, Mosaic, and Falcon-40b.\nUpon creating a Prompt Node you‚Äôll be asked to import a prompt from an existing Deployment, Sandbox, or create one from scratch. Prompts are defined by their variables, prompt template, model provider, and parameters. Refer to this help center article to learn more about our prompt syntax (Vellum Prompt Template Syntax).\nPrompt Node",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "prompt-nodes",
        "title": "Prompt Nodes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-templating-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Templating Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#templating-nodes",
    "content": "The Templating Node allows you to perform custom data transformations on a set of defined inputs to create a new output. You can use this to define constants, manipulate data before feeding into a prompt, or massage a response to a format of your liking.\nCheck out our Common Data Transformation Templates for some common examples.\nTemplating Node\n\n\n\n\nYou may have a templating node that outputs JSON which seems valid, but yields the following error when you click ‚ÄúTest‚Äù or run your workflow:\nTips - Using Jinja\nJinja has a tendency to leave hard-to-see whitespace which can cause issues when doing equality checks in places like Metrics or Conditional Nodes.\n\n\n\n\nUse double quotes when working with JSON\n\nJinja has a tendency to leave hard-to-see whitespace which can cause issues when doing equality checks in places like Metrics or Conditional Nodes.",
    "code_snippets": [
      {
        "lang": "jinja",
        "code": "{# this example will have invisible whitespace #} \n{% if some_condition %}\n    {{ result A }}\n{% else %}\n    {{ result B }}\n{% endif %}\n\n{# this will give the result you expect #} \n{%- if some_condition -%}\n    {{- result A -}}\n{%- else -%}\n    {{- result B -}}\n{%- endif -%}"
      },
      {
        "lang": "jinja",
        "code": "{# this example will have invisible whitespace #} \n{% if some_condition %}\n    {{ result A }}\n{% else %}\n    {{ result B }}\n{% endif %}\n\n{# this will give the result you expect #} \n{%- if some_condition -%}\n    {{- result A -}}\n{%- else -%}\n    {{- result B -}}\n{%- endif -%}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "templating-nodes",
        "title": "Templating Nodes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-search-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Search Node",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#search-node",
    "content": "The Search Node returns results from a Document Index stored inside Vellum Search. Once your documents are uploaded in an index (details on how to do that here: Uploading Documents), you can start using them in a Workflow.\nThe index in a Search Node can be fixed for the Workflow or chosen dynamically based on the output of an upstream node. Additional configuration options, similar to the ones in Vellum Search are also available in the Search Node.\nSearch Node",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "search-node",
        "title": "Search Node"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-api-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "API Node",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#api-node",
    "content": "The API Node invokes an API endpoint and returns back the status code, raw output, and JSON output if applicable. These APIs can be either publicly accessible or privately defined within your backend through the help of Authorization headers and Secrets. Simply define a URL, HTTP Method, relevant additional headers, and the body that you would like to send to the desired endpoint.\nAPI Node\n\n\nYou can use a Templating Node and the \"Dynamic\" field of an API Node to quickly and flexibly make API calls in your Workflows. See the example below for more details. Notice how we do string concatenation in the Templating Node using Jinja2's ~ syntax.\n\n\nIt's better to use API Nodes over Code Execution Nodes for API calls. Code Execution Nodes add more latency to your Workflow. Reserve them for more complex tasks.",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "api-node",
        "title": "API Node"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-code-execution-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Code Execution Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code-execution-nodes",
    "content": "The Code Execution Node empowers you to include custom logic defined directly in the workflow. You can even import custom public packages within the node's logic. We support the following languages:\nPython\n\nTypeScript\n\n\nCode Execution Node\n\n\n\n\nSet your output type to JSON when returning string arrays from Code Execution Nodes, or you'll get the following error: Failed to execute node Code Execution Node: Mismatched output type. Output[0]: Expected to deserialize a 'dict', got 'str'\n\n\n\n\nThe main scenario in which you'd use Array as your Code Execution Node output type is when you're processing Prompt Execution Node outputs with Function Calls.\nFor more on that, see Quirks and Tips for Handling Functions",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "code-execution-nodes",
        "title": "Code Execution Nodes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-subworkflow-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Subworkflow Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#subworkflow-nodes",
    "content": "Subworkflow Nodes are essential for managing giant, complex workflows. Define reusable groups of nodes in one Workflow Sandbox and have them directly accessible upon deployment from any other workflow in your workspace. Subworkflow nodes also support release tag specification, allowing you the option to always invoke the latest workflow, or pinning to a specific release tag defined by you.\nCheck out the video below to see Subworkflow Nodes in action!",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "subworkflow-nodes",
        "title": "Subworkflow Nodes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-inline-subworkflow-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Inline Subworkflow Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#inline-subworkflow-nodes",
    "content": "Subworkflow Nodes could also be defined directly within the existing Workflow editor! This spawns a new editor within the existing parent Workflow that supports many of\nthe same features as the parent Workflow such as all existing nodes and copy/paste. This could be used to help organize complex Workflow architectures into separate,\ndigestable groups. Check out the video below to see it in action!",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "subworkflow-nodes",
        "title": "Subworkflow Nodes"
      },
      "h4": {
        "id": "inline-subworkflow-nodes",
        "title": "Inline Subworkflow Nodes"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-map-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Map Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#map-nodes",
    "content": "Map Nodes allow you to easily run a Subworkflow multiple times in a row. Map Nodes work in the same way that array map functions do in many common programming languages.\nThe Nodes take a JSON array as an input and iterate over it, running a Subworkflow for each item. The Subworkflow is provided with three input variables for the iteration item, index and the array.\nThe output of every Subworkflow is then combined into a single array as a Node output. Map Nodes also support up to 96 concurrent iterations.\n\n\n\n\nTwo tips here:\nAt the time of writing, you'll need to cast items into strings at the beginning of your Map Node Subworkflow. Expand the Map Node in the Subworkflow below for more:\n\n\n\n\nMake sure you're using the JSON type as output, even if it's an array, from whichever Node output you're passing to the Map Node. ARRAY types won't be recognized.",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "map-nodes",
        "title": "Map Nodes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-guardrail-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Guardrail Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#guardrail-nodes",
    "content": "Guardrail Nodes allow you to use Evaluation Metrics from within a Workflow. Guardrail Nodes let you run pre-defined evaluation criteria at runtime as part of a Workflow execution so that you can drive downstream behavior based on that Metric's score.\nFor example, if building a RAG application, you might determine whether the generated response passes some threshold for Ragas Faithfulness and if not, loop around to try again.\nGuardrail Nodes",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "guardrail-nodes",
        "title": "Guardrail Nodes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-conditional-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Conditional Node",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#conditional-node",
    "content": "Conditional Nodes are extremely powerful because they can help you diverge the execution path of your Workflow based on the results of an upstream node. The Conditional Node supports as many if-else-if conditions as you‚Äôd like and the rules can be grouped / nested within each other.\nThe number of exit options from a conditional node equal the number of if-else-if conditions created on the node\nConditional Node",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "conditional-node",
        "title": "Conditional Node"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-tip---equality-checking-templating-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Tip - Equality Checking Templating Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#tip---equality-checking-templating-nodes",
    "content": "See our tips about invisible whitespace in Jinja\nWrong Way To Check Equality From Templating Nodes\nThe issue in the above check is that we're not using the Jinja2 syntax to remove unintentional whitespace: {%- and {{- rather than {% or {{\nRight Way To Check Equality From Templating Nodes\nYou can see here that adding the - character fixes the issue and gets the correct branch to execute after the conditional.",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "conditional-node",
        "title": "Conditional Node"
      },
      "h4": {
        "id": "tip---equality-checking-templating-nodes",
        "title": "Tip - Equality Checking Templating Nodes"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-merge-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Merge Node",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#merge-node",
    "content": "Merge Nodes are used when the goal is to bring back the execution of divergent paths into one path. You can configure the number of inputs to a Merge Node and choose between ‚ÄúAwait All‚Äù or ‚ÄúAwait Any‚Äù as your merge strategy. The merge strategy determines the logic that will continue workflow execution.\nMerge Node",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "merge-node",
        "title": "Merge Node"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-final-output-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Final Output Node",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#final-output-node",
    "content": "The Final Output Node represents the end of your workflow. Your workflow may have multiple Final Output Nodes if the execution has been branched off from an upstream node.\nA name for the output and an output type must be configured here because the response streamed back from the endpoint (when the workflow is taken to production) has this information included.\nFinal Output Node",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "final-output-node",
        "title": "Final Output Node"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-error-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Error Node",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#error-node",
    "content": "The Error Node enables you to reject the full workflow, terminating execution with an error event wherever you define it in your execution flow. There are two types of errors you could raise with this node:\nPass-through - Use an Error output from an upstream node and pass it through to this node.\n\nCustom - Define your own String output that this node will use as an error message\n\n\nError Node",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "error-node",
        "title": "Error Node"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.node-types-note-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/node-types",
    "pathname": "/help-center/workflows/node-types",
    "title": "Note Node",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#note-node",
    "content": "The Note Node helps you keep your workflow organized and maintainable. You can use it to add context, related links, or other pieces of information in your workflow. They don't alter any functionality in your workflow, and are purely for your team and you. You can change the font size and even use colors!\nNote Node",
    "hierarchy": {
      "h0": {
        "title": "Build Powerful Workflows with Vellum Nodes"
      },
      "h2": {
        "id": "quick-reference",
        "title": "Quick Reference"
      },
      "h3": {
        "id": "note-node",
        "title": "Note Node"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-architectures-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-architectures",
    "pathname": "/help-center/workflows/common-architectures",
    "title": "Building Common LLM architectures with Vellum Workflows",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how to build dynamic architectures using Workflows, from RAG systems to message routing and looping",
    "content": "With a large number of supported node types (full details here: Experimenting with Workflows) and few limits on how they can be connected to each other, the types of architectures/ applications you can create using Workflows is very large.\nThe list of architectures below is not exhaustive, we‚Äôre continuing to build it out. If you come up with an interesting architecture that you think the community might benefit from, please reach out so we can add it to the list here."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-architectures-create-a-retrieval-augmented-generation-rag-system-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-architectures",
    "pathname": "/help-center/workflows/common-architectures",
    "title": "Create a Retrieval Augmented Generation (RAG) system",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#create-a-retrieval-augmented-generation-rag-system",
    "content": "LLM applications often require specific context from a Vector DB which is added into the prompt. Forget signing up for multiple systems and being stuck on various micro decisions, with Vellum you can prototype a RAG system in minutes\nWalkthrough\n\n\nCreate a Document Index and upload your documents\nFollow this article for tips: Uploading Documents)\nAdd a Search Node in your Workflow\nPlace this anywhere and connect it to the \"entrypoint\"\nAdd a Prompt Node\nThe prompt node should take the results of your Search Node as an input variable\nLink to a Final Output or other downstream node\nFor example, if the Prompt Node result is a certain value branch execution based on a Conditional Node)\nSet up input variables and hit Run!\nWorkflow",
    "hierarchy": {
      "h0": {
        "title": "Building Common LLM architectures with Vellum Workflows"
      },
      "h2": {
        "id": "create-a-retrieval-augmented-generation-rag-system",
        "title": "Create a Retrieval Augmented Generation (RAG) system"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-architectures-route-messages-to-a-human-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-architectures",
    "pathname": "/help-center/workflows/common-architectures",
    "title": "Route messages to a Human",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#route-messages-to-a-human",
    "content": "If you‚Äôre building an agent that answers questions coming from users (e.g., a support chatbot), you may want to set up rules such that anytime the incoming message from a user is sensitive (e.g., the user is angry or in a dangerous situation) then the LLM automatically escalates it to a human. With Workflows you‚Äôd be able to build that out real quick.\nWalkthrough\n\n\nAdd a classification prompt\nUse a Prompt Node to filter out incoming messages\nAdd a downstream prompt\nUse another prompt node for the LLM to respond to messages that don‚Äôt need to be escalated\nAdd and connect two Final Output Nodes\nConnect the classification prompt outputs to two separate Final Output Nodes\nSet up variables and hit Run!\nWorkflow",
    "hierarchy": {
      "h0": {
        "title": "Building Common LLM architectures with Vellum Workflows"
      },
      "h2": {
        "id": "route-messages-to-a-human",
        "title": "Route messages to a Human"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-architectures-retrying-a-prompt-node-in-case-of-non-deterministic-failure-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-architectures",
    "pathname": "/help-center/workflows/common-architectures",
    "title": "Retrying a Prompt Node in case of non-deterministic failure",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#retrying-a-prompt-node-in-case-of-non-deterministic-failure",
    "content": "Prompt nodes support two selectable outputs - one from the model in case of a valid output and one in case of a non deterministic error. Model hosts fail for all sorts of reasons that include timeouts, rate limits, or server overload. You could make your production-grade LLM features resilient to these features by adding retry logic into your Workflows!\nWalkthrough\n\n\nAdd a standard Prompt Node\nAdd a Conditional Node (Error Check)\nThis node will read from the new Error output from the Prompt Node and check to see if it's not null.\nDefine another Conditional Node (Count Check)\nThis node will read from the Prompt Node's Execution Counter, and check if it's been invoked more than your desired limit (3).\nLoop back to the Prompt Node\nLoop back to the Prompt Node if it's under the limit, or exit with some error message if it's over the limit. In the case that the error is null, exit with the Prompt Node's response.\nWorkflow",
    "hierarchy": {
      "h0": {
        "title": "Building Common LLM architectures with Vellum Workflows"
      },
      "h2": {
        "id": "retrying-a-prompt-node-in-case-of-non-deterministic-failure",
        "title": "Retrying a Prompt Node in case of non-deterministic failure"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-architectures-summarizing-the-contents-of-a-pdf-file-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-architectures",
    "pathname": "/help-center/workflows/common-architectures",
    "title": "Summarizing the contents of a PDF file",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#summarizing-the-contents-of-a-pdf-file",
    "content": "Vellum Document Indexes are typically used to power RAG systems via Search Nodes. However, they can also be used to operate on the entirety of a single file's contents.\nIn this example, we make use of Vellum Document Indexes not for the purpose of search, instead, to leverage the OCR that's performed and operate on the raw text that's extracted\nfrom a PDF file.\nPrerequisites:\nYou need to have ....\nCreated a Document Index. Note: it doesn't matter what embedding model or chunking strategy you choose, since we're only leveraging the OCR capabilities of the Document Index.\n\nUploaded a PDF file to the Document Index and noted down its ID.\n\nGenerated a Vellum API Token and saved its value as a Workspace Secret.\n\n\nWalkthrough\n\n\nSet the input to the workflow\nThis will be the ID of a Document that was previously uploaded to a Document Index\nAdd a Templating Node (Document API URL)\nThis will construct the url of a Vellum API we want to hit.\nAdd an API Node (Document API)\nThis will ping the Vellum API and retrieve metadata about the Document.\nAdd a Templating Node (Processed Document URL)\nThis will extract the url of the processed document from the API response.\nAdd an API Node (Processed Document Contents)\nThis will retrieve the text contents of the Document.\nPass those contents to a Prompt Node that summarizes the text.\nWorkflow",
    "hierarchy": {
      "h0": {
        "title": "Building Common LLM architectures with Vellum Workflows"
      },
      "h2": {
        "id": "summarizing-the-contents-of-a-pdf-file",
        "title": "Summarizing the contents of a PDF file"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-data-transforms-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-data-transforms",
    "pathname": "/help-center/workflows/common-data-transforms",
    "title": "Guide to Data Transformation with Templating Nodes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to manipulate strings, JSON, chat history, and search results using Templating Nodes for efficient AI workflows.",
    "content": "The Templating Node supports Jinja2 syntax and is a flexible way of performing light-weight data transformations as part of your Workflow. Here are some common data manipulations you may want to make in a Workflow and how you define them via Templating Nodes."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-data-transforms-output-only-the-first-n-characters-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-data-transforms",
    "pathname": "/help-center/workflows/common-data-transforms",
    "title": "Output Only the First n Characters",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#output-only-the-first-n-characters",
    "content": "Useful if you want to ensure that you‚Äôre not providing too much context to a prompt.\nString Manipulation",
    "code_snippets": [
      {
        "lang": "jinja2",
        "code": "{{ user_input[:10] }}"
      },
      {
        "lang": "jinja2",
        "code": "{{ user_input[:10] }}"
      },
      {
        "code": "Inputs:\n-------\nuser_input = \"Hello, world!\"\n\nOutput:\n-------\n\"Hello, wor\""
      },
      {
        "code": "Inputs:\n-------\nuser_input = \"Hello, world!\"\n\nOutput:\n-------\n\"Hello, wor\""
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Guide to Data Transformation with Templating Nodes"
      },
      "h1": {
        "id": "string-manipulation",
        "title": "String Manipulation"
      },
      "h3": {
        "id": "output-only-the-first-n-characters",
        "title": "Output Only the First n Characters"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-data-transforms-checking-llm-output-for-valid-json-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-data-transforms",
    "pathname": "/help-center/workflows/common-data-transforms",
    "title": "Checking LLM Output for Valid JSON",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#checking-llm-output-for-valid-json",
    "content": "If you‚Äôre trying to extract structured JSON from unstructed text using a prompt, or if you want to use OpenAI‚Äôs function-calling functionality, it‚Äôs likely you‚Äôll need to check whether an LLM‚Äôs response is valid JSON and if so, convert the output string as proper JSON.\nYou can also extract specific properties from valid JSON strings.\nHere‚Äôs how to do it:\nJSON Manipulation",
    "code_snippets": [
      {
        "lang": "jinja2",
        "code": "{% if maybe_json|is_valid_json_string %}\n    {{ maybe_json }}\n    \n    ## to extract specific properties from the JSON\n    {{ json.loads(maybe_json).property }}\n{% else %}\n    {{ {} }}\n{% endif %}"
      },
      {
        "lang": "jinja2",
        "code": "{% if maybe_json|is_valid_json_string %}\n    {{ maybe_json }}\n    \n    ## to extract specific properties from the JSON\n    {{ json.loads(maybe_json).property }}\n{% else %}\n    {{ {} }}\n{% endif %}"
      },
      {
        "code": "Inputs:\n-------\nmaybe_json = '{\"key\": \"value\"}'\n\nOutput:\n-------\n{\"key\": \"value\"}"
      },
      {
        "code": "Inputs:\n-------\nmaybe_json = '{\"key\": \"value\"}'\n\nOutput:\n-------\n{\"key\": \"value\"}"
      },
      {
        "code": "Inputs:\n-------\nmaybe_json = 'not valid json'\n\nOutput:\n-------\n{}"
      },
      {
        "code": "Inputs:\n-------\nmaybe_json = 'not valid json'\n\nOutput:\n-------\n{}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Guide to Data Transformation with Templating Nodes"
      },
      "h1": {
        "id": "json-manipulation",
        "title": "JSON Manipulation"
      },
      "h3": {
        "id": "checking-llm-output-for-valid-json",
        "title": "Checking LLM Output for Valid JSON"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-data-transforms-output-the-most-recent-n-messages-in-chat-history-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-data-transforms",
    "pathname": "/help-center/workflows/common-data-transforms",
    "title": "Output the Most Recent n Messages in Chat History",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#output-the-most-recent-n-messages-in-chat-history",
    "content": "If you‚Äôre building a chatbot and conversations can be long-lived, you may find that your chat histories are too long to fit within the context window of a prompt.\nOnce simple solution is to only ever include the most recent n messages from the conversation. Here‚Äôs how you can do this:\nChat History Manipulation",
    "code_snippets": [
      {
        "lang": "jinja2",
        "code": "{{ chat_history[-2:] }}"
      },
      {
        "lang": "jinja2",
        "code": "{{ chat_history[-2:] }}"
      },
      {
        "code": "Inputs:\n-------\nchat_history = [\n    {\"role\": \"USER\", \"text\": \"What color is the sky?\"},\n    {\"role\": \"ASSISTANT\", \"text\": \"Blue\"},\n    {\"role\": \"USER\", \"text\": \"But why\"}\n]\n\nOutput:\n-------\n[\n    {\"role\": \"ASSISTANT\", \"text\": \"Blue\"},\n    {\"role\": \"USER\", \"text\": \"But why\"}\n]"
      },
      {
        "code": "Inputs:\n-------\nchat_history = [\n    {\"role\": \"USER\", \"text\": \"What color is the sky?\"},\n    {\"role\": \"ASSISTANT\", \"text\": \"Blue\"},\n    {\"role\": \"USER\", \"text\": \"But why\"}\n]\n\nOutput:\n-------\n[\n    {\"role\": \"ASSISTANT\", \"text\": \"Blue\"},\n    {\"role\": \"USER\", \"text\": \"But why\"}\n]"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Guide to Data Transformation with Templating Nodes"
      },
      "h1": {
        "id": "chat-history-manipulation",
        "title": "Chat History Manipulation"
      },
      "h3": {
        "id": "output-the-most-recent-n-messages-in-chat-history",
        "title": "Output the Most Recent n Messages in Chat History"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-data-transforms-citing-sources-via-chunk-concatenation-customization-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-data-transforms",
    "pathname": "/help-center/workflows/common-data-transforms",
    "title": "Citing Sources via Chunk Concatenation Customization",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#citing-sources-via-chunk-concatenation-customization",
    "content": "Search Nodes make it easy to query a vector store for text that‚Äôs semantically similar to some input. By default, the chunks of text that are returned are concatenated together into a single string using a configurable separator (e.g. \\n\\n#####\\n\\n). The flattened string can then be fed directly to Prompt Nodes as an input variable and referenced within your prompt template.\nHowever, if you want your Prompt to cite its sources and say where it got the info it used to generate its response, then you‚Äôll need more than just the chunk text. You need the name/id/url/etc of the document each chunk came from and you need to provide this info to your Prompt in a consumable form. This is where Templating Nodes come in.\nThe template below takes in the raw search results and performs custom chunk concatenation, but also pulls in info from the document associated with each chunk.\nSearch Result Manipulation",
    "code_snippets": [
      {
        "lang": "jinja2",
        "code": "{% for result in search_results -%}\nSource:\n{{ result.document.label }}\n\nContent:\n{{ result.text }}\n{% if not loop.last %}\n\n#####\n\n{% endif %}\n{% endfor %}"
      },
      {
        "lang": "jinja2",
        "code": "{% for result in search_results -%}\nSource:\n{{ result.document.label }}\n\nContent:\n{{ result.text }}\n{% if not loop.last %}\n\n#####\n\n{% endif %}\n{% endfor %}"
      },
      {
        "code": "Inputs:\n-------\nsearch_results = [\n    {\n        \"text\": \"Hello, world!\",\n        \"score\": 0.015,\n        \"keywords\": [\"hello\", \"world‚Äù],\n        \"document\": {\n            \"id\": \"22df06cf-c876-45ef-a162-4836c410e37b\",\n            \"label\": \"introduction.txt\",\n            \"external_id\": \"introduction.txt\"\n        }\n    },\n    {\n        \"text\": \"The sky is blue.\",\n        \"score\": 0.005,\n        \"keywords\": [\"sky\", \"blue‚Äù],\n        \"document\": {\n            \"id\": \"d9655f5f-885e-400e-b000-00b605a03a99\",\n            \"label\": \"description.txt\",\n            \"external_id\": \"description.txt\"\n        }\n    }\n]\n\nOutput:\n-------\nSource:\nintroduction.txt\n\nContent:\nHello, world!\n\n\n#####\n\n\nSource:\ndescription.txt\n\nContent:\nThe sky is blue."
      },
      {
        "code": "Inputs:\n-------\nsearch_results = [\n    {\n        \"text\": \"Hello, world!\",\n        \"score\": 0.015,\n        \"keywords\": [\"hello\", \"world‚Äù],\n        \"document\": {\n            \"id\": \"22df06cf-c876-45ef-a162-4836c410e37b\",\n            \"label\": \"introduction.txt\",\n            \"external_id\": \"introduction.txt\"\n        }\n    },\n    {\n        \"text\": \"The sky is blue.\",\n        \"score\": 0.005,\n        \"keywords\": [\"sky\", \"blue‚Äù],\n        \"document\": {\n            \"id\": \"d9655f5f-885e-400e-b000-00b605a03a99\",\n            \"label\": \"description.txt\",\n            \"external_id\": \"description.txt\"\n        }\n    }\n]\n\nOutput:\n-------\nSource:\nintroduction.txt\n\nContent:\nHello, world!\n\n\n#####\n\n\nSource:\ndescription.txt\n\nContent:\nThe sky is blue."
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Guide to Data Transformation with Templating Nodes"
      },
      "h1": {
        "id": "search-result-manipulation",
        "title": "Search Result Manipulation"
      },
      "h3": {
        "id": "citing-sources-via-chunk-concatenation-customization",
        "title": "Citing Sources via Chunk Concatenation Customization"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.common-data-transforms-need-help-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/common-data-transforms",
    "pathname": "/help-center/workflows/common-data-transforms",
    "title": "Need Help?",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#need-help",
    "content": "Templating nodes are flexible and powerful, but admittedly not the most intuitive. If you‚Äôd like to see additional examples here, or have ideas for custom filters that we should add (like the is_valid_json_string filter used above), please don‚Äôt hesitate to reach out to us on discord!",
    "hierarchy": {
      "h0": {
        "title": "Guide to Data Transformation with Templating Nodes"
      },
      "h1": {
        "id": "need-help",
        "title": "Need Help?"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.code-execution-node-examples-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/code-execution-node-examples",
    "pathname": "/help-center/workflows/code-execution-node-examples",
    "title": "Code Execution Node Examples",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how to use Python or TypeScript for data transformations in Vellum Workflows, including arithmetic and JSON manipulation.",
    "content": "The Code Execution Node supports running arbitrary Python or TypeScript code to perform data transformations in your Workflow. It can simplify your workflow, especially in cases where a combination of Conditional, Templating, and Merge nodes are used. Below are some example use cases:"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.code-execution-node-examples-code-packages-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/code-execution-node-examples",
    "pathname": "/help-center/workflows/code-execution-node-examples",
    "title": "Code Packages",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code-packages",
    "content": "You can add both pip packages for Python code and npm packages for TypeScript code. You must provide exact package versions and add the import to your code yourself.\nNote that whenever you update your packages list, the first execution after doing so may be slow due to our system creating and caching the custom runtime.\nCode Package example",
    "code_snippets": [
      {
        "lang": "typescript",
        "code": "import * as _ from \"lodash\";\n\nasync function main(inputs: {\n  test: string,\n}): Promise<number> {\n  return inputs.test.length + _.floor(5.452);\n}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Code Execution Node Examples"
      },
      "h1": {
        "id": "code-packages",
        "title": "Code Packages"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.api-integration-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/api-integration",
    "pathname": "/help-center/workflows/api-integration",
    "title": "Easy Integration with Vellum's API for Workflows",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to integrate and monitor your Workflow with Vellum's API, making production deployment quick and easy.",
    "content": "Once you have your Workflow built in Vellum‚Äôs UI, we provide an easy way to use it in production. Vellum handles the execution of the Workflow ‚Äî all you need to provide are the input variables to call the Workflow. Vellum abstracts away the need to store the prompts, semantic search & the business logic tying together these prompts in your code base. Using Workflows in production becomes a matter of minutes, not days.\nThis help center article covers how to make the integration, and the monitoring options you have once in production."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.api-integration-workflow-code-snippet-integration-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/api-integration",
    "pathname": "/help-center/workflows/api-integration",
    "title": "Workflow Code Snippet Integration",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-code-snippet-integration",
    "content": "Once you Deploy the Workflow from the UI, you‚Äôre taken to a code snippet which you need to use to call this Workflow in production. The adjacent screenshot shows the Workflow Deployment‚Äôs name & its input variables\nWorkflow Details\nWorkflow API Code Snippet",
    "hierarchy": {
      "h0": {
        "title": "Easy Integration with Vellum's API for Workflows"
      },
      "h2": {
        "id": "workflow-code-snippet-integration",
        "title": "Workflow Code Snippet Integration"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.api-integration-workflow-executions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/api-integration",
    "pathname": "/help-center/workflows/api-integration",
    "title": "Workflow Executions",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-executions",
    "content": "Once you start making requests to the Workflow, all the executions are stored in the Executions tab for monitoring purposes. Any time you find an edge case in production, you can save that specific Execution back as a Scenario for future testing. This is typically used to build out your test bank and debugging unexpected behavior. By running this Scenario in the UI you can see what the responses were at each step and tweak the Workflow logic (prompts, semantic search, business logic tying together the prompts)\nWorkflow Execution Observability",
    "hierarchy": {
      "h0": {
        "title": "Easy Integration with Vellum's API for Workflows"
      },
      "h2": {
        "id": "workflow-executions",
        "title": "Workflow Executions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.api-integration-workflow-executions-details-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/api-integration",
    "pathname": "/help-center/workflows/api-integration",
    "title": "Workflow Executions Details",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-executions-details",
    "content": "Clicking the View Details button on the Execution brings you to a UI where you can see the inputs, outputs and latency at each step of the Workflow when it was run in production",
    "hierarchy": {
      "h0": {
        "title": "Easy Integration with Vellum's API for Workflows"
      },
      "h2": {
        "id": "workflow-executions-details",
        "title": "Workflow Executions Details"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Function Calling with Chat Models",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to use function calling with Chat Models in Vellum Workflows",
    "content": "Function calling (aka ‚Äútool calling‚Äù) helps you get consistent structured data from LLMs. It lets you call custom functions, interact with external APIs, and generally turn natural language into something code can understand.\nBut, don't be misled by the name‚Äîthis feature doesn't actually call functions for you.\nInstead, it creates a JSON object with the name of the function to call and the arguments to pass, which you can use to trigger functions in your code. OpenAI models generate this JSON based on the tools you define with the tools parameter in the API.\nSo now that we‚Äôve cleared that part, let‚Äôs learn how you can use function calling with Chat Models in Vellum."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-using-function-calling-in-vellum-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Using Function Calling in Vellum",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#using-function-calling-in-vellum",
    "content": "In this tutorial, we cover how function calling works and how to use it in Vellum Workflows:\nBy the end of this tutorial, you'll learn to do four tasks in Vellum:\nDefine function calls in a Prompt Node within Workflows;\n\nEnable your models to auto-select or enforce the execution of a function response;\n\nPass Function Call outputs from a Workflow to your code;\n\nRun functions with the provided arguments.\n\n\n\n\nüí° Keep in mind that although we‚Äôll run some arbitrary functions to close\nthe response loop, we won't go into much detail on how to call external APIs\nusing the generated arguments.",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-outline-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Outline",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#outline",
    "content": "For this tutorial, we‚Äôll create an AI-powered customer chatbot for a smartphone outlet, that will have two tools (or functions) defined:\ndelivery_data\nThis function will require three parameters: Phone, which returns the phone's name, Location, which returns the user's location, and Condition, which returns the phone's condition.\n\n\n\ncall_agent\nThis one accepts one parameter: Question which is the user's query.\n\n\n\n\n\n\nüí° This tutorial demonstrates how to define function calling messages in\nPrompt Nodes within Workflows. However, they can also be configured in Prompt\nVariants within a Prompt Sandbox.",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "outline",
        "title": "Outline"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-step-1-setting-up-messages-and-conversation-history-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Step 1: Setting up Messages and Conversation History",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-1-setting-up-messages-and-conversation-history",
    "content": "To setup an OpenAI API call in Vellum, we‚Äôll be using a Prompt Node. This node enables the configuration of all parameters required for an OpenAI API call.\nWe begin by adding the Prompt Node in the Workflow:\nAdd Prompt Node\nTo edit the Prompt Node, just click on the ‚Äúexpand‚Äù icon like on the image above.\nNow let‚Äôs set up the messages.",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-1-setting-up-messages-and-conversation-history",
        "title": "Step 1: Setting up Messages and Conversation History"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-system-message-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "System Message",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#system-message",
    "content": "First we‚Äôll start by adding a system message that tells the model to classify user intents. These models can hallucinate, so we‚Äôll explicitly tell the model to ask for clarification if there's incomplete information. Here‚Äôs the system message we used:\n\n\nüí¨ You're great at classifying user intents. Don't assume which values to use\nin functions‚Äîask for clarification if needed.",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-1-setting-up-messages-and-conversation-history",
        "title": "Step 1: Setting up Messages and Conversation History"
      },
      "h3": {
        "id": "system-message",
        "title": "System Message"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-user-message-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "User Message",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#user-message",
    "content": "Next, we'll create a dynamic variable msg , and add it in the user message to ensure it automatically updates with the variable's content.\nHere‚Äôs what the Prompt Node looks like once we've added the System and the User message:\nPrompt Node Setup",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-1-setting-up-messages-and-conversation-history",
        "title": "Step 1: Setting up Messages and Conversation History"
      },
      "h3": {
        "id": "user-message",
        "title": "User Message"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-chat-mode-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Chat Mode",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#chat-mode",
    "content": "To use function calling with Chat Models, you first need to set up three things in the Prompt Node:\nChat history variable: Simply click on Add Variable and write $chat_history\n\nChat generation model: Click on the model dropdown and select the latest GPT-4 turbo model, or GPT-4 Turbo 04/09/2024\n\nChat history block: Click on the ‚ÄúAdd‚Äù dropdown on the right, and select ‚ÄúAdd Chat History‚Äù\n\n\nHere‚Äôs what the prompt should look like after you've completed the final step:\nPrompt Node With Chat History\nNow let‚Äôs set up the functions.",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-1-setting-up-messages-and-conversation-history",
        "title": "Step 1: Setting up Messages and Conversation History"
      },
      "h3": {
        "id": "chat-mode",
        "title": "Chat Mode"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-step-2-defining-function-calls-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Step 2: Defining Function Calls",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-2-defining-function-calls",
    "content": "To include a Function block, simply select it from the \"Add\" dropdown menu. Once added, you‚Äôll notice a grayed out box that says ‚Äútodo‚Äù:\nAdd Function\nWhen you click that box, you can change the function's name and add a custom description and parameters:\nEdit Function\nYou'll notice there are two options available to define these functions: Form and Upload. The Form option allows you to define your function calling message using the UI, while the Upload option enables you to upload a JSON or YAML file. The uploaded file will automatically map its values to the fields.\nYou might upload a file if you already have your functions defined in in your codebase and want to track their source of truth there.\nIn this tutorial, we‚Äôll upload this JSON file for the delivery_data function that has three properties (condition, phone, location):\nAlso, notice that all of these are required, so the model needs to collect all three in order to generate the response. Here‚Äôs what the UI returned:\nUploaded Function Definition\nHave in mind that you can also check the \"Forced\" box to ensure the model always uses this function. If left unchecked, the model will decide which function to use based on the user query. OpenAI's latest models are quite good at making the right choice, so we‚Äôll leave it unchecked.\nToggle Forced Function\nNow let‚Äôs create the other Function block call_agent. Using the same process as earlier, we add this function as well, which has one required parameter, \"question\" which is the user's query:\nCall Agent Function\nNow that we defined everything, our setup looks like this:\nPrompt Node With Functions\n\n\nüí° With this setup, our OpenAI API calls will take into account the system and user message, the chat history, and two function calling messages to generate responses to a given user query.",
    "code_snippets": [
      {
        "lang": "jsx",
        "code": "{\n  \"name\": \"delivery_data\",\n  \"description\": \"Calls a function with phone and location details\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"type\": {\n        \"description\": \"returns if the model is used or new\",\n        \"type\": \"string\"\n      },\n      \"phone\": {\n        \"description\": \"Description about the phone\",\n        \"type\": \"string\"\n      },\n      \"location\": {\n        \"description\": \"The location of the user\",\n        \"type\": \"string\"\n      }\n    },\n    \"required\": [\n      \"type\",\n      \"phone\",\n      \"location\"\n    ]\n  }\n}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-2-defining-function-calls",
        "title": "Step 2: Defining Function Calls"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-step-3-testing-the-api-call-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Step 3: Testing the API call",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-3-testing-the-api-call",
    "content": "To test the API call, we‚Äôll use the Chat History simulation, where you can run user-assistant messages. You can find this option in the top-left corner of your Workflow sandbox:\nWorkflow Chat History",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-3-testing-the-api-call",
        "title": "Step 3: Testing the API call"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-testing-the-delivery_data-function-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Testing the delivery_data function",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#testing-the-delivery_data-function",
    "content": "In the image below, you'll notice that the model recognizes the user's inquiry about delivery options for a particular mobile phone. Consequently, it prompts the user for the other required parameters, \"location,\" & \"condition\".\nThis corresponds to the function call we defined earlier: delivery_data, and the model successfully determined which function to call for this request:\nWorkflow Chat History\nAfter the user provides the missing information, the model then proceeds to generate the JSON object with the function parameters. Below, you can see that the model successfully gathered all required parameters and displayed them in the output of the Prompt Node:\nPrompt Node Function Called\nNext, you‚Äôll probably want to pass these values directly to your code. Let‚Äôs learn how to do that in the next section.",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-3-testing-the-api-call",
        "title": "Step 3: Testing the API call"
      },
      "h3": {
        "id": "testing-the-delivery_data-function",
        "title": "Testing the delivery_data function"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-step-4-pass-standardized-function-call-outputs-to-your-code-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Step 4: Pass standardized Function Call outputs to your code",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-4-pass-standardized-function-call-outputs-to-your-code",
    "content": "To ensure consistent output across different models, you can use Vellum‚Äôs standardized Function Call output type.\nTo do this, you need to add a Templating Node that receives all model outputs, and extracts a specific one.\nIn our case, we add a Templating Node, where we extract the Prompt Node‚Äôs outputs as an Array, and we set the output type to be a Function Call:\nExtract Function from Templating Node\nFinally, you can add a Final Output node to pass the function call into your code.\nHere‚Äôs what the final Workflow looks like:\nFinal Workflow\nAnd here‚Äôs the raw format from the Final Output node:\nThis is beneficial if you want your Workflow to exclusively produce function call responses. But in real situations, you might have a Workflow that should generate both Assistant and Function call outputs.\nLet‚Äôs look at how you can conditionally branch out those outputs with Vellum.",
    "code_snippets": [
      {
        "lang": "jsx",
        "code": "{\"state\":\"FULFILLED\",\"arguments\":{\"type\":\"new\",\"phone\":\"iPhone 15 Pro\",\"location\":\"San Diego\"},\"id\":\"call_2wVIb9fBFDYh5rPP6QOOemok\",\"name\":\"delivery_data\"}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-4-pass-standardized-function-call-outputs-to-your-code",
        "title": "Step 4: Pass standardized Function Call outputs to your code"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-step-4-branching-out-prompt-node-outputs-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Step 4: Branching out Prompt Node Outputs",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-4-branching-out-prompt-node-outputs",
    "content": "To branch out the model's responses, you‚Äôll first need to add a Templating Node and extract the output type from the Prompt Node:\nExtract Output Type Templating Node\nNext, you‚Äôll add a Conditional Node, where you‚Äôll verify if the output type is a FUNCTION_CALL. If it is, you can divert to the function calling flow; otherwise, proceed with the alternative path.\nHere‚Äôs what the setup should look like:\nConditional Node Branching\nFinally, we add the Function calling and the alternate path:\nFunction Calling with Alternative Workflow Branch\nThe first path will verify if the model generates a function call message and then pass that value as the final output. The second path will check if the model produces an Assistant message and similarly pass that value as the final output.\nOnce all of this is connected, we get this Workflow:\nFull Workflow Diagram\nYou can now deploy your Workflow in your code.\nOnce deployed, you‚Äôll need to invoke it using two input variables:\nchat_history ‚Äì CHAT_HISTORY\n\nuser ‚Äì STRING\n\n\nAnd the API call will return, two output variables:\nfunction_call ‚Äì FUNCTION_CALL\n\nanswer ‚Äì STRING",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-4-branching-out-prompt-node-outputs",
        "title": "Step 4: Branching out Prompt Node Outputs"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-step-5-adding-arbitrary-functions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Step 5: Adding arbitrary functions",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-5-adding-arbitrary-functions",
    "content": "To showcase how this Workflow works, in our code, we wrote arbitrary functions that will print some static messages once the model passes the required parameters.\nFor the delivery_data function we‚Äôll retrieve static message:\n\n\nüí¨ For delivery options in San Diego: You can get same-day delivery if you\norder before noon, with deliveries happening between 1:00 PM and 8:00 PM. If\nyou miss the deadline, don't worry! You can still get your order the next day\nif you place it after noon, with deliveries scheduled between 10:00 AM and\n6:00 PM.\nFor the call_agent function we send another static message:\n\n\nüí¨ Please wait until I connect you with an agent‚Ä¶\nThis is what our code looks like:",
    "code_snippets": [
      {
        "lang": "jsx",
        "code": "import json\n\ndef main(input_str):\n    # Convert the string to a dictionary\n    data = json.loads(input_str)\n\n    # Check the 'name' field and output the corresponding message\n    if data.get(\"name\") == \"delivery_data\":\n        return \"For delivery options in San Diego: You can get same-day delivery if you order before noon, with deliveries happening between 1:00 PM and 8:00 PM. If you miss the deadline, don't worry! You can still get your order the next day if you place it after noon, with deliveries scheduled between 10:00 AM and 6:00 PM.\"\n    elif data.get(\"name\") == \"call_agent\":\n        return \"Please wait until I connect you with an agent‚Ä¶\"\n    else:\n        return \"unknown operation\""
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-5-adding-arbitrary-functions",
        "title": "Step 5: Adding arbitrary functions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-step-6-testing-the-workflow-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Step 6: Testing the workflow",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-6-testing-the-workflow",
    "content": "Now, let‚Äôs see how this works!",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-6-testing-the-workflow",
        "title": "Step 6: Testing the workflow"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-case-1-ask-incomplete-delivery-questions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Case 1: Ask incomplete delivery questions",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#case-1-ask-incomplete-delivery-questions",
    "content": "Works as intended, the model asks about the other required parameter: _location_.\nTest Case 1",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-6-testing-the-workflow",
        "title": "Step 6: Testing the workflow"
      },
      "h3": {
        "id": "case-1-ask-incomplete-delivery-questions",
        "title": "Case 1: Ask incomplete delivery questions"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-case-2-closing-the-loop-call-the-delivery_data-function-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Case 2: Closing the loop, Call the delivery_data function",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#case-2-closing-the-loop-call-the-delivery_data-function",
    "content": "Works as intended; the model provides the arbitrary answer we added in our function for the delivery_data function:\nTest Case 2",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-6-testing-the-workflow",
        "title": "Step 6: Testing the workflow"
      },
      "h3": {
        "id": "case-2-closing-the-loop-call-the-delivery_data-function",
        "title": "Case 2: Closing the loop, Call the delivery_data function"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-case-3-ask-other-questions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Case 3: Ask other questions",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#case-3-ask-other-questions",
    "content": "The model accurately follows the instructions and asks the user if they want to be connected with an agent:\nTest Case 3",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-6-testing-the-workflow",
        "title": "Step 6: Testing the workflow"
      },
      "h3": {
        "id": "case-3-ask-other-questions",
        "title": "Case 3: Ask other questions"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-case-4-call-the-call_agent-function-if-user-says-yes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Case 4: Call the call_agent function if user says yes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#case-4-call-the-call_agent-function-if-user-says-yes",
    "content": "The model successfully runs the call_agent function and outputs the arbitrary answer we defined:\nTest Case 4",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "step-6-testing-the-workflow",
        "title": "Step 6: Testing the workflow"
      },
      "h3": {
        "id": "case-4-call-the-call_agent-function-if-user-says-yes",
        "title": "Case 4: Call the call_agent function if user says yes"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-conclusion-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Conclusion",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#conclusion",
    "content": "Hopefully, through this guide, you've learned how to effectively set up and utilize function calling with Chat Models in Vellum Workflows.\nBy following the steps outlined, you can define functions or tools, enable models to auto-select or enforce function execution, pass function call outputs to your code, and run functions with the provided arguments. This powerful feature allows you to create sophisticated, AI-powered workflows that can handle complex user interactions and seamlessly integrate with your existing systems.",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "using-function-calling-in-vellum",
        "title": "Using Function Calling in Vellum"
      },
      "h2": {
        "id": "conclusion",
        "title": "Conclusion"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.function-calling-with-chat-models-quirks-and-tips-for-handling-functions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/function-calling-with-chat-models",
    "pathname": "/help-center/workflows/function-calling-with-chat-models",
    "title": "Quirks and Tips for Handling Functions",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#quirks-and-tips-for-handling-functions",
    "content": "See below for a quick overview of some common scenarios for handling functions and passing them between nodes.\nIn all three examples, the Prompt Node returns text beyond just the function call. We show how to filter that away and pass the Function Call as part of an Array or on its own.\nExtracting an Array of multiple Function Calls with a Code Execution Node\n\nExtracting a single Function Call with a Code Execution Node\n\nExtracting a single Function Call with a Templating Node",
    "hierarchy": {
      "h0": {
        "title": "Function Calling with Chat Models"
      },
      "h1": {
        "id": "quirks-and-tips-for-handling-functions",
        "title": "Quirks and Tips for Handling Functions"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.examples-and-walkthroughs-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/examples-and-walkthroughs",
    "pathname": "/help-center/workflows/examples-and-walkthroughs",
    "title": "Examples and Walkthroughs",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "See interactive Vellum architectures and watch video walkthroughs of them! Use these as a great starting point for your own applications.",
    "content": "Below you'll find many example architectures for common use-cases, alongside video walkthroughs that explain the architecture of each. You're free to use these as a starting point for your own applications!"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.examples-and-walkthroughs-customer-support-bot-with-escalation-to-human-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/examples-and-walkthroughs",
    "pathname": "/help-center/workflows/examples-and-walkthroughs",
    "title": "Customer Support Bot with Escalation To Human",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#customer-support-bot-with-escalation-to-human",
    "content": "Concepts: Routing, Classification, Chatbot, Statefulness, State Management, Function Calling, Dynamic API URLs",
    "hierarchy": {
      "h0": {
        "title": "Examples and Walkthroughs"
      },
      "h4": {
        "id": "customer-support-bot-with-escalation-to-human",
        "title": "Customer Support Bot with Escalation To Human"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.examples-and-walkthroughs-slack-support-bot-cites-sources-using-multiple-indexes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/examples-and-walkthroughs",
    "pathname": "/help-center/workflows/examples-and-walkthroughs",
    "title": "Slack Support Bot, Cites Sources using Multiple Indexes",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#slack-support-bot-cites-sources-using-multiple-indexes",
    "content": "Concepts: Document Indexes, Metadata, Zapier, Slack, Citing Sources, Combining Sources\n\n\n\n\n\n\n\n\nPassing JSON Arrays in Zapier can be tricky. Instead, you can use Code Blocks to make it easier.\nYou can use the follow code snippet as inspiration for your own API calls with Zapier Code Blocks and Python.",
    "code_snippets": [
      {
        "lang": "python",
        "code": "  import requests\n\n  # Replace with your actual Vellum API key\n  VELLUM_API_KEY = \"...\"\n\n  url = \"https://predict.vellum.ai/v1/execute-workflow\"\n\n  headers = {\n      \"Content-Type\": \"application/json\",\n      \"X_API_KEY\": VELLUM_API_KEY\n  }\n\n  data = {\n      \"workflow_deployment_name\": \"vellum-customer-support-q-a-demos\",\n      \"release_tag\": \"LATEST\",\n      \"inputs\": [\n          {\n              \"type\": \"STRING\",\n              \"name\": \"question\",\n              \"value\": input_data[\"user_question\"] # whatever Zapier values you want to use here\n          }\n      ]\n  }\n\n  response = requests.post(url, headers=headers, json=data)\n\n  # Print the response from the server\n  print(response.status_code)\n  print(response.json())\n\n  return response.json()"
      },
      {
        "lang": "python",
        "code": "  import requests\n\n  # Replace with your actual Vellum API key\n  VELLUM_API_KEY = \"...\"\n\n  url = \"https://predict.vellum.ai/v1/execute-workflow\"\n\n  headers = {\n      \"Content-Type\": \"application/json\",\n      \"X_API_KEY\": VELLUM_API_KEY\n  }\n\n  data = {\n      \"workflow_deployment_name\": \"vellum-customer-support-q-a-demos\",\n      \"release_tag\": \"LATEST\",\n      \"inputs\": [\n          {\n              \"type\": \"STRING\",\n              \"name\": \"question\",\n              \"value\": input_data[\"user_question\"] # whatever Zapier values you want to use here\n          }\n      ]\n  }\n\n  response = requests.post(url, headers=headers, json=data)\n\n  # Print the response from the server\n  print(response.status_code)\n  print(response.json())\n\n  return response.json()"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Examples and Walkthroughs"
      },
      "h4": {
        "id": "slack-support-bot-cites-sources-using-multiple-indexes",
        "title": "Slack Support Bot, Cites Sources using Multiple Indexes"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.examples-and-walkthroughs-chatbots-debating-each-other-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/examples-and-walkthroughs",
    "pathname": "/help-center/workflows/examples-and-walkthroughs",
    "title": "Chatbots Debating Each Other",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#chatbots-debating-each-other",
    "content": "Concepts: Chatbots, Chat History Modification, Conditionals, Adversarial Debate, Academic Research",
    "hierarchy": {
      "h0": {
        "title": "Examples and Walkthroughs"
      },
      "h4": {
        "id": "chatbots-debating-each-other",
        "title": "Chatbots Debating Each Other"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.examples-and-walkthroughs-convert-pdf-to-csv-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/examples-and-walkthroughs",
    "pathname": "/help-center/workflows/examples-and-walkthroughs",
    "title": "Convert PDF to CSV",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#convert-pdf-to-csv",
    "content": "Concepts: PDF Parsing, CSV Generation, Data Extraction, Data Transformation, Document Indexes, Map Nodes\nBlog post",
    "hierarchy": {
      "h0": {
        "title": "Examples and Walkthroughs"
      },
      "h4": {
        "id": "convert-pdf-to-csv",
        "title": "Convert PDF to CSV"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.examples-and-walkthroughs-multiple-parallelized-function-calls-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/examples-and-walkthroughs",
    "pathname": "/help-center/workflows/examples-and-walkthroughs",
    "title": "Multiple Parallelized Function Calls",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#multiple-parallelized-function-calls",
    "content": "Concepts: Parallel Function Calls, Concurrency, Map Nodes, Chat History, API Calls",
    "hierarchy": {
      "h0": {
        "title": "Examples and Walkthroughs"
      },
      "h4": {
        "id": "multiple-parallelized-function-calls",
        "title": "Multiple Parallelized Function Calls"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.workflows.examples-and-walkthroughs-lookup-conference-attendees-with-perplexity-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/workflows/examples-and-walkthroughs",
    "pathname": "/help-center/workflows/examples-and-walkthroughs",
    "title": "Lookup Conference Attendees with Perplexity",
    "breadcrumb": [
      {
        "title": "Workflows",
        "pathname": "/help-center/workflows"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#lookup-conference-attendees-with-perplexity",
    "content": "This example takes a URL, looks up all people mentioned on the page, and sorts them in accordance with how involved they or their affiliates are with AI / LLMs.\nConcepts: Perplexity, SERP, Research Automation, Structured Data Extraction, Parallelization",
    "hierarchy": {
      "h0": {
        "title": "Examples and Walkthroughs"
      },
      "h4": {
        "id": "lookup-conference-attendees-with-perplexity",
        "title": "Lookup Conference Attendees with Perplexity"
      }
    },
    "level": "h4"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Maximize LLM Development Quality with Vellum's Evaluations",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how Vellum's Evaluations feature quantitatively evaluates LLM outputs, ensuring model quality across numerous scenarios.",
    "content": "Ensuring model quality is challenging, because prompts need to work effectively and\nconsistently over a wide range of potential inputs.\nWhen modifying a Prompt, adjusting parameters, or switching models, the likelihood of regression is high.\nThis is where quantitative evaluation comes in.\nVellum's answer to quantitative evaluation are Test Suites and Metrics. Unlike Comparison Mode and Chat Mode,\nwhere the output of each Scenario is qualitatively evaluated by visual inspection,\nTest Suites use Metrics that return scores between 0 and 1 to provide a more objective measure of quality over a wider range of scenarios.\nThis is especially important when your prompt's coverage needs scale and visual inspection is no longer feasible,\nwhich typically happens when you have 10+ scenarios.\nTest Suites cover common use cases in LLM development:\nTest Driven Development of Prompts/Workflows in a Sandbox\n\nPerformance testing on large numbers of Scenarios\n\nRegression testing before deploying a change to a Prompt or Workflow\n\nEvaluating external entities\n\n\nIf you're looking to improve the velocity or quality of your LLM development, Test Suites could be your answer."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-create-a-test-suite-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Create a Test Suite",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#create-a-test-suite",
    "content": "You can create standalone Test Suites through the Test Suites page in the Evaluations tab.\nYou can also create Test Suites starting from a Prompt or Workflow Sandbox.\nHere, we'll begin by creating a Test Suite from a Prompt Sandbox.\nFrom your Prompt Sandbox, click on Evaluations sub-tab\n\nClick \"Create New Test Suite\" if you haven't set up a Test Suite for this Prompt Sandbox yet or click the gray \"Add Test Suite\" button on the right of the page\n\nThe \"label\" and \"name\" fields are autopopulated with the name of your Sandbox\n\nOpen the \"Interface Configuration\" to see the expected inputs/outputs for this Test Suite. This is also autopopulated from your Sandbox.\n\nIf you are creating a Test Suite from scratch, you can customize the inputs/outputs to meet your needs. For now, leave this as it is and click next to start setting up your Metrics.\n\nClick the \"Add Metric\" button to select one or more Metrics to evaluate your output against\n\nSelect \"Exact Match\" from the list of available Metrics. To learn how to create Custom Metrics that appear in this list, see Vellum's Metrics\n\nPress \"Confirm\" to start mapping the Metric to this Test Suite\n\nFirst, select \"Completion\" to map the input to the output of your Prompt\n\nNext, select \"Target\" and then \"Add New\" in the dropdown to create a new expected output variable that's mapped to this input\n\nPress \"Next\" in the bottom right\n\n\nWell done! You've now created a Test Suite with the Exact Match Metric to check for whether the output is desirable.\nTest Suite Creation - Metric Configuration",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "getting-started",
        "title": "Getting Started"
      },
      "h2": {
        "id": "create-a-test-suite",
        "title": "Create a Test Suite"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-create-a-test-case-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Create a Test Case",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#create-a-test-case",
    "content": "Test Cases are analogous to Scenarios. A Test Case by default will have a column for each input and output variable expected by your Test Suite,\nas well as columns for any expected output variables required by your selected Metric.\nWhen a Test Suite is run, Vellum will iterate over every Test Case it contains.\nFor each Test Case, it will feed the provided inputs into the Prompt, Workflow, or entity being tested.\nThe output will be passed to the Metric based on your mapping in the previous step, and a score will be provided based on the Metric being used.\nWith this Test Suite created, you should be on a step that asks you how you want to initialize your Test Cases.\nSelect \"Start from Scenarios\" which will autopopulate test cases for you from Scenarios in your Sandbox.\nTo create additional Test Cases, follow these steps:\nClick the blue \"+ Add Test Case\" button just below the tab to add a new Test Case row\n\nYou can leave the \"Label\" field alone for now - it's used to help you visually identify your Test Cases\n\nEnter a value for each of your input variables. For example, if you have an input variable user_age, you may enter \"28\".\n\nEnter a value for each of your expected output variables\n\nClick outside of your Test Case row to save. You should get a notification that it was successful.\n\nClick \"Finish\" to exit the Test Suite creation wizard\n\n\nAlmost there! Now that you have your Test Cases added, you're ready to run it against your Prompt.\nTest Suite Creation - Test Cases",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "getting-started",
        "title": "Getting Started"
      },
      "h2": {
        "id": "create-a-test-case",
        "title": "Create a Test Case"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-run-a-test-suite-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Run a Test Suite",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#run-a-test-suite",
    "content": "This Test Suite is automatically added to the current Prompt Sandbox you are in.\nTo evaluate your Prompt, simply click the blue Run button.\nThe Test Suite can also be run by any Prompt or Workflow that uses the same input variables you configured earlier. Let's try it.\nNavigate to any Prompt Sandbox in the \"Prompts\" tab\n\nClick the gray \"Add Test Suite\" at the top right of the page\n\nAttach a Test Suite by clicking on \"Use Existing Test Suite\" and selecting your Test Suite from the dropdown\n\nPress the blue \"Run\" to execute the Test Suite\n\n\nLink Test Suite to Prompt\nRun Test Suite on Prompt",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "getting-started",
        "title": "Getting Started"
      },
      "h2": {
        "id": "run-a-test-suite",
        "title": "Run a Test Suite"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-download-via-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Download via API",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#download-via-api",
    "content": "We also support viewing your Test Suite Run results via the API. Check out our docs on Test Suite Runs to learn how to view existing runs. We also embed ready-to-use code snippets within the app itself for each executable column on the evaluations table.\nTest Suite Runs via API",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "getting-started",
        "title": "Getting Started"
      },
      "h2": {
        "id": "download-via-api",
        "title": "Download via API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-multiple-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Multiple Metrics",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#multiple-metrics",
    "content": "It's possible for a Test Suite to have multiple Metrics run simultaneously.\nThis is often desirable when the output is complex and must meet multiple criterion.\nFor example, you may want to validate that an output semantically means \"I'm very happy\",\nbut must contain the word \"ecstatic\".\nAdditional Metrics can be configured on an existing Test Suite under the \"Metric Setup\" section\nof the \"Test Suite Details\" page. Any additional columns needed by that Metric will be editable\nunder the \"Test Cases\" tab.\nWhen running the Test Suite, you'll see columns displaying the results for each Metric that's been added to the Test Suite.\n\n\nFor more on premade Vellum Metrics, see Out of the Box Metrics. To learn how to create your own, see Custom Metrics",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "multiple-metrics",
        "title": "Multiple Metrics"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-uploading-test-cases-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Uploading Test Cases",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#uploading-test-cases",
    "content": "To help you migrate your Test Cases into Vellum, we provide two methods for bulk Test Case uploads.",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "uploading-test-cases",
        "title": "Uploading Test Cases"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-via-csv-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Via CSV",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#via-csv",
    "content": "Under the \"Test Cases\" tab on the \"Test Suite Details\" page, there is a blue \"Upload Test Cases\" button.\nClicking that button will open a modal that allows you to bulk upload test cases via a CSV file.",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "uploading-test-cases",
        "title": "Uploading Test Cases"
      },
      "h3": {
        "id": "via-csv",
        "title": "Via CSV"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-via-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Via API",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#via-api",
    "content": "To upload test cases via API, check out the Test Cases API documentation.",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "uploading-test-cases",
        "title": "Uploading Test Cases"
      },
      "h3": {
        "id": "via-api",
        "title": "Via API"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-function-calling-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Function Calling",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#function-calling",
    "content": "Prompts can output different modalities, which at Vellum we call input and output types. One increasingly popular output type for models if function/tool calling. You can use Vellum Test Suites to ensure that your model is producing the correct function call based on any given combination of inputs.\nFirst, you will want to edit the Output Variable type of the test suite to the \"Function Call\" type:\nOutput Function Type\nNext, define the Expected Output type to be of type \"Function Call\" too:\nExpected Function Type\nYou can then use any Metric to help ensure that your prompt is outputting function calls that perform well across your test cases! Here's an example of a test suite using Exact Match as the Metric:\nFunction Call Tests",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "function-calling",
        "title": "Function Calling"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-testing-workflows-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Testing Workflows",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#testing-workflows",
    "content": "Just like Prompts, Workflows can be tested too.\nThe key difference Workflow Test Suites have is that Workflows may have multiple outputs.\nYou may choose to test some of them, or all of them.\nWorkflow Test Suites can be run from the \"Evaluations\" tab in the Workflow Builder.\nIt works very similarly as testing prompts, but you can create new test cases inline.\nOne common pitfall is trying to attach a Test Suite where the output variable is named completion\nto a Workflow where the output variable is something else. You will receive a warning when this happens.\nInterface Mismatch\nInterface Match",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "testing-workflows",
        "title": "Testing Workflows"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-viewing-workflow-test-case-entitys-execution-details-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Viewing Workflow Test Case Entity's Execution Details",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#viewing-workflow-test-case-entitys-execution-details",
    "content": "To help you diagnose issues with workflows you can click on the \"View Workflow Details\" button located within a test case's value cell to view the details.\nWorkflow Executions2",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "testing-workflows",
        "title": "Testing Workflows"
      },
      "h3": {
        "id": "viewing-workflow-test-case-entitys-execution-details",
        "title": "Viewing Workflow Test Case Entity's Execution Details"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.quantitative-evaluation-testing-functions-external-to-vellum-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/quantitative-evaluation",
    "pathname": "/help-center/evaluation/quantitative-evaluation",
    "title": "Testing Functions External to Vellum",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#testing-functions-external-to-vellum",
    "content": "Not only can Vellum's evaluation framework be used to test Prompts & Workflows hosted in Vellum, it can also be used\nto evaluate the outputs of arbitrary functions hosted externally to Vellum.\nFor example, you might test a prompt chain that lives in your codebase and that's defined using another third party\nlibrary. This can be particularly useful if you want to incrementally migrate to Vellum Prompts/Workflows, but ensure\nthat the outputs remain consistent.\nFor a detailed example of how to use Vellum's evaluation framework to test external functions, see the\npython example here",
    "hierarchy": {
      "h0": {
        "title": "Maximize LLM Development Quality with Vellum's Evaluations"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "testing-functions-external-to-vellum",
        "title": "Testing Functions External to Vellum"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.evaluating-rag-pipelines-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "pathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "title": "Evaluating RAG Pipelines",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "How to evaluate and maintain high quality RAG pipelines in Vellum",
    "content": "Retrieval Augmented Generation (RAG) is a powerful technique to improve your LLM output quality by providing it relevant data - usually retrieved from an external knowledgebase.\nIn Vellum, setting up your RAG pipeline is straightforward using our Documents feature. Upload and vectorize your knowledgebase for use in minutes.\nFor more details on how to set up a RAG pipeline in Vellum, see common architectures here.\nOnce you have your RAG workflow set up, a challenging but important and often overlooked aspect is evaluating quality. When it comes to RAG, you're not only interested in the quality of your LLM response (the Generation), but also the context being returned from your vector database (the Retrieval).\nEssentially, you're checking to see how effectively your system retrieves relevant information from a knowledge base and then uses it to produce reliable and precise responses or content.\nRAG evaluation is a continuous process - running these evaluations gives confidence when initially deploying your RAG into production but the benefits continue post-deployment.\nRunning these evals in production help you understand your system's current performance and identify areas for optimization.\nUsing Out-of-Box RAG Metrics in Test Suites, Vellum makes it easy to evaluate, monitor, and continuously improve your RAG pipeline over time without concern of introducing regressions.\nRead on to see how you can evaluate your RAG pipeline in Vellum!"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.evaluating-rag-pipelines-set-up-your-rag-pipeline-for-evaluation-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "pathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "title": "Set up your RAG pipeline for Evaluation",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#set-up-your-rag-pipeline-for-evaluation",
    "content": "Step 1: Create a Document Index and upload your documents (follow this article for tips: Uploading Documents)\n\nStep 2: Add a Search Node in your Workflow\n\nStep 3: Add a Prompt Node that takes the results of your Search Node as an input variable\n\nStep 4: Link the output of the Prompt Node to a Final Output Node (for evaluating Generation)\n\nStep 5: Link the output of the Search Node to a Final Output Node (for evaluating Retrieval)\n\nStep 5: Set up your Workflow variables and hit Run!\n\n\nOnce your RAG pipeline runs and passes visual inspection, it's time to set up your Test Suite.\nRAG Pipeline Workflow",
    "hierarchy": {
      "h0": {
        "title": "Evaluating RAG Pipelines"
      },
      "h1": {
        "id": "rag-evaluation-in-vellum",
        "title": "RAG Evaluation in Vellum"
      },
      "h2": {
        "id": "set-up-your-rag-pipeline-for-evaluation",
        "title": "Set up your RAG pipeline for Evaluation"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.evaluating-rag-pipelines-set-up-your-test-suite-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "pathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "title": "Set up your Test Suite",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#set-up-your-test-suite",
    "content": "Step 1: Create a Test Suite for this Workflow (follow this article for more info: Quantitatively Evaluating Outputs\n\nStep 2: Add the following Ragas Metrics: Ragas - Faithfulness, Ragas - Answer Relevance, Ragas - Context Relevancy\n\nStep 3: Map the Test Suite variables to the Metric Inputs\n\nStep 4: Add your Test Cases and hit Run!\n\n\nRagas Metrics\nNow you can see how well your RAG pipeline performs across a bank of test cases!\nDepending on your results, you can adjust the appropriate component in your RAG system.\nRagas Test Suite Results",
    "hierarchy": {
      "h0": {
        "title": "Evaluating RAG Pipelines"
      },
      "h1": {
        "id": "rag-evaluation-in-vellum",
        "title": "RAG Evaluation in Vellum"
      },
      "h2": {
        "id": "set-up-your-test-suite",
        "title": "Set up your Test Suite"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.evaluating-rag-pipelines-generation-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "pathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "title": "Generation",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#generation",
    "content": "Answer Relevance and Faithfulness are Generation evals that measure the quality of the LLM response and guard against hallucinations.\nIf you see low performance here, you can optimize your Prompt.\nTry adjusting the Prompt itself, tweak Model parameters, or try a different Model for better performance.\nRead more about Prompt Engineering best practices from the Vellum team:\nPrompt Engineering Tips for Claude\n\nPrompt Engineering Tips for GPT",
    "hierarchy": {
      "h0": {
        "title": "Evaluating RAG Pipelines"
      },
      "h1": {
        "id": "rag-evaluation-in-vellum",
        "title": "RAG Evaluation in Vellum"
      },
      "h2": {
        "id": "set-up-your-test-suite",
        "title": "Set up your Test Suite"
      },
      "h3": {
        "id": "generation",
        "title": "Generation"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.evaluating-rag-pipelines-retrieval-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "pathname": "/help-center/evaluation/evaluating-rag-pipelines",
    "title": "Retrieval",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#retrieval",
    "content": "Context Relevancy is a Retrieval eval. If you see low performance here, you can optimize your Document Indexes.\nTry different embedding strategies, chunking sizes, and add metadata filtering so the context returned is precise and relevant to the question being asked.\nIf these methods don't improve performance enough, make sure the documents you've uploaded are clean from any noise or extraneous elements that can negatively impact their vector representation and your results.\nThis includes:\nHeader / footer info\n\nExtra or special characters\n\nNew Lines\n\nInconsistent formatting (including capitalizations)\n\n\nOnce the documents are processed, you can also try more sophisticated Workflow methods such as splitting your knowledge base into separate Document Indexes and dynamically selecting the right Document Index to use in your Search Node.\nThis method often involves an additional LLM call from a simpler model (think GPT-3.5 turbo) that is used to categorize and select the correct Document Index base on the question being asked.\n\n\nTo learn more about Retrieval Augmented Generation and the most effective\nMetrics to use in your RAG pipelines, check out our blog\narticle",
    "hierarchy": {
      "h0": {
        "title": "Evaluating RAG Pipelines"
      },
      "h1": {
        "id": "rag-evaluation-in-vellum",
        "title": "RAG Evaluation in Vellum"
      },
      "h2": {
        "id": "set-up-your-test-suite",
        "title": "Set up your Test Suite"
      },
      "h3": {
        "id": "retrieval",
        "title": "Retrieval"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Leveraging Online Evaluations for LLM Development with Vellum",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how Vellum's Online Evaluations feature continuously assesses LLM outputs, ensuring model quality across diverse deployment scenarios.",
    "content": "Online Evaluations in Vellum provide a powerful way to continuously assess the quality of your deployed LLM applications.\nThis feature allows you to monitor and evaluate the performance of your prompts or workflows in real-time as they're being used in production."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-step-1-create-and-deploy-your-llm-application-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Step 1: Create and Deploy Your LLM Application",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-1-create-and-deploy-your-llm-application",
    "content": "Start by creating either a Workflow in the Workflow Sandbox or a Prompt in the Prompt Sandbox.\n\nOnce you're satisfied with what you've created, deploy your Workflow or Prompt.",
    "hierarchy": {
      "h0": {
        "title": "Leveraging Online Evaluations for LLM Development with Vellum"
      },
      "h1": {
        "id": "getting-started-with-online-evaluations",
        "title": "Getting Started with Online Evaluations"
      },
      "h2": {
        "id": "step-1-create-and-deploy-your-llm-application",
        "title": "Step 1: Create and Deploy Your LLM Application"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-step-2-configure-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Step 2: Configure Metrics",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-2-configure-metrics",
    "content": "After deployment, you can configure Metrics to evaluate your LLM application's performance:\nConfigure Metrics for use in Online Evals\nNavigate to your Prompt or Workflow Deployment.\n\nLocate the \"Metrics\" tab in the tab bar.\n\nIn the Metrics tab, configure which Metrics you'd like like to use to evaluate the performance of your Deployment.\n\nSave your changes. From this point forward, every execution of your Deployment will be automatically evaluated against these Metrics.\n\n\nSee results of Metrics alongside Execution details\n\n\nFor information on using and defining Metrics in Vellum, see our Metrics page.",
    "hierarchy": {
      "h0": {
        "title": "Leveraging Online Evaluations for LLM Development with Vellum"
      },
      "h1": {
        "id": "getting-started-with-online-evaluations",
        "title": "Getting Started with Online Evaluations"
      },
      "h2": {
        "id": "step-2-configure-metrics",
        "title": "Step 2: Configure Metrics"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-step-3-understanding-online-evaluations-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Step 3: Understanding Online Evaluations",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-3-understanding-online-evaluations",
    "content": "Online Evaluations offer several key benefits for LLM application development:\nReal-time Performance Monitoring: Continuously assess your Deployment's performance as it handles live requests.\n\nQuality Assurance: Ensure your LLM application maintains high standards even as input patterns may shift over time.\n\nRegression Detection: Quickly identify any degradation in performance, allowing for swift corrective action.\n\nInsight-Driven Improvement: Use the gathered data to inform future iterations and improvements of your LLM application.",
    "hierarchy": {
      "h0": {
        "title": "Leveraging Online Evaluations for LLM Development with Vellum"
      },
      "h1": {
        "id": "getting-started-with-online-evaluations",
        "title": "Getting Started with Online Evaluations"
      },
      "h2": {
        "id": "step-3-understanding-online-evaluations",
        "title": "Step 3: Understanding Online Evaluations"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-selecting-the-right-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Selecting the Right Metrics",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#selecting-the-right-metrics",
    "content": "When configuring Metrics for use with Online Evaluations, it's essential to choose the right ones to align with your specific use case and quality standards. Here are some key considerations to keep in mind:\nYou should start by defining what \"good\" means to you and how you might decompose your definition of \"good\" into multiple smaller dimensions that are easier to measure individually.\n\nFrom there, you can select Metrics provided by Vellum that align with these dimensions, or you can define your own.\n\nNote that for now, Metrics are only able to operate on the inputs sent to a Deployment and the outputs generated by it.\nIn the future, Metrics will also be able to operate on Actuals\n(i.e. end-user feedback send back to Vellum), such that they can more effectively measure accuracy.\n\nIf you'd like advice on which Metrics to use, please free to reach out to the Vellum team for guidance!",
    "hierarchy": {
      "h0": {
        "title": "Leveraging Online Evaluations for LLM Development with Vellum"
      },
      "h1": {
        "id": "selecting-the-right-metrics",
        "title": "Selecting the Right Metrics"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-viewing-evaluation-results-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Viewing Evaluation Results",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#viewing-evaluation-results",
    "content": "To access your Online Evaluation results:\nGo to your Prompt or Workflow's Deployment details page.\n\nNavigate to the \"Executions\" tab.\n\nClick on an individual Execution ID to view its details.\n\nIn the Execution Details page, you'll find the evaluation results based on your configured metrics.\n\n\nYou can analyze these results to gain insights into your Deployment's strengths and areas for improvement.",
    "hierarchy": {
      "h0": {
        "title": "Leveraging Online Evaluations for LLM Development with Vellum"
      },
      "h1": {
        "id": "viewing-evaluation-results",
        "title": "Viewing Evaluation Results"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-multiple-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Multiple Metrics",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#multiple-metrics",
    "content": "You can configure multiple Metrics within a single Deployment to evaluate its performance across multiple dimensions. This allows for a more comprehensive assessment of your Deployment's capabilities.\nFor example, you might configure a Metric to evaluate whether your LLM application produced a response of an appropriate length and another Metric to assess whether it used the proper tone of voice.",
    "hierarchy": {
      "h0": {
        "title": "Leveraging Online Evaluations for LLM Development with Vellum"
      },
      "h1": {
        "id": "advanced-usage",
        "title": "Advanced Usage"
      },
      "h2": {
        "id": "multiple-metrics",
        "title": "Multiple Metrics"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.evaluation.online-evaluations-conclusion-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/evaluation/online-evaluations",
    "pathname": "/help-center/evaluation/online-evaluations",
    "title": "Conclusion",
    "breadcrumb": [
      {
        "title": "Evaluation & Test Suites",
        "pathname": "/help-center/evaluation"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#conclusion",
    "content": "Online Evaluations in Vellum offer a robust, automated way to ensure the ongoing quality and performance of your LLM applications. By providing continuous, metric-based assessments, this feature empowers you to maintain high standards and make data-driven improvements to your Prompts and Workflows.\nRemember, the key to leveraging Online Evaluations effectively is in thoughtfully configuring your Metrics to align with your specific use case and quality standards. Regularly reviewing and adjusting these Metrics will help you get the most out of this powerful feature.",
    "hierarchy": {
      "h0": {
        "title": "Leveraging Online Evaluations for LLM Development with Vellum"
      },
      "h1": {
        "id": "conclusion",
        "title": "Conclusion"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to add both private and public custom models to your Vellum workspace for enhanced functionality and domain-specific advantages."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Metrics",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#metrics",
    "content": "Vellum comes with a set of Metrics that you can use right away within your Test Suites. We are continually adding new Metrics based on the needs of Vellum users.\nHere are the default Metrics currently available within Vellum:",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-exact-match-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Exact Match",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#exact-match",
    "content": "Check that the output is exactly equal to the target.\nReturns a score of 1 if the output is an exact match, and 0 otherwise.",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      },
      "h2": {
        "id": "exact-match",
        "title": "Exact Match"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-regex-match-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Regex Match",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#regex-match",
    "content": "Check that the specified regular expression can be found in the output.\nReturns a score of 1 if the regular expression matches, and 0 otherwise.\nNote that unless the regular expression is explicitly anchored, it can match anywhere in the output.",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      },
      "h2": {
        "id": "regex-match",
        "title": "Regex Match"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-semantic-similarity-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Semantic Similarity",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#semantic-similarity",
    "content": "Check that the output is semantically similar to the target.\nReturns a score between 0 and 1, where 1 is a perfect match.\nUses a cross encoder to compute the similarity.",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      },
      "h2": {
        "id": "semantic-similarity",
        "title": "Semantic Similarity"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-json-validity-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "JSON Validity",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#json-validity",
    "content": "Check that the output is valid JSON.\nReturns a score of 1 if the output is valid JSON, and 0 otherwise.\n\n\n\n\nThe Metrics below are Ragas\nMetrics designed to evaluate your\nRetrieval Augmented Generation (RAG) systems. For tips on evaluating your RAG\npipeline in Vellum, check out this help center\narticle",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      },
      "h2": {
        "id": "json-validity",
        "title": "JSON Validity"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-ragas---faithfulness-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Ragas - Faithfulness",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#ragas---faithfulness",
    "content": "Faithfulness measures the factual consistency of the generated answer against the given context. It is calculated from answer and retrieved context. The answer is scaled to (0,1) range. Higher the better.\nFor details, see: https://docs.ragas.io/en/latest/concepts/metrics/faithfulness.html",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      },
      "h2": {
        "id": "ragas---faithfulness",
        "title": "Ragas - Faithfulness"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-ragas---answer-relevance-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Ragas - Answer Relevance",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#ragas---answer-relevance",
    "content": "The Metric, Answer Relevancy, focuses on assessing how pertinent the generated answer is to the given prompt. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy.\nFor details, see: https://docs.ragas.io/en/latest/concepts/metrics/answer_relevance.html",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      },
      "h2": {
        "id": "ragas---answer-relevance",
        "title": "Ragas - Answer Relevance"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.out-of-the-box-metrics-ragas--context-relevancy-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/out-of-the-box-metrics",
    "pathname": "/help-center/metrics/out-of-the-box-metrics",
    "title": "Ragas ‚Äì Context Relevancy",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#ragas--context-relevancy",
    "content": "This Metric gauges the relevancy of the retrieved context, calculated based on both the question and contexts. The values fall within the range of (0, 1), with higher values indicating better relevancy.\nFor details, see: https://docs.ragas.io/en/v0.1.5/concepts/metrics/context_relevancy.html",
    "hierarchy": {
      "h0": {
        "title": "Evaluate your LLM Workflows with Dozens of Premade Vellum Metrics"
      },
      "h1": {
        "id": "metrics",
        "title": "Metrics"
      },
      "h2": {
        "id": "ragas--context-relevancy",
        "title": "Ragas ‚Äì Context Relevancy"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Create Custom Reusable Metrics for LLM Evaluation",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to create custom Metrics to evaluate your LLM Workflows with ease. Catch edge-cases, prevent regressions, and ship AI features faster with more confidence!",
    "content": "In addition to the default Metrics, Vellum makes it easy to define custom Reusable Metrics tailored to your specific business logic and use-case.\nThis saves you time and ensures standardized evaluation criteria for your Prompts, Workflows, or external entities you'd like to test.\nLet's create your first Reusable Metric\nVisit the Evaluations tab in Vellum and open the Metrics page\n\nClick the blue Create Metric button at the top-right of the page to open the Create Metric modal\n\nFrom the Metric type dropdown, select JSON Schema Match. To learn about Metric types other than JSON Schema Match, see Vellum's Available Metric Types.\n\nIn the \"Label\" field at the top left, enter \"My First Metric\". The \"Name\" field should autopopulate. This is a unique name that you can use to programmatically identify this Metric.\n\nIn the \"Description\" field, type in \"My first Metric description\"\n\nClick next to configure your Metric and define what the expected output should match\n\nAdd \"name\" and \"email\" properties to the JSON schema\n\nClick Finish to exit the modal and see your newly added Metric card on the Metrics page\n\n\nCongrats! You've now created a Reusable Metric that will be visible when selecting and configuring Metrics within any Test suite.\nCreate New Reusable Metric"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-json-schema-match-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "JSON Schema Match",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#json-schema-match",
    "content": "Check that the output matches a specified JSON schema.\nReturns a score of 1 if the output matches the schema, and 0 otherwise.",
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h2": {
        "id": "available-metric-types",
        "title": "Available Metric Types"
      },
      "h3": {
        "id": "json-schema-match",
        "title": "JSON Schema Match"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-workflow-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Workflow",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow",
    "content": "Run a Workflow to evaluate the output.\nSee Workflow Metric for more details.",
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h2": {
        "id": "available-metric-types",
        "title": "Available Metric Types"
      },
      "h3": {
        "id": "workflow",
        "title": "Workflow"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-code-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Code",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code",
    "content": "Run custom Python code to evaluate the output.\nThe code must include a function named main that takes the function arguments specified when creating the Metric and returns a dictionary with the key score.",
    "code_snippets": [
      {
        "lang": "python",
        "code": "def main(input_1, input_2, target, completion):\n    return {\n        \"score\": 10\n    }"
      },
      {
        "lang": "python",
        "code": "def main(input_1, input_2, target, completion):\n    return {\n        \"score\": 10\n    }"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h2": {
        "id": "available-metric-types",
        "title": "Available Metric Types"
      },
      "h3": {
        "id": "code",
        "title": "Code"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-code-execution-metric-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Code Execution Metric",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code-execution-metric",
    "content": "The Code Execution Metric allows arbitrary Python code execution to be used to produce scores for LLM outputs.\nIt is intended as a quick and powerful way to format outputs and write conditionals without the restrictions of Jinja or Regex.\nAfter selecting the \"Code Execution\" Metric in the UI, a code editor will be provided.\nThere will be a template with the bare minimum for the Metric to run: A main() function that returns a score.",
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h1": {
        "id": "code-execution-metric",
        "title": "Code Execution Metric"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-json-comparison-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "JSON Comparison",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#json-comparison",
    "content": "While JSON Validity checks for whether the output is JSON and JSON Schema Match checks if the output conforms to a structure,\nneither checks for exact key/value matches per test case. Using the following Python code,\nit's possible to check that the output matches a known JSON regardless of order or spacing.",
    "code_snippets": [
      {
        "lang": "python",
        "code": "def main(\n    completion: str,\n    target: str,\n) -> dict:\n    \"\"\"Produces a dict containing at least a \"score\" key with a numerical value.\"\"\"\n    completion_dict = json.loads(completion)\n    target_dict = json.loads(target)\n    completion_set = set(completion_dict.items())\n    target_set = set(target_dict.items())\n    is_equal = completion_set == target_set\n\n    return {\n        \"score\": 1.0 if is_equal else 0.0,\n    }"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h1": {
        "id": "code-execution-metric",
        "title": "Code Execution Metric"
      },
      "h2": {
        "id": "examples",
        "title": "Examples"
      },
      "h3": {
        "id": "json-comparison",
        "title": "JSON Comparison"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-ignore-whitespace-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Ignore Whitespace",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#ignore-whitespace",
    "content": "A common problem with exact match comparison using LLM outputs is that often there is additional leading or trailing whitespace.\nWe can create an exact match Metric that ignores such whitespace with a few short lines of Python.",
    "code_snippets": [
      {
        "lang": "python",
        "code": "def main(\n    completion: str,\n    target: str,\n) -> dict:\n    \"\"\"Produces a dict containing at least a \"score\" key with a numerical value.\"\"\"\n    is_equal = completion.strip() == target.strip()\n\n    return {\n        \"score\": 1.0 if is_equal else 0.0,\n    }"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h1": {
        "id": "code-execution-metric",
        "title": "Code Execution Metric"
      },
      "h2": {
        "id": "examples",
        "title": "Examples"
      },
      "h3": {
        "id": "ignore-whitespace",
        "title": "Ignore Whitespace"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-code-packages-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Code Packages",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code-packages",
    "content": "You can add both pip packages for Python code and npm packages for TypeScript code. You must provide exact package versions and add the import to your code yourself.\nNote that whenever you update your packages list, the first execution after doing so may be slow due to our system creating and caching the custom runtime.\nCode Package example",
    "code_snippets": [
      {
        "lang": "typescript",
        "code": "import * as _ from \"lodash\"\n\nasync function main(variables: {\n  completion: string,\n  target: string,\n}): Promise<{ score: number }> {\n  return {\n    score: variables.target.length + _.floor(7.55),\n  }\n}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h1": {
        "id": "code-execution-metric",
        "title": "Code Execution Metric"
      },
      "h2": {
        "id": "examples",
        "title": "Examples"
      },
      "h3": {
        "id": "code-packages",
        "title": "Code Packages"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-workflow-metric-using-llms-to-evaluate-llms-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Workflow Metric (using LLMs to evaluate LLMs)",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-metric-using-llms-to-evaluate-llms",
    "content": "The Workflow Metric allows you to use a Workflow to evaluate outputs, allowing LLM based evaluation for outputs that may be hard to score via traditional methods.",
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h1": {
        "id": "workflow-metric-using-llms-to-evaluate-llms",
        "title": "Workflow Metric (using LLMs to evaluate LLMs)"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-the-generic-llm-metric-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "The Generic LLM Metric",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#the-generic-llm-metric",
    "content": "We've built a Metric that you can use in your test suites to evaluate the outputs of your Prompts and LLMs using another LLM. This example simply takes a rubric, or set of rules, outputs a 1 if the output passes the criteria in the rubric, or a 0 if it does not, and also outputs a reason for the provided score. You can extend this to give scores between 0 and 1, or to provide more detailed feedback.\n\n\n\n\n\n\n\n\nAdd the Metric to your test suite and add a new input which we'll use to tell the Metric how it should score the output that it's evaluating.\n\n\n\n\nOption #1: Different assertions on different test cases\nAdd a new input to your test suite, connect it to this Metric, and use different rules in that input for each test case.  For example: one row checks that the user is addressed by name during introductions, but this isn't a condition we'd want to test on every test case. It will ultimately depend how you split up your Workflows and Prompts (unit testing vs. integration testing).\nOption #2: Same assertion on every row\nAdd multiple copies of this Metric to your test suite, rename each one according to its purpose, and hardcode a different rule for each.  For example: one could check that every output of a Q&A bot cites a source, another could check that every output of a Math Assistant shows its work.\n\n\nAvoid putting too many rules in a single scoring rubric. Split into multiple Metrics if you have many rules and notice your evaluations aren't performing well.",
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h1": {
        "id": "workflow-metric-using-llms-to-evaluate-llms",
        "title": "Workflow Metric (using LLMs to evaluate LLMs)"
      },
      "h2": {
        "id": "the-generic-llm-metric",
        "title": "The Generic LLM Metric"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.metrics.custom-metrics-setting-up-an-metric-workflow-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/metrics/custom-metrics",
    "pathname": "/help-center/metrics/custom-metrics",
    "title": "Setting up an Metric Workflow",
    "breadcrumb": [
      {
        "title": "Metrics",
        "pathname": "/help-center/metrics"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#setting-up-an-metric-workflow",
    "content": "Create a new Workflow Sandbox.\n\nAdd one input variable for each Test Suite variable you want to pass to the Workflow.\nYou'll map these to the Test Suite variables when setting up the Metric later, so you can name them anything you want.\nExamples of variables you may want to include: the output to be evaluated, the desired output, the inputs to the evaluated prompt.\n\nCreate a Final Output, set the name to score, and set the output type to Number.\n\n[Optional] - create additional outputs to provide more context about the score (\"rationale\" or \"summary\" or \"chat history\" etc.). Great for debugging!\n\nFill in the logic of your Workflow!\n\nDeploy your Workflow using the Deploy button in the top right corner of the Workflow Sandbox.",
    "hierarchy": {
      "h0": {
        "title": "Create Custom Reusable Metrics for LLM Evaluation"
      },
      "h1": {
        "id": "workflow-metric-using-llms-to-evaluate-llms",
        "title": "Workflow Metric (using LLMs to evaluate LLMs)"
      },
      "h2": {
        "id": "setting-up-an-metric-workflow",
        "title": "Setting up an Metric Workflow"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "Streamline Your Prompt Deployment with Vellum",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how Vellum simplifies prompt deployment with observability, version control, and easy integration for better performance."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management-introduction-to-prompt-deployments-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "Introduction to Prompt Deployments",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#introduction-to-prompt-deployments",
    "content": "Now that you‚Äôve used Vellum Playground for prompt engineering and have a prompt that clears your test cases, you‚Äôre ready to start making requests against it. In production, Vellum acts as a high reliability, low latency proxy between your application and the underlying model provider.\nBy deploying a Prompt through Vellum and integrating a 10-line code snippet you get:\nObservability into individual completions and their quality: Tracking completions & measuring quality\n\nVersion Controlled changes to prompts/model without updating code: Changing prompts in production & versioning\n\nRequest Replay to back-test changes and avoid regressions: Backtesting with Vellum\n\nMonitoring of aggregate data to spot trends: Monitoring production traffic\n\n\nLet's take a look at how to actually deploy a Prompt in Vellum",
    "hierarchy": {
      "h0": {
        "title": "Streamline Your Prompt Deployment with Vellum"
      },
      "h2": {
        "id": "introduction-to-prompt-deployments",
        "title": "Introduction to Prompt Deployments"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management-creating-a-prompt-deployment-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "Creating a Prompt Deployment",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#creating-a-prompt-deployment",
    "content": "Deploy Prompt Button\nDeploy Prompt Options",
    "hierarchy": {
      "h0": {
        "title": "Streamline Your Prompt Deployment with Vellum"
      },
      "h2": {
        "id": "creating-a-prompt-deployment",
        "title": "Creating a Prompt Deployment"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management-view-deployment-details-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "View Deployment Details",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#view-deployment-details",
    "content": "The Deployment Overview page shows you details about the currently live version of the Prompt.\nPrompt Deployment Details",
    "hierarchy": {
      "h0": {
        "title": "Streamline Your Prompt Deployment with Vellum"
      },
      "h2": {
        "id": "view-deployment-details",
        "title": "View Deployment Details"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management-integrating-w-vellums-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "Integrating w/ Vellum's API",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#integrating-w-vellums-api",
    "content": "The Deployment Overview page also contains code snippets to make integration simple. We support Python & Typescript clients and have an option to make Curl requests. Optionally, you can also integrate with our Actuals Endpoint to start keeping track of output quality for monitoring and eventually fine tuning. More details about this in the completions & quality help center article.\nGenerate API Code Snippet\nNote that our full API docs can be found at docs.vellum.ai",
    "hierarchy": {
      "h0": {
        "title": "Streamline Your Prompt Deployment with Vellum"
      },
      "h2": {
        "id": "integrating-w-vellums-api",
        "title": "Integrating w/ Vellum's API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management-changing-prompts-in-production-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "Changing Prompts in Production",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#changing-prompts-in-production",
    "content": "With Vellum, you can make changes to your prompts in production without having to make any code changes! This might be useful for a variety of reasons:\nWhen you encounter edge cases in production, you may want to tweak the prompt to accommodate for them\n\nA new model comes out and can provide similar quality at lower cost or lower latency\n\nProduct requirements change and a non-technical member of the team with the proper permissions wants to make changes\n\n\nYou can do this by updating a Prompt Deployment. All updates are version-controlled and past versions can be immediately reverted to at any time (no code chnages required).",
    "hierarchy": {
      "h0": {
        "title": "Streamline Your Prompt Deployment with Vellum"
      },
      "h2": {
        "id": "changing-prompts-in-production",
        "title": "Changing Prompts in Production"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management-updating-a-prompt-deployment-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "Updating a Prompt Deployment",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#updating-a-prompt-deployment",
    "content": "Find the Prompt Sandbox you'd like to deploy and click the \"Deploy\" button.\nDeploy Prompt Button\nThis'll provide the option to update an existing deployment or create a new one. Select \"Update Existing Deployment\" and choose the deployment you'd like to update.\nUpdate Deployment Option\n\n\nNote that code changes will likely be required if you change which input variables the Prompt replies on.",
    "hierarchy": {
      "h0": {
        "title": "Streamline Your Prompt Deployment with Vellum"
      },
      "h2": {
        "id": "changing-prompts-in-production",
        "title": "Changing Prompts in Production"
      },
      "h3": {
        "id": "updating-a-prompt-deployment",
        "title": "Updating a Prompt Deployment"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.prompt-lifecycle-management-prompt-versioning-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/prompt-lifecycle-management",
    "pathname": "/help-center/deployments/prompt-lifecycle-management",
    "title": "Prompt Versioning",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-versioning",
    "content": "After a Prompt Deployment is updated, you'll find a new entry in the \"History\" tab. You can visually inspect how the Prompt has changed\nover time across versions. You can also revert to prior versions at any time. After reverting to a prior version, it's immediately live ‚Äì\nno code changes required.\nPrompt Versioning",
    "hierarchy": {
      "h0": {
        "title": "Streamline Your Prompt Deployment with Vellum"
      },
      "h2": {
        "id": "prompt-versioning",
        "title": "Prompt Versioning"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.observability-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/observability",
    "pathname": "/help-center/deployments/observability",
    "title": "Enhance AI Model Accuracy with Vellum's Observability Tools",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how Vellum's observability in production helps track requests and improve AI model responses with user feedback integration.",
    "content": "After using a Prompt in prompt with your application, you'll likely wonder what the contents of the requests were and whether the model provided reasonable responses. A big benefit of using Vellum's proxy layer via Prompt Deployments is that we automatically keep track of every request and the details you need to debug issues."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.observability-prompt-deployment-completions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/observability",
    "pathname": "/help-center/deployments/observability",
    "title": "Prompt Deployment Completions",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-deployment-completions",
    "content": "You can go to the \"Completions\" tab of any prompt Deployment to see the requests that were made. Columns can be hidden, shown, filtered, and sorted.\nCompletions\nAs you apply filters/sorting, the page's url is updated. You can bookmark this link or share with others to return to the same view later.\nCompletion Columns",
    "hierarchy": {
      "h0": {
        "title": "Enhance AI Model Accuracy with Vellum's Observability Tools"
      },
      "h2": {
        "id": "prompt-deployment-completions",
        "title": "Prompt Deployment Completions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.observability-capturing-end-user-feedback-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/observability",
    "pathname": "/help-center/deployments/observability",
    "title": "Capturing End-User Feedback",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#capturing-end-user-feedback",
    "content": "Vellum has the concept of \"Completion Actuals\" where you can say, for a given request, what the output should have been and what its quality was.\nThis is particularly using for monitoring quality, and later, for usage as training data to fine-tune your own custom model.\nCapturing Actuals works best if your end users have some mechanism (usually via a UI) to provide feedback on the output of the model.\nFor example, you're creating an AI Recruiting Email Generator for recruiters where they can use AI to generate rough draft, you might:\nInfer that if they hit \"Send\" without making edits, the quality was great (a 1.0 in Vellum)\n\nInfer that if they hit \"Discard\" then the quality was bad (a 0.0 in Vellum)\n\nOr you might have a 5-star \"Rating\" system that they can use to explicitly provide feedback on the quality of the output.\n\n\nIn all cases, you could integrate with Vellum's Completion Actuals API to capture this feedback. You can find a code snippet for this in a Prompt Deployment's \"Overview\" tab. It'll look like this:\nDeployment Actuals\nNote that you reference a Completion made previously by the ID that Vellum generates and returns, or by some UUID that you track and provide via the \"external_id\" property.",
    "hierarchy": {
      "h0": {
        "title": "Enhance AI Model Accuracy with Vellum's Observability Tools"
      },
      "h2": {
        "id": "capturing-end-user-feedback",
        "title": "Capturing End-User Feedback"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.monitoring-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/monitoring",
    "pathname": "/help-center/deployments/monitoring",
    "title": "Track Production Trends with Prompt Deployment Monitoring",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Easily monitor request volume, latency, and quality trends in your Prompt Deployment with our intuitive charts and filters.",
    "content": "All the row-level Completions found in the \"Completions\" tab of a Prompt Deployment can\nbe monitored in aggregate via the \"Monitoring\" tab.\nThis is especially useful for spotting trends in things like request volume, latency,\nquality, and more. If there are other visualizations you'd like to see here, please share that feedback with us!\nThe charts you see can be filtered down to specific time ranges using the ‚ÄúRelative Date‚Äù button.\nPrompt Deployment Monitoring\nNumber of Completions: Number of requests made against the Generate endpoint\nAverage Quality over Time: Quality tracked for each completion. This is only\nvisible if Quality is filled out either through the UI or Actuals Endpoint API\nNumber of Completions w/ Actuals Submitted: Number of requests that have an\nassociated quality / Actuals indication\nAverage Latency Over Time: Time taken for the request to complete\nNum LLM Provider Errors Over Time: Number of errors from the LLM provider"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover how to manage Vellum deployments with release tags for better version control in your development workflow."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-introduction-to-deployment-release-tags-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Introduction to Deployment Release Tags",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#introduction-to-deployment-release-tags",
    "content": "As you start having many versions of a Prompt or Workflow, being able to manage these deployment releases becomes an important consideration.\nIn Vellum, you have multiple ways to manage releases so you can easily promote prompt / workflow changes from your development or staging environments into production with as much flexibility or control as required by your team.\nLet's take a look at some of the different release strategies in Vellum!",
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "introduction-to-deployment-release-tags",
        "title": "Introduction to Deployment Release Tags"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-tldr-watch-a-video-walkthrough-instead-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "TL;DR Watch a Video Walkthrough Instead",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#tldr-watch-a-video-walkthrough-instead",
    "content": "This page highlights Prompt Deployments but the same holds true for managing\nyour Workflow Deployment releases",
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "tldr-watch-a-video-walkthrough-instead",
        "title": "TL;DR Watch a Video Walkthrough Instead"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-1-dont-specify-a-release-tag-and-always-use-latest-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Don‚Äôt Specify a Release Tag and Always Use Latest",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#1-dont-specify-a-release-tag-and-always-use-latest",
    "content": "Every time you create a new Prompt or Workflow Deployment or update an existing one, Vellum will automatically assign it as latest.\nIn this approach, you always point to the latest prompt or workflow available for a given Deployment by making your Vellum API requests without providing a specific Release Tag.\nThis method simplifies your deployment process by automatically incorporating any changes that you deploy from your Prompt or Workflow Sandbox.",
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "three-ways-to-release-prompts-or-workflows",
        "title": "Three Ways to Release Prompts or Workflows"
      },
      "h3": {
        "id": "1-dont-specify-a-release-tag-and-always-use-latest",
        "title": "1. Don‚Äôt Specify a Release Tag and Always Use Latest"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-2-use-custom-release-tags-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Use Custom Release Tags",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#2-use-custom-release-tags",
    "content": "For more flexibility, Vellum lets you define Custom Release Tags. Custom Release Tags are floating tags that you define and can be moved by authorized users directly within the Vellum app.\nYou can assign multiple Custom Release Tags to a single Prompt or Workflow Deployment, providing flexibility to granularly assign and update versions across different environments.\nFor example, you can assign Custom Release Tags to point to a version of your prompt in both your ‚ÄúProduction‚Äù and ‚ÄúStaging‚Äù environments.\nThis method offers you the ability to manage your releases according to your own specific workflow and versioning requirements.\n\n\nNote that Custom Release Tags follow a specific format: less than or equal to\n150 characters, begin and end with a Regex word character (i.e., letter,\nnumber, or underscore), contain only word characters, dashes or dots, and do\nnot contain more than one dot in a row",
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "three-ways-to-release-prompts-or-workflows",
        "title": "Three Ways to Release Prompts or Workflows"
      },
      "h3": {
        "id": "2-use-custom-release-tags",
        "title": "2. Use Custom Release Tags"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-3-use-static-release-tags-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Use Static Release Tags",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#3-use-static-release-tags",
    "content": "Every time you create a new Deployment or update an existing one, Vellum creates a unique Static Release Tag tied to that version.\nWhen using Static Release Tags to manage your releases, you can control version increments through code to ensure a structured and controlled release process.\nThis method is ideal if your organization prioritizes strict version management and you want to avoid accidental updates or changes to prompts.\nRelease Tags Types",
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "three-ways-to-release-prompts-or-workflows",
        "title": "Three Ways to Release Prompts or Workflows"
      },
      "h3": {
        "id": "3-use-static-release-tags",
        "title": "3. Use Static Release Tags"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-creating-a-custom-release-tag-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Creating a Custom Release Tag",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#creating-a-custom-release-tag",
    "content": "Release tags can be created:\nWithin the Create New or Update Existing tabs of the Deploy Prompt modal in a Prompt Sandbox or Deploy Workflow modal in a Workflow Sandbox\nCreating Release Tags from Deploy Modal\n\nBy opening the Assign Release Tags modal from the Releases tab of the Deployment Details page",
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "creating-a-custom-release-tag",
        "title": "Creating a Custom Release Tag"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-updating-a-custom-release-tag-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Updating a Custom Release Tag",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#updating-a-custom-release-tag",
    "content": "Release tags can be updated:\nWithin the Update Existing tab of the Deploy Prompt modal in a Prompt Sandbox or Deploy Workflow modal in a Workflow Sandbox\nUpdating Release Tags from Deploy Modal\n\nBy opening the Assign Release Tags modal from the Releases tab of the Deployment Details page\nCreating Release Tags Post Deployment",
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "updating-a-custom-release-tag",
        "title": "Updating a Custom Release Tag"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.deployments.managing-releases-pinning-to-a-release-tag-in-code-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/deployments/managing-releases",
    "pathname": "/help-center/deployments/managing-releases",
    "title": "Pinning to a Release Tag in Code",
    "breadcrumb": [
      {
        "title": "Deployments",
        "pathname": "/help-center/deployments"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#pinning-to-a-release-tag-in-code",
    "content": "Both the Vellum execute_prompt and execute_workflow API‚Äôs accept an optional release_tag parameter to pin your request to a specific release tag. When release tags are updated via the Vellum app to point to new versions of a prompt or workflow, these changes will automatically reflect in these requests.\nIf no release_tag parameter is provided, the request will default to the latest version of that Deployment.\nMore details on how to do this: Vellum API Docs",
    "code_snippets": [
      {
        "code": "curl -X POST \\\n--url \"https://predict.vellum.ai/v1/execute-prompt\" \\\n--header \"Content-Type: application/json\" \\\n--header \"X_API_KEY: $VELLUM_API_KEY\" \\\n--header \"Accept: application/json\" \\\n--data '\n{\n  \"inputs\": [\n    {\n      \"type\": \"STRING\",\n      \"name\": \"string\",\n      \"value\": \"string\"\n    }\n  ],\n  ‚Äúrelease_tag‚Äù: ‚Äústaging‚Äù\n}\n  '\n"
      },
      {
        "code": "curl -X POST \\\n--url \"https://predict.vellum.ai/v1/execute-prompt\" \\\n--header \"Content-Type: application/json\" \\\n--header \"X_API_KEY: $VELLUM_API_KEY\" \\\n--header \"Accept: application/json\" \\\n--data '\n{\n  \"inputs\": [\n    {\n      \"type\": \"STRING\",\n      \"name\": \"string\",\n      \"value\": \"string\"\n    }\n  ],\n  ‚Äúrelease_tag‚Äù: ‚Äústaging‚Äù\n}\n  '\n"
      },
      {
        "code": ""
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Mastering Vellum Deployment ‚Äì Release Tags Explained"
      },
      "h2": {
        "id": "updating-a-custom-release-tag",
        "title": "Updating a Custom Release Tag"
      },
      "h3": {
        "id": "pinning-to-a-release-tag-in-code",
        "title": "Pinning to a Release Tag in Code"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.uploading-documents-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/uploading-documents",
    "pathname": "/help-center/documents/uploading-documents",
    "title": "Easy Guide to Uploading Documents on Vellum AI",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to upload and manage documents on Vellum AI for efficient document indexing and searching. Supports multiple file types.",
    "content": "Any document that you want to query against should be uploaded ahead\nof time at https://app.vellum.ai/document-indexes."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.uploading-documents-what-is-a-document-index-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/uploading-documents",
    "pathname": "/help-center/documents/uploading-documents",
    "title": "What is a Document Index?",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#what-is-a-document-index",
    "content": "Document indexes act as a collection of documents grouped together\nfor performing searches against for a specific use case. For example,\nif you are creating a chatbot to query against OpenAI‚Äôs help center\ndocuments, the text files of each article in the help center would be\nstored in one index. Here's how it looks in Vellum's UI:\nDocument Details",
    "hierarchy": {
      "h0": {
        "title": "Easy Guide to Uploading Documents on Vellum AI"
      },
      "h2": {
        "id": "what-is-a-document-index",
        "title": "What is a Document Index?"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.uploading-documents-how-to-upload-documents-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/uploading-documents",
    "pathname": "/help-center/documents/uploading-documents",
    "title": "How to upload documents?",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#how-to-upload-documents",
    "content": "You can manually upload files through the UI\nor via API.\nUpload Documents\nEach document has a Name and an External ID which are\ninitially populated with the name of the file that you upload.\nName - Human readable text which is how the document will be visible in Vellum's UI (in documents tab)\nExternal ID - As the contents of a document change and the old documents becomes out of date, you can submit the updated document for reindexing re-uploading it and specifying the same External ID.",
    "hierarchy": {
      "h0": {
        "title": "Easy Guide to Uploading Documents on Vellum AI"
      },
      "h2": {
        "id": "how-to-upload-documents",
        "title": "How to upload documents?"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.uploading-documents-supported-file-types-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/uploading-documents",
    "pathname": "/help-center/documents/uploading-documents",
    "title": "Supported File Types",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#supported-file-types",
    "content": "In addition to sending plain strings via API, Vellum also supports uploading files of the following types:\n.csv\n\n.doc\n\n.docx\n\n.pdf\n\n.png\n\n.txt\n\n.xls\n\n.xlsx\n\n\nFor .pdf and .png files, we apply an OCR process to convert the file to a text representation. If you need another file type, please reach out!",
    "hierarchy": {
      "h0": {
        "title": "Easy Guide to Uploading Documents on Vellum AI"
      },
      "h2": {
        "id": "how-to-upload-documents",
        "title": "How to upload documents?"
      },
      "h3": {
        "id": "supported-file-types",
        "title": "Supported File Types"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.uploading-documents-document-size-limits-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/uploading-documents",
    "pathname": "/help-center/documents/uploading-documents",
    "title": "Document Size Limits",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#document-size-limits",
    "content": "Each document can be up to 32MB and 2.5M characters",
    "hierarchy": {
      "h0": {
        "title": "Easy Guide to Uploading Documents on Vellum AI"
      },
      "h2": {
        "id": "how-to-upload-documents",
        "title": "How to upload documents?"
      },
      "h3": {
        "id": "document-size-limits",
        "title": "Document Size Limits"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.uploading-documents-out-of-box-chunking-strategy-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/uploading-documents",
    "pathname": "/help-center/documents/uploading-documents",
    "title": "Out-of-box Chunking Strategy",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#out-of-box-chunking-strategy",
    "content": "Vellum currently uses a static chunking strategy.\nChunking strategy: Overlapping windows w/ sentence splitting\nMin overlap: 50%\nMax characters: 1000\nThis configuration has proven to work well for most use cases. These settings will become configurable in future updates. Please reach out to support@vellum.ai if this chunking strategy doesn‚Äôt work for you and we can work on a solution for you.",
    "hierarchy": {
      "h0": {
        "title": "Easy Guide to Uploading Documents on Vellum AI"
      },
      "h2": {
        "id": "out-of-box-chunking-strategy",
        "title": "Out-of-box Chunking Strategy"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.running-searches-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/running-searches",
    "pathname": "/help-center/documents/running-searches",
    "title": "Using Search to retrieve context in a prompt",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn to add relevant context to your searches in Vellum Playground with simple steps for better query results.",
    "code_snippets": [
      {
        "code": "Answer questions based on the context provided below without\nusing any other knowledge. If the question can't be answered\nusing the provided context say \"Sorry, I don't know.\"\nAnswer in the following format:\n\nQuestion: ..\nAnswer: ..\n\n---\n{context_str}\n---\nQuestion: {query_str}\nAnswer:"
      }
    ],
    "content": "Vellum Search can be used to include relevant context in a prompt at run-time that fits within LLM token window limits. Typically, the query that produces the search results comes from an end-user.\nFor example, here‚Äôs a prompt used to answer questions, pulling the source materials for an answer from a document index. The remainder of this article references variables from this prompt to explain the mechanics."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.running-searches-step-1-how-to-add-relevant-context-to-context_str-variable-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/running-searches",
    "pathname": "/help-center/documents/running-searches",
    "title": "Step 1: How to add relevant context to context_str variable",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-1-how-to-add-relevant-context-to-context_str-variable",
    "content": "In Vellum Playground, each variable has a üîç icon to include search results in Playground\nPrompt Search Icon\nClicking this button opens up a modal to return Search results for a given query. Follow these steps in the modal:\nEnter the Document Index that should be queried against\n\nType the search query (note: this should be the same as the query_str in the prompt variable)\n\nChoose the number of chunks to be returned, the separators between each chunk and hit Run. By default, Vellum returns 3 chunks and uses new lines as separators.\n\nClicking Apply adds these results to the context_str variable\n\n\nPrompt Search Dialog",
    "hierarchy": {
      "h0": {
        "title": "Using Search to retrieve context in a prompt"
      },
      "h2": {
        "id": "step-1-how-to-add-relevant-context-to-context_str-variable",
        "title": "Step 1: How to add relevant context to context_str variable"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.running-searches-step-2-how-to-use-the-context-to-get-results-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/running-searches",
    "pathname": "/help-center/documents/running-searches",
    "title": "Step 2: How to use the context to get results",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#step-2-how-to-use-the-context-to-get-results",
    "content": "Copy/paste the same user query into the query_str variable. Hit Run on the Playground and see the results against a variety of prompts.\nPrompt Search Results",
    "hierarchy": {
      "h0": {
        "title": "Using Search to retrieve context in a prompt"
      },
      "h2": {
        "id": "step-2-how-to-use-the-context-to-get-results",
        "title": "Step 2: How to use the context to get results"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.api-integration-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/api-integration",
    "pathname": "/help-center/documents/api-integration",
    "title": "Easily integrate with Velum‚Äôs Search API",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn to integrate search results in your queries with our easy 3-step process, including API calls and formatting tips.",
    "content": "Once in production, there‚Äôs a 3 step process to add search results in your queries at run-time:\nCall Search API to obtain relevant context (details below)\n\nFormat the returned context and include as a single variable value when making requests to a Vellum Deployment\n\nPass search results to request endpoint while calling the LLM\n\n\nFor Step 3, make sure you have a variable in Vellum Playground where search results are entered. Details to set that up are here: Running Searches in Playground"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.api-integration-search-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/api-integration",
    "pathname": "/help-center/documents/api-integration",
    "title": "Search API",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#search-api",
    "content": "There‚Äôs a code snippet for the Search API in the Document Index. There are 3 variables to call the API:\nindex_name - Index that is searched across\n\nquery - Search query (usually a user input)\n\noptions - Optional configuration that drives search behavior. Namely used to\ndetermine the max number of results returned in the response. You can also use:\n\nweights - to change the prioritization between keyword matches vs semantic similarity\n\nresult_merging - to automatically merge overlapping chunks into larger chunks without redundant content\n\nfilters - to perform rule-based filtering prior to matching on keywords / semantic similarity.\nFor more info, see Metadata Filtering\n\n\nSearch API Code Snippet",
    "hierarchy": {
      "h0": {
        "title": "Easily integrate with Velum‚Äôs Search API"
      },
      "h2": {
        "id": "search-api",
        "title": "Search API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.metadata-filtering-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/metadata-filtering",
    "pathname": "/help-center/documents/metadata-filtering",
    "title": "Improve Retrieval Results with Metadata Filtering",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to refine searches using metadata filtering for precise document retrieval. Perfect for targeted searches.",
    "content": "Some use-cases of Vellum Search require you to narrow in on a subset of documents prior to searching based on keyword match / semantic similarity. For example, you might want to search across historical conversations for a specific user or only across documents that have specific tags.\nYou can do this through metadata filtering.\nMetadata filtering requires that you:\nProvide structured metadata for your documents either upon initial upload or later; and\n\nProvide filter criteria when performing a search.\n\n\nLet‚Äôs see how to do each."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.metadata-filtering-specifying-metadata-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/metadata-filtering",
    "pathname": "/help-center/documents/metadata-filtering",
    "title": "Specifying Metadata",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#specifying-metadata",
    "content": "You can specify metadata for documents through both the UI and API.",
    "hierarchy": {
      "h0": {
        "title": "Improve Retrieval Results with Metadata Filtering"
      },
      "h1": {
        "id": "specifying-metadata",
        "title": "Specifying Metadata"
      }
    },
    "level": "h1"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.metadata-filtering-through-the-ui-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/metadata-filtering",
    "pathname": "/help-center/documents/metadata-filtering",
    "title": "Through the UI",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#through-the-ui",
    "content": "You can provide metadata upon initial upload.\nMetadata Specification\nYou can also view metadata associated with a document and edit it after it‚Äôs been uploaded.\nViewing Metadata",
    "hierarchy": {
      "h0": {
        "title": "Improve Retrieval Results with Metadata Filtering"
      },
      "h1": {
        "id": "specifying-metadata",
        "title": "Specifying Metadata"
      },
      "h3": {
        "id": "through-the-ui",
        "title": "Through the UI"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.metadata-filtering-through-the-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/metadata-filtering",
    "pathname": "/help-center/documents/metadata-filtering",
    "title": "Through the API",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#through-the-api",
    "content": "You can provide metadata as stringified JSON upon initial upload using the upload Documents API here.\nYou can also update a document‚Äôs metadata after-the-fact using the the Document - Partial Update endpoint here.\nNote that in this endpoint, you can simply provide a JSON object (rather than a stringified JSON object as is required during initial upload).",
    "hierarchy": {
      "h0": {
        "title": "Improve Retrieval Results with Metadata Filtering"
      },
      "h1": {
        "id": "specifying-metadata",
        "title": "Specifying Metadata"
      },
      "h3": {
        "id": "through-the-api",
        "title": "Through the API"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.metadata-filtering-filtering-against-metadata-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/metadata-filtering",
    "pathname": "/help-center/documents/metadata-filtering",
    "title": "Filtering Against Metadata",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#filtering-against-metadata",
    "content": "You use the search endpoint to perform a search against an index (documented here). This endpoint exposes an options.filters.metadata field for filtering against your provided metadata prior to matching on keywords/semantic similarity.\nThe syntax of the metadata property supports complex boolean logic and was borrowed from React Query Builder. You can use their demo here to get a feel for the query syntax.\nNote that values for fields must be JSON-deserializable. If you're looking to filter against a string, then the value passed in should contain escaped double quotes.",
    "hierarchy": {
      "h0": {
        "title": "Improve Retrieval Results with Metadata Filtering"
      },
      "h1": {
        "id": "specifying-metadata",
        "title": "Specifying Metadata"
      },
      "h2": {
        "id": "filtering-against-metadata",
        "title": "Filtering Against Metadata"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.documents.metadata-filtering-example-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/documents/metadata-filtering",
    "pathname": "/help-center/documents/metadata-filtering",
    "title": "Example",
    "breadcrumb": [
      {
        "title": "Documents",
        "pathname": "/help-center/documents"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#example",
    "content": "Suppose you have two documents with the following metadata:\nAnd you wanted to perform a search across all documents that are marked as high priority, customer-facing bugs, you would use the following query:",
    "code_snippets": [
      {
        "lang": "json",
        "code": "// Document A\n{\n\t\"tags\": [\n\t\t\"customer-facing\", \"needs-triage\", \"bug\"\n\t],\n\t\"priority\": \"high\"\n}\n// Document B\n{\n\t\"tags\": [\n\t\t\"needs-triage\", \"bug\"\n\t],\n\t\"priority\": \"low\"\n}"
      },
      {
        "lang": "json",
        "code": "{\n\t\t...,\n\t\t\"options\": {\n\t\t\t\"filters\": {\n\t\t\t\t\"metadata\": {\n\t\t\t\t\t\"combinator\": \"AND\",\n\t\t\t\t\t\"rules\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"field\": \"tags\",\n\t\t\t\t\t\t\t\"operator\": \"contains\",\n\t\t\t\t\t\t\t\"value\": \"\\\"customer-facing\\\"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"field\": \"tags\",\n\t\t\t\t\t\t\t\"operator\": \"contains\",\n\t\t\t\t\t\t\t\"value\": \"\\\"bug\\\"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"priority\": \"tags\",\n\t\t\t\t\t\t\t\"operator\": \"+\",\n\t\t\t\t\t\t\t\"value\": \"high\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"negated\": false\n\t\t\t\t}\n\t\t\t}\n\t\t}\n}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Improve Retrieval Results with Metadata Filtering"
      },
      "h1": {
        "id": "specifying-metadata",
        "title": "Specifying Metadata"
      },
      "h2": {
        "id": "filtering-against-metadata",
        "title": "Filtering Against Metadata"
      },
      "h3": {
        "id": "example",
        "title": "Example"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.security.hmac-authentication-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/security/hmac-authentication",
    "pathname": "/help-center/security/hmac-authentication",
    "title": "HMAC Authetication",
    "breadcrumb": [
      {
        "title": "Security",
        "pathname": "/help-center/security"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "This guide will walk you through the process of setting up and using HMAC authentication in Vellum.",
    "content": "This guide will walk you through the process of setting up and using HMAC authentication in Vellum. HMAC authentication provides an additional layer of security for outgoing API calls and webhooks."
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.security.hmac-authentication-setup-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/security/hmac-authentication",
    "pathname": "/help-center/security/hmac-authentication",
    "title": "Setup",
    "breadcrumb": [
      {
        "title": "Security",
        "pathname": "/help-center/security"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#setup",
    "content": "Create a new secret token securely: You can do this in Python using the secrets module. Here's a simple example:\n\n\n\n\nProvide your secret token to Vellum: Navigate to the API keys page. Click the \"Provide HMAC Token\" button and enter your secret token.",
    "code_snippets": [
      {
        "lang": "python",
        "code": "import secrets\nprint(secrets.token_hex(16))"
      },
      {
        "lang": "python",
        "code": "import secrets\nprint(secrets.token_hex(16))"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "HMAC Authetication"
      },
      "h2": {
        "id": "setup",
        "title": "Setup"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.help-center.help-center.security.hmac-authentication-usage-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/help-center/security/hmac-authentication",
    "pathname": "/help-center/security/hmac-authentication",
    "title": "Usage",
    "breadcrumb": [
      {
        "title": "Security",
        "pathname": "/help-center/security"
      }
    ],
    "tab": {
      "title": "Help Center",
      "pathname": "/help-center"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#usage",
    "content": "Only outgoing webhooks and API calls from Vellum include HMAC authentication.\nEach request will contain two headers: X-Vellum-Timestamp and X-Vellum-Signature.\nVerify the timestamp: Check that the value of X-Vellum-Timestamp is within the last 60 seconds.\n\nCreate the message string: Concatenate the following values together, separated by one newline character, into a new string message:\nX-Vellum-Timestamp\n\nThe request method (GET, POST, etc)\n\nThe request URL\n\nThe request body\n\n\n\n\n\n\nVerify the signature. Use the HMAC algorithm with SHA-256 to verify the authenticity of X-Vellum-Signature.",
    "code_snippets": [
      {
        "lang": "python",
        "code": "message = f\"{timestamp}\\n{method}\\n{url}\\n{body}\""
      },
      {
        "lang": "python",
        "code": "message = f\"{timestamp}\\n{method}\\n{url}\\n{body}\""
      },
      {
        "lang": "python",
        "code": "import hmac\nimport hashlib\n\ndef verify(message: str, secret: str, signature: str) -> bool:\n    hash_object = hmac.new(secret.encode(), msg=message.encode(), digestmod=hashlib.sha256)\n    expected_signature = hash_object.hexdigest()\n    return hmac.compare_digest(expected_signature, signature)"
      },
      {
        "lang": "python",
        "code": "import hmac\nimport hashlib\n\ndef verify(message: str, secret: str, signature: str) -> bool:\n    hash_object = hmac.new(secret.encode(), msg=message.encode(), digestmod=hashlib.sha256)\n    expected_signature = hash_object.hexdigest()\n    return hmac.compare_digest(expected_signature, signature)"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "HMAC Authetication"
      },
      "h2": {
        "id": "usage",
        "title": "Usage"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.getting-started-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/getting-started",
    "pathname": "/api-reference/overview/getting-started",
    "title": "Welcome to Vellum",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Dive into Vellum's API docs for endpoint details, parameters, and responses. Use our official Python, Node, or Go clients for stable interaction.",
    "content": "Welcome to Vellum's API documentation! Here you'll find information about the various endpoints available to you,\nas well as the parameters and responses that they accept and return.\nWe will be exposing more and more of our APIs over time as they stabilize. If there is some action you can perform\nvia the UI that you wish you could perform via API, please let us know and we can expose the relevant API here."
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.getting-started-api-stability-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/getting-started",
    "pathname": "/api-reference/overview/getting-started",
    "title": "API Stability",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#api-stability",
    "content": "Some of the APIs documented within are undergoing active development. Use the \n\n and \n\n\ntags to differentiate between those that are stable and those that are not. GA stands for generally available.",
    "hierarchy": {
      "h0": {
        "title": "Welcome to Vellum"
      },
      "h3": {
        "id": "api-stability",
        "title": "API Stability"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.getting-started-base-urls-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/getting-started",
    "pathname": "/api-reference/overview/getting-started",
    "title": "Base URLs",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#base-urls",
    "content": "Some endpoints are hosted separately from the main Vellum API and therefore have a different base url. If this is\nthe case, they will say so in their description.\nUnless otherwise specified, all endpoints use https://api.vellum.ai as their base URL.",
    "hierarchy": {
      "h0": {
        "title": "Welcome to Vellum"
      },
      "h3": {
        "id": "base-urls",
        "title": "Base URLs"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.getting-started-official-api-clients-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/getting-started",
    "pathname": "/api-reference/overview/getting-started",
    "title": "Official API Clients",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#official-api-clients",
    "content": "Vellum maintains official API clients for Python, Node/Typescript, and Go. We recommend using these clients to interact\nwith all stable endpoints. You can find them here:",
    "hierarchy": {
      "h0": {
        "title": "Welcome to Vellum"
      },
      "h3": {
        "id": "official-api-clients",
        "title": "Official API Clients"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.authentication",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/authentication",
    "pathname": "/api-reference/overview/authentication",
    "title": "Authentication",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Learn how to authenticate with the Vellum API using API tokens."
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.authentication-generating-api-keys-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/authentication",
    "pathname": "/api-reference/overview/authentication",
    "title": "Generating API Keys",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#generating-api-keys",
    "content": "The Vellum API uses API keys to authenticate requests. You can view and manage your API keys in the Vellum here.",
    "hierarchy": {
      "h0": {
        "title": "Authentication"
      },
      "h2": {
        "id": "generating-api-keys",
        "title": "Generating API Keys"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.authentication-authentication-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/authentication",
    "pathname": "/api-reference/overview/authentication",
    "title": "Authentication",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#authentication",
    "content": "Authentication is performed using headers. You should include your API key as the value associated with the X_API_KEY header in your requests.\nNote that all API requests must be made over HTTPS. Calls made over plain HTTP will fail. API requests without authentication will also fail.",
    "hierarchy": {
      "h0": {
        "title": "Authentication"
      },
      "h2": {
        "id": "authentication",
        "title": "Authentication"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.api-reference.api-reference.overview.authentication-api-key-best-practices-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/overview/authentication",
    "pathname": "/api-reference/overview/authentication",
    "title": "API Key Best Practices",
    "breadcrumb": [
      {
        "title": "Overview",
        "pathname": "/api-reference/overview"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#api-key-best-practices",
    "content": "The API keys you generate should be treated like passwords. Do not share your API keys in publicly accessible areas such as GitHub, client-side code, etc.",
    "hierarchy": {
      "h0": {
        "title": "Authentication"
      },
      "h2": {
        "id": "api-key-best-practices",
        "title": "API Key Best Practices"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Changelog | October, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-aws-bedrock-support-for-anthropics-claude-35-sonnet-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "AWS Bedrock Support for Anthropic's Claude 3.5 Sonnet",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#aws-bedrock-support-for-anthropics-claude-35-sonnet",
    "content": "October 31st, 2024\nWe've added support for Anthropic's Claude-3-5-sonnet-20241022-v2:0 model on AWS Bedrock.\nAWS Bedrock Support",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "aws-bedrock-support-for-anthropics-claude-35-sonnet",
        "title": "AWS Bedrock Support for Anthropic's Claude 3.5 Sonnet"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-google-cloud-vertex-ai-support-for-anthropics-claude-35-sonnet-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Google Cloud Vertex AI Support for Anthropic's Claude 3.5 Sonnet",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#google-cloud-vertex-ai-support-for-anthropics-claude-35-sonnet",
    "content": "October 31st, 2024\nWe've added support for Anthropic's Claude-3-5-sonnet-20241022-v2:0 model on Google Cloud Vertex AI.\nGoogle Cloud Vertex AI Support",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "google-cloud-vertex-ai-support-for-anthropics-claude-35-sonnet",
        "title": "Google Cloud Vertex AI Support for Anthropic's Claude 3.5 Sonnet"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-retrieve-workspace-secret-or-update-workspace-secret-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Retrieve Workspace Secret or Update Workspace Secret",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#retrieve-workspace-secret-or-update-workspace-secret",
    "content": "October 31st, 2024\nWe've added two new API endpoints for retrieving a Workspace Secret and updating a Workspace Secret.\nFor retrieving a Workspace Secret, check out our GET API here.\n\nFor updating a Workspace Secret, check out our PATCH API here.\n\n\nThis API is available in our SDKs beginning with version 0.8.30.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "retrieve-workspace-secret-or-update-workspace-secret",
        "title": "Retrieve Workspace Secret or Update Workspace Secret"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-prompt-timeout-enabled-for-prompt-deployments-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Prompt Timeout Enabled for Prompt Deployments",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-timeout-enabled-for-prompt-deployments",
    "content": "October 29th, 2024\nYou can now set timeouts for Prompt Deployments. With this, you can ensure that any Prompt Execution will timeout if it lasts longer than the specified amount of time.\nTo set a timeout for a Prompt Deployment, navigate to the \"Parameters\" section within the Prompt Sandbox and scroll down to toggle the \"Timeout\" setting on. You can then set the timeout duration in seconds. After deploying your Prompt, your Prompt Deployment will respect your configured timeout.\nVisit Prompt Parameters to set Timeout\nSet Timeout Duration",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "prompt-timeout-enabled-for-prompt-deployments",
        "title": "Prompt Timeout Enabled for Prompt Deployments"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-reorder-test-suite-variables-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Reorder Test Suite Variables",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#reorder-test-suite-variables",
    "content": "October 24th, 2024\nYou can now reorder Input and Evaluation Variables within a Test Suite's settings page. Drag and drop the variables into the order you prefer. This new order will automatically be reflected in your Evaluation Reports.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "reorder-test-suite-variables",
        "title": "Reorder Test Suite Variables"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-support-for-perplexity-ais-online-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Support for Perplexity AI's Online Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-perplexity-ais-online-models",
    "content": "October 24th, 2024\nWe've added support for Perplexity AI's newest Sonar Online models, which provide real-time web search capabilities integrated directly into the language model.\nCheck out Perplexity AI's online models here:\nThe supported models are:\nLLama 3.1 Sonar Small 128k Online\n\nLLama 3.1 Sonar Large 128k Online\n\nLLama 3.1 Sonar Huge 128k Online\n\n\nThese models offer several key features:\nReal-time web search: The models can perform live internet searches to retrieve up-to-date information.\n\nContextual understanding: They can interpret search results in the context of the user's query.\n\nSource citation: The models provide citations for information sourced from the web.\n\nMultilingual support: They can understand and generate content in multiple languages.\n\nLong-context understanding: The models can handle extended conversations and complex queries.\n\n\nTo use these models in Vellum, simply select the appropriate Sonar Online model when configuring your Prompt or Workflow. The model will automatically perform web searches when needed to supplement its knowledge and provide the most current and relevant information.\nNote: Using these models may result in slightly longer processing times due to the real-time web search functionality, but they offer significantly enhanced capabilities for tasks requiring up-to-date information.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "support-for-perplexity-ais-online-models",
        "title": "Support for Perplexity AI's Online Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-support-for-perplexity-ai-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Support for Perplexity AI Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-perplexity-ai-models",
    "content": "October 24th, 2024\nWe've added support for Perplexity AI as one of our newest model hosts!\nAlong with the launch of the Perplexity AI integration, we've added the following models:\nPerplexity AI: LLama 3.1 Sonar Small 128k Chat\n\nPerplexity AI: LLama 3.1 Sonar Large 128k Chat\n\nPerplexity AI: LLama 3.1 8B Instruct\n\nPerplexity AI: LLama 3.1 70B Instruct\n\n\nPerplexity AI Models",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "support-for-perplexity-ai-models",
        "title": "Support for Perplexity AI Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-support-for-llama-31-lumimaid-70b-and-magnum-v4-72b-models-on-openrouter-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Support for LLama 3.1 Lumimaid 70B and Magnum v4 72B models on OpenRouter",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-llama-31-lumimaid-70b-and-magnum-v4-72b-models-on-openrouter",
    "content": "October 24th, 2024\nWe've added support for the LLama 3.1 Lumimaid 70B and Magnum v4 72B models on OpenRouter!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "support-for-llama-31-lumimaid-70b-and-magnum-v4-72b-models-on-openrouter",
        "title": "Support for LLama 3.1 Lumimaid 70B and Magnum v4 72B models on OpenRouter"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-support-for-gemini-15-flash-8b-model-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Support for Gemini 1.5 Flash 8B Model",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-gemini-15-flash-8b-model",
    "content": "October 23nd, 2024\nIn addition to the existing support for the Gemini 1.5 models, we've added support for the Gemini 1.5 Flash 8B model to Vellum!\nGemini 1.5 Flash 8B",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "support-for-gemini-15-flash-8b-model",
        "title": "Support for Gemini 1.5 Flash 8B Model"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-claude-35-sonnet-2024-10-22-live-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Claude 3.5 Sonnet 2024-10-22 Live!",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#claude-35-sonnet-2024-10-22-live",
    "content": "October 22nd, 2024\nWe've added support for Anthropic's latest 10/22/2024 snapshot of Claude 3.5 Sonnet to Vellum!\nClaude 3.5 Sonnet",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "claude-35-sonnet-2024-10-22-live",
        "title": "Claude 3.5 Sonnet 2024-10-22 Live!"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-support-for-cerebras-ai-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Support for Cerebras-AI Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-cerebras-ai-models",
    "content": "October 22nd, 2024\nWe've added support for Cerebras-AI to Vellum!\nAlong with the launch of the Cerebras-AI API, we've added the following models:\nCerebras-AI: llama3.1-8b\n\nCerebras-AI: llama3.1-70b\n\n\nCerebras-AI Models",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "support-for-cerebras-ai-models",
        "title": "Support for Cerebras-AI Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-configurable-prompt-node-timeouts-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Configurable Prompt Node Timeouts",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#configurable-prompt-node-timeouts",
    "content": "October 22nd, 2024\nYou can now set a max timeout for Prompt Nodes within Workflows. With this, you can ensure that no one LLM invocation will run for too long and slow down the Workflow overall and instead, fail early if it does.\nTo set a timeout for a Prompt Node, simply navigate to the new \"Settings\" section and toggle the \"Timeout\" setting on. You can then set the timeout duration in seconds.\nPrompt Settings",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "configurable-prompt-node-timeouts",
        "title": "Configurable Prompt Node Timeouts"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-new-api-for-listing-entities-in-a-folder-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "New API for Listing Entities in a Folder",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-api-for-listing-entities-in-a-folder",
    "content": "October 20th, 2024\nWe now have a new API endpoint for listing all entities in a folder. This endpoint allows you to retrieve all entities in a folder, including subfolders, with a single API call. You can use this endpoint to quickly get a list of all entities in a folder with high-level metadata about them.\nFor details, check out our API Reference here.\nThis API is available in our SDKs beginning version 0.8.25.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "new-api-for-listing-entities-in-a-folder",
        "title": "New API for Listing Entities in a Folder"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-datadog-and-webhook-logging-beta-integrations-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Datadog and Webhook Logging Beta Integrations",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#datadog-and-webhook-logging-beta-integrations",
    "content": "October 15th, 2024\nLogs for your Prompts, Workflows and Documents can now be streamed to Datadog and external Webhooks. This is useful if you want deeper insight into key events that happen in Vellum in your external systems. For example, you might set up a Datadog alert that fires when there are multiple subsequent failures when executing a Workflow Deployment.\nThese integrations are currently in beta. If you'd like to participate in the beta period and want help setting up the integration, please contact Vellum Support.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "datadog-and-webhook-logging-beta-integrations",
        "title": "Datadog and Webhook Logging Beta Integrations"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-eva-qwen-and-rocinante-added-to-openrouter-integration-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Eva Qwen and Rocinante Added to OpenRouter Integration",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#eva-qwen-and-rocinante-added-to-openrouter-integration",
    "content": "October 13th, 2024\nWe've added 2 additional new models to Vellum via our OpenRouter integration!\nEva Qwen 2.5 14B - A powerful model based on the Qwen architecture.\n\nRocinante 12B - A versatile 12 billion parameter model.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "eva-qwen-and-rocinante-added-to-openrouter-integration",
        "title": "Eva Qwen and Rocinante Added to OpenRouter Integration"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-vertex-ai-embedding-model-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Vertex AI Embedding Model Support",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#vertex-ai-embedding-model-support",
    "content": "October 15th, 2024\nWe're excited to announce the addition of the Vertex AI embedding models text-embedding-004 and text-multilingual-embedding-002 to Vellum!\nThese models can be selected when creating a Document Index.\nVertex AI Embeddings",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "vertex-ai-embedding-model-support",
        "title": "Vertex AI Embedding Model Support"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-new-models-added-to-openrouter-integration-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "New Models Added to OpenRouter Integration",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-models-added-to-openrouter-integration",
    "content": "October 11th, 2024\nWe now have the addition of 8 new models integrated into Vellum via our OpenRouter integration:\nMagnum v2 72B - A powerful model designed to achieve prose quality similar to Claude 3 models.\n\nNous: Hermes 3 405B Instruct - A frontier-level, full-parameter finetune of the Llama-3.1 405B foundation model.\n\nNousResearch: Hermes 2 Pro - Llama-3 8B - An upgraded version of Nous Hermes 2 with improved capabilities.\n\nNous: Hermes 3 405B Instruct (extended) - An extended context version of Hermes 3 405B Instruct.\n\nGoliath 120B - A large LLM created by combining two fine-tuned Llama 70B models.\n\nDolphin 2.9.2 Mixtral 8x22B - An uncensored model designed for instruction following, conversation, and coding.\n\nAnthropic: Claude 3.5 Sonnet (self-moderated) - A faster, self-moderated endpoint of Claude 3.5 Sonnet.\n\nLiquid: LFM 40B MoE - A 40.3B Mixture of Experts (MoE) model for general-purpose AI tasks.\n\n\nThese new models offer a wide range of capabilities, from improved prose quality and instruction following to extended context lengths and specialized tasks like coding. Users can now leverage these models in their Vellum projects, expanding the possibilities for AI-powered applications.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "new-models-added-to-openrouter-integration",
        "title": "New Models Added to OpenRouter Integration"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-workflow-edge-type-improvements-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Workflow Edge Type Improvements",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-edge-type-improvements",
    "content": "October 10th, 2024\nIn the past, it could be quite difficult to achieve a perfectly straight line between two Nodes in a Workflow with the \"smooth-step\" edge type, but those days are behind us, friends.\nYou'll now see that your edges will automagically snap into straight-line connectors whenever they're close-to-horizontal.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "workflow-edge-type-improvements",
        "title": "Workflow Edge Type Improvements"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-autolayout-and-autoconnect-for-workflows-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "AutoLayout and AutoConnect for Workflows",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#autolayout-and-autoconnect-for-workflows",
    "content": "October 10th, 2024\nTwo exciting new features have been added to Workflows ‚Äî AutoLayout and AutoConnect.\nAutoLayout allows you to instantly organize your workflow via algorithm, making it easier than ever to tame even the most-unruly of Workflows.\nAutoConnect will automatically connect any unconnected Nodes in your Workflow by creating edges from left to right (more-or-less).\nBoth of these features are accessible via new buttons in the bottom left toolbar in your Workflow Sandboxes.\nIn the event that you only want to use AutoConnect or AutoLayout on a specific subset of Nodes, simply drag to select and you'll see a new temporary toolbar that allows you to do just that.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "autolayout-and-autoconnect-for-workflows",
        "title": "AutoLayout and AutoConnect for Workflows"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-reorder-entities-in-evaluation-reports-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Reorder Entities in Evaluation Reports",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#reorder-entities-in-evaluation-reports",
    "content": "October 9th, 2024\nYou can now reorder entities in the Evaluation Report table. Simply select the \"Reorder\" option in the entity column's menu to adjust the order to your preference.\nEvaluation Report Entity Reorder",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "reorder-entities-in-evaluation-reports",
        "title": "Reorder Entities in Evaluation Reports"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-online-evaluations-for-workflow-and-prompt-deployments-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Online Evaluations for Workflow and Prompt Deployments",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#online-evaluations-for-workflow-and-prompt-deployments",
    "content": "October 3rd, 2024\nWe're excited to announce the launch of Online Evaluations for Workflow and Prompt Deployments! This new feature allows you to configure Metrics for your Deployments to be evaluated in real-time as they're executed. Key highlights include:\nContinuous Assessment: Automatically evaluate the quality of your deployed LLM applications as they handle live requests.\n\nFlexible Configuration: Set up multiple Metrics to assess different aspects of your Deployment's performance.\n\nEasy Access to Results: View evaluation results directly in the execution details of your Deployments.\n\n\nIt works by configuring Metrics for your Workflow or Prompt Deployment in the new \"Metrics\" tab.\nConfigure Metrics for use in Online Evals\nOnce configured, every execution of your Deployment will be evaluated against these Metrics. You can then view the results alongside the execution details.\nSee results of Metrics alongside Execution details\nFor more details on how to get started with Online Evaluations, check out our help documentation.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "online-evaluations-for-workflow-and-prompt-deployments",
        "title": "Online Evaluations for Workflow and Prompt Deployments"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-openrouter-model-hosting--wizardlm-2-8x22b-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "OpenRouter Model Hosting + WizardLM-2 8x22B",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#openrouter-model-hosting--wizardlm-2-8x22b",
    "content": "October 2nd, 2024\nWe've added OpenRouter as a new model host in Vellum! OpenRouter provides access to a wide range of AI models through a single API, expanding the options of models available to our users.\nAs part of our new OpenRouter integration, we're pleased to introduce the WizardLM-2 8x22B model to our platform. WizardLM-2 8x22B is known for its strong performance across various natural language processing tasks and is now available for use in your Vellum projects.\nOpenRouter Model Host",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "openrouter-model-hosting--wizardlm-2-8x22b",
        "title": "OpenRouter Model Hosting + WizardLM-2 8x22B"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-prompt-caching-support-for-openai-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Prompt Caching Support for OpenAI",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-caching-support-for-openai",
    "content": "October 2nd, 2024\nToday OpenAI introduced Prompt Caching for GPT-4o and o1 models. Subsequent invocations of the same prompt will produce outputs with lower latency and up to 50% reduced costs.\nTo follow this, we've begun capturing cache tokens in Vellum's monitoring layer. With this update, you'll now see the number of Prompt Cache Tokens used by a Prompt Deployment's executions if it's backed by an OpenAI model.\nThis new monitoring data can be used to help analyze your cache hit rate with OpenAI and optimize your LLM spend.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "prompt-caching-support-for-openai",
        "title": "Prompt Caching Support for OpenAI"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-10-filter-and-sort-on-metric-scores-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-10",
    "pathname": "/changelog/2024/2024-10",
    "title": "Filter and Sort on Metric Scores",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#filter-and-sort-on-metric-scores",
    "content": "October 1st, 2024\nYou can now filter and sort on a Metric's score within Evaluation Reports. This makes it easy to find all Test Cases that failed below a given threshold for a given Metric.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | October, 2024"
      },
      "h2": {
        "id": "filter-and-sort-on-metric-scores",
        "title": "Filter and Sort on Metric Scores"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Changelog | September, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-fireworks-llama-32-90b-vision-instruct-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Fireworks Llama 3.2 90B Vision Instruct",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#fireworks-llama-32-90b-vision-instruct",
    "content": "September 30th, 2024\nMeta's most recent open source vision model, Llama 3.2 Vision Instruct, is now available in Vellum.\nThis model excels in visual recognition, image reasoning, captioning, and answering diverse questions related to images and is a great open source option if you're looking for a vision model.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "fireworks-llama-32-90b-vision-instruct",
        "title": "Fireworks Llama 3.2 90B Vision Instruct"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-private-models-cost-tracking-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Private Models Cost Tracking",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#private-models-cost-tracking",
    "content": "September 26th, 2024\nModels that are now created through the Custom Model Carousel on the models page will have\ncost tracking for prompt sandboxes and cost tracking for prompt deployments.\nThis means that you'll be able to see the dollar cost of LLM calls to model providers even for your custom models.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "private-models-cost-tracking",
        "title": "Private Models Cost Tracking"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-google-gemini-15-002-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Google Gemini 1.5 002 Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#google-gemini-15-002-models",
    "content": "September 24th, 2024\nGoogle Gemini's newest 002 models gemini-1.5-pro-002 & gemini-1.5-flash-002 are now available in Vellum! They offer 50% reduced pricing, 2x higher rate limits, and 3x lower latency than the previous Gemini 1.5 models.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "google-gemini-15-002-models",
        "title": "Google Gemini 1.5 002 Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-release-tag-column-and-filter-for-prompt-deployment-execution-table-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Release Tag Column and Filter for Prompt Deployment Execution Table",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#release-tag-column-and-filter-for-prompt-deployment-execution-table",
    "content": "September 24th, 2024\nYou can now view and filter on release tags attached to your prompt executions within the Prompt Deployment Execution Table!\nThis addition allows for quick identification of the release version associated with each execution.\nYou can enable this new column in the Columns dropdown.\nPrompt Deployment Executions Table with Release Tag Filter",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "release-tag-column-and-filter-for-prompt-deployment-execution-table",
        "title": "Release Tag Column and Filter for Prompt Deployment Execution Table"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-new-prompt-caching-columns-for-prompt-deployment-execution-table-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "New Prompt Caching Columns for Prompt Deployment Execution Table",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-prompt-caching-columns-for-prompt-deployment-execution-table",
    "content": "September 23rd, 2024\nA while back Anthropic added support for Prompt Caching. With this update, you'll now see the number of Prompt Cache Read and Cache Creation Tokens used by a Prompt Deployment's executions if it's backed by an Anthropic model.\nThis new monitoring data can be used to help analyze your cache hit rate with Anthropic and optimize your LLM spend.\nPrompt Executions with Cache Tokens",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "new-prompt-caching-columns-for-prompt-deployment-execution-table",
        "title": "New Prompt Caching Columns for Prompt Deployment Execution Table"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-improved-latency-filter-and-sorting-for-workflow-executions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Improved Latency Filter and Sorting for Workflow Executions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#improved-latency-filter-and-sorting-for-workflow-executions",
    "content": "September 23rd, 2024\nYou can now sort and filter by the Latency field in the Workflow Executions Table! This update allows for better prioritization and\nidentification of executions with higher or lower latencies, as well as targeting executions within a range of latencies.\nWe believe these improvements will greatly aid in monitoring and managing workflow executions and their performance and metrics!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "improved-latency-filter-and-sorting-for-workflow-executions",
        "title": "Improved Latency Filter and Sorting for Workflow Executions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-improved-debugging-for-map-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Improved Debugging for Map Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#improved-debugging-for-map-nodes",
    "content": "September 23rd, 2024\nIt used to be difficult to debug problematic iterations when a Map Node failed. We now keep track of each iteration's execution and make it easy to view them. You can page through a Map Node's iterations one-by-one.\nMap Node Rejected Pagination\nEach of these iterations, included the any that failed, are now also show in a Map Node's full screen editor.\nMap Node Rejected Editor\nThe full screen editor now also allows you to cycle through each of an executed Map Node's iterations, making it easy to debug problematic iterations and iterate on the subworkflow used to produce that iteration's execution.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "improved-debugging-for-map-nodes",
        "title": "Improved Debugging for Map Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-resizable-node-editor-panel-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Resizable Node Editor Panel",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#resizable-node-editor-panel",
    "content": "September 20th, 2024\nFor those of you using the new Workflow Builder, you'll now be able to resize the Node Editor Panel. This update makes it much easier to edit complex Conditional Node rules, Chat History Messages, JSON values, and more.\nResizable editor panel",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "resizable-node-editor-panel",
        "title": "Resizable Node Editor Panel"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-evaluations-performance-improvements-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Evaluations Performance Improvements",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#evaluations-performance-improvements",
    "content": "September 17th, 2024\nWhile not as flashy as some of our other updates, we've undergone a major overhaul of our Evaluations backend resulting\nin significant performance improvements to the Evaluations page. Test Suites consisting of thousands of Test Cases\nused to feel sluggish and sometimes not load, but now load successfully and should feel much more responsive.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "evaluations-performance-improvements",
        "title": "Evaluations Performance Improvements"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-cost-tracking-for-prompt-deployment-executions-table-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Cost Tracking for Prompt Deployment Executions Table",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#cost-tracking-for-prompt-deployment-executions-table",
    "content": "September 17th, 2024\nYou can now see the cost of each Prompt Execution in the Prompt Executions Table.\nCost tracking prompt executions\nThis is the next step of many we have planned for improving visibility into LLM costs in Vellum. You might use this to audit expensive calls and optimize your prompts to reduce costs.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "cost-tracking-for-prompt-deployment-executions-table",
        "title": "Cost Tracking for Prompt Deployment Executions Table"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-optimized-prompt-deployment-executions-table-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Optimized Prompt Deployment Executions Table",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#optimized-prompt-deployment-executions-table",
    "content": "September 13th, 2024\nThis update brings a reduction in load times for filters and sorts; in some instances, dropping 2 minute load times to a\nfew seconds.\nWe've achieved this by switching to a more efficient data source, enabling more effective filtering and sorting\ncapabilities. You'll notice faster page load times across the board, resulting in a smoother, more responsive experience\nwhen working with Prompt Deployment Executions.\nThis optimization sets the stage for exciting new features we have in the works. Stay tuned for more updates that\nwill enhance your ability to analyze, and optimize your prompt executions.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "optimized-prompt-deployment-executions-table",
        "title": "Optimized Prompt Deployment Executions Table"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-external-id-filtering-for-workflow-deployment-executions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "External ID Filtering for Workflow Deployment Executions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#external-id-filtering-for-workflow-deployment-executions",
    "content": "September 13th, 2024\nPreviously, when filtering workflow deployment executions by external IDs, you had to provide the exact string match\nto retrieve relevant results.\nNow, you can filter external IDs using a variety of string patterns. You can specify that the external ID\nshould start with, end with, or contain certain substrings. This enhancement allows for more flexible filtering,\nmaking it easier to locate specific workflow deployment executions based on partial matches.\nnew_external_id_filter_options",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "external-id-filtering-for-workflow-deployment-executions",
        "title": "External ID Filtering for Workflow Deployment Executions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-workflow-execution-timeline-view-revamp-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Workflow Execution Timeline View Revamp",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-execution-timeline-view-revamp",
    "content": "September 13th, 2024\nWe have given the Workflow Execution Timeline View a bit of a facelift. Along with a more modern look, we have added a couple quality of life improvements:\nSubworkflows: Instead of needing to navigate to a separate page, you can now expand subworkflows to view their executions details within the same page.\n\nNode Pages: Instead of cluttering the page with the details of all nodes at once, we now display the details for just one node at a time. Click on a node to view its inputs, outputs, and more. Each node has its own permalink so that you can share the url with others.\n\n\nWorkflow Execution Timeline",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "workflow-execution-timeline-view-revamp",
        "title": "Workflow Execution Timeline View Revamp"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-openai-strawberry-o1-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "OpenAI Strawberry (o1) Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#openai-strawberry-o1-models",
    "content": "September 12th, 2024\nOpenAI's newest Strawberry (o1) models o1-preview, o1-mini, o1-preview-2024-09-12, & o1-mini-2024-09-12 are now available in Vellum and have been added to all workspaces!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "openai-strawberry-o1-models",
        "title": "OpenAI Strawberry (o1) Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-interactive-pages-in-single-editor-mode-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Interactive Pages in Single Editor Mode",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#interactive-pages-in-single-editor-mode",
    "content": "September 7th, 2024\nIt used to be that when two people were on the same Prompt/Workflow Sandbox, only one person could edit and interact with the page.\nIf you were a Viewer, you were unable to interact with the page at all and were blocked with a big page overlay.\nNow, the page overlay is gone and Viewers can interact with the page in a read-only mode and perform actions that\ndon't affect the state of the page. This includes things like scrolling, opening modals, copying text, etc.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "interactive-pages-in-single-editor-mode",
        "title": "Interactive Pages in Single Editor Mode"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-expand-cost-in-execute-prompt-apis-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Expand Cost in Execute Prompt APIs",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#expand-cost-in-execute-prompt-apis",
    "content": "September 4th, 2024\nYou can now opt in to receive the cost of a Prompt's execution in the response of the Execute Prompt and\nExecute Prompt Stream APIs.\nThis is helpful if you want to capture the cost of executing a Prompt in your own system or if you want to provide cost\ntransparency to your end users.\nTo opt in, you can pass the expand_meta field in the request body with the cost key set to true.\nYou can expect a corresponding value to be included in the meta field on the response:\nThis functionality is available in our SDKs beginning v0.8.9.",
    "code_snippets": [
      {
        "lang": "json",
        "code": "{\n  ...,\n  \"expand_meta\" : {\n    \"cost\": true\n  }\n}"
      },
      {
        "lang": "json",
        "code": "{\n  ...,\n  \"meta\": {\n    \"cost\" : {\n        \"value\" : 0.000450003,\n        \"unit\" : \"USD\"\n    }\n  }\n}"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "expand-cost-in-execute-prompt-apis",
        "title": "Expand Cost in Execute Prompt APIs"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-default-block-type-preference-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Default Block Type Preference",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#default-block-type-preference",
    "content": "September 4th, 2024\nYou can now set a default Block type to use when defining Prompts in Vellum. Whenever you see the \"Add Block\" or \"Add Message\" options in a Prompt Editor, your preferred Block type will be used.\nBy default, the Block type is set to \"Rich Text,\" the newer option that supports Variable Chips. You can still switch between Block types for individual Blocks within the Prompt Editor.\ndefault block type toggle",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "default-block-type-preference",
        "title": "Default Block Type Preference"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-new-and-improved-code-editor-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "New and Improved Code Editor",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-and-improved-code-editor",
    "content": "September 3rd, 2024\nWe now use Monaco Editor for our code editor that is used by Workflow Code Nodes and custom Code Evaluation Metrics.\nMonaco is the same editor that Visual Studio Code uses under the hood.\nThis offers a number of improvements including IntelliSense, semantic validation and syntax validation. Additionally we now inject Vellum Value types into the editor,\nso you can now have fully typed input values for things such as Chat History. Some of these improvements are currently only available for TypeScript and not Python.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "new-and-improved-code-editor",
        "title": "New and Improved Code Editor"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-vpc-disable-gvisor-option-for-code-execution-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "VPC Disable gVisor Option for Code Execution",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#vpc-disable-gvisor-option-for-code-execution",
    "content": "September 3rd, 2024\nVPC customers of Vellum can now disable gVisor sandboxing for code execution in self-hosted environments to significantly improve the performance of Code Nodes in Workflows.\ngVisor is needed for secure sandboxing in our Managed SASS platform, but in a self hosted environment where you're the only organization,\nit's not strictly required if you trust that users within your org won't run malicious code.\ngVisor self hosted flag",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "vpc-disable-gvisor-option-for-code-execution",
        "title": "VPC Disable gVisor Option for Code Execution"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-09-download-original-document-from-ui-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-09",
    "pathname": "/changelog/2024/2024-09",
    "title": "Download Original Document from UI",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#download-original-document-from-ui",
    "content": "September 2nd, 2024\nYou can now download a file that was originally uploaded as a Document to a Document Index from the UI.\nYou'll find a new \"Download Original\" option in a Document's ‚Ä¢‚Ä¢‚Ä¢ More Menu.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | September, 2024"
      },
      "h2": {
        "id": "download-original-document-from-ui",
        "title": "Download Original Document from UI"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Changelog | August, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-anthropic-google-vertex-ai-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Anthropic Google Vertex AI Support",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#anthropic-google-vertex-ai-support",
    "content": "August 30th, 2024\nWe now support using Anthropic's Claude 3.5 Sonnet, Claude 3 Opus and Claude 3 Haiku Models with Google Vertex AI. You can add them to your workspace from the models page.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "anthropic-google-vertex-ai-support",
        "title": "Anthropic Google Vertex AI Support"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-anthropic-tool-use-api-for-function-calling-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Anthropic Tool Use API for Function Calling",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#anthropic-tool-use-api-for-function-calling",
    "content": "August 30th, 2024\nWe now support using Anthropic's Tool Use API for function calling with Claude 3.5 Sonnet, Claude 3 Opus and Claude 3 Haiku Models. Previously Anthropic function calling had been supported by shimming function call XML into the prompt.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "anthropic-tool-use-api-for-function-calling",
        "title": "Anthropic Tool Use API for Function Calling"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-prompt-node-linked-deployments-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Prompt Node Linked Deployments",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-node-linked-deployments",
    "content": "August 29th, 2024\nWe have reworked the relationship of how Prompt Node's interact with Deployments. Previously, there was:\nNo way to update a Prompt in one spot and have it update in multiple Workflows\n\nConfusing UX around what it meant to import a Prompt\n\n\nToday we are releasing this new setup modal that appears when you create a Prompt Node:\nNew Prompt Node Setup\nThe setup modal contains a new Link to Deployment option. This is a Prompt Node that references a Prompt Deployment directly with a Release Tag. This\nallows for Workflows both in the Sandbox and as a Deployment to automatically pick up changes to the underlying Prompt without needing to update the Workflow\nby pointing to LATEST. To maintain a specific version of a Prompt Deployment, you can specify a user-defined Release Tag to keep the Prompt Node pinned to\na specific version. In this way, they now work exactly as Subworkflow Nodes when you select Link to Deployment there:\nPrompt Node Linked Deployments",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "prompt-node-linked-deployments",
        "title": "Prompt Node Linked Deployments"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-workflow-executed-by-filterable-column-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Workflow Executed By Filterable Column",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-executed-by-filterable-column",
    "content": "August 29th, 2024\nEarlier this month, we restricted the Workflow Deployment Executions table to only show executions invoked via API requests. This helped to filter out all of the noise\nfrom other contexts in which a Workflow Deployment could be invoked, bringing focus to only data from production traffic. However, we've found that are still other contexts in which it's useful to see Workflow Executions.\nYou'll now find a new Executed By column that shows what the immediate \"parent\" context was in which the Workflow was executed. This table is filtered down to just API Request by default, but you can opt in to include additional contexts, such invocation as a Subworkflow via a parent Workflow:\nExecuted By Workflow Filter",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "workflow-executed-by-filterable-column",
        "title": "Workflow Executed By Filterable Column"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-tool-choice-parameter-support-for-openai-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Tool Choice Parameter Support for OpenAI",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#tool-choice-parameter-support-for-openai",
    "content": "August 28th, 2024\nWe are excited to announce that you can now natively specify how prompts handle functions using OpenAI's Tool Choice\nparameter. With the Tool Choice parameter, you can now dictate exactly when tools are used, allowing more precise and effective control of your prompt tools.\nThis feature is now available across all OpenAI models that support functions.\nTool Choice Enablement",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "tool-choice-parameter-support-for-openai",
        "title": "Tool Choice Parameter Support for OpenAI"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-add-metadata-to-workflow-executions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Add Metadata to Workflow Executions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#add-metadata-to-workflow-executions",
    "content": "August 27th, 2024\nYou can now add metadata to your Workflow Executions through the API. This is useful for tracking additional information\nabout your executions, such as the source of the request or any other custom data you want to associate with the\nexecution.\nThis metadata is visible in the Workflow Execution Details page in the Vellum UI.\nYou can view more information at the API documentation.\nWorkflow Execution Details Metadata",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "add-metadata-to-workflow-executions",
        "title": "Add Metadata to Workflow Executions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-new-workflow-editor-beta-release-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "New Workflow Editor Beta Release",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-workflow-editor-beta-release",
    "content": "August 26th, 2024\nOur new Workflow Editor is now available as an opt-in beta release. Next time you open the Workflow Editor, you'll see an announcement with the option to turn on the new Editor experience.\nWe've made a ton of improvements to the Editor UI, and more improvements are in the works. You should find that your Workflows are easier to navigate and edit, and more performant.\nThe beta can also be toggled on or off in the workflow builder settings at any time.\nWe'd love to get your feedback about the new experience, so please let us know what you think!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "new-workflow-editor-beta-release",
        "title": "New Workflow Editor Beta Release"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-view-the-provider-payload-on-a-workflows-prompt-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "View the Provider Payload on a Workflow's Prompt Node",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#view-the-provider-payload-on-a-workflows-prompt-node",
    "content": "August 26th, 2024\nYou can now view the compiled provider payload on a Workflow's Prompt Node. This is useful for debugging and understanding the\nexact data that was sent to the provider during a run, especially if you got some unexpected results.\nWorkflow Provider Payload",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "view-the-provider-payload-on-a-workflows-prompt-node",
        "title": "View the Provider Payload on a Workflow's Prompt Node"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-merging-two-adjacent-prompt-blocks-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Merging Two Adjacent Prompt Blocks",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#merging-two-adjacent-prompt-blocks",
    "content": "August 26th, 2024\nMerging two adjacent prompt blocks in the prompt editor is now possible! This feature is especially useful when you want to combine two prompt long prompt blocks into one.\nYou can find this button in the top right drop down in the prompt editor.\nOnly blocks of the same type can be merged. For example, you can merge two rich text blocks or two Jinja blocks, but you cannot merge a rich text block with a Jinja block.\nYou can easily convert between the two, however, by clicking the three dots in the top right of the block and selecting \"Convert to Jinja\" or \"Convert to Rich Text\".\nMerging Two Adjacent Blocks Dropdown",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "merging-two-adjacent-prompt-blocks",
        "title": "Merging Two Adjacent Prompt Blocks"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-asynchronous-exports-of-evaluation-reports-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Asynchronous Exports of Evaluation Reports",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#asynchronous-exports-of-evaluation-reports",
    "content": "August 26th, 2024\nExports of evaluation reports are now asynchronous. You can export your evaluation report along with its results in CSV or JSON format, and an email will be sent to you once the export is done.\nThis change is especially useful for large evaluation reports, where the export process and download can take some time.\nEvaluation Report Export",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "asynchronous-exports-of-evaluation-reports",
        "title": "Asynchronous Exports of Evaluation Reports"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-json-schema-editor-with-ref-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "JSON Schema Editor with $ref Support",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#json-schema-editor-with-ref-support",
    "content": "August 26th, 2024\nVellum let's you define JSON Schemas in a few different places throughout the app to do things like define Structured Outputs and Function Calls. Previously this UI was just a simple form that allowed you to define basic JSON schemas. This UI has been improved to support direct edits via a raw JSON editor.\nRaw Schema Button\nFrom here, you can edit your JSON schema directly. This raw editor allows you to make use of all features supported by the JSON Schema spec, even if they may not yet be supported by our basic form UI. For example, you can now defined references (i.e. $ref) like this:\nas references:\nRaw Editor References",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "json-schema-editor-with-ref-support",
        "title": "JSON Schema Editor with $ref Support"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-support-for-excel-files-in-document-indexes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Support for Excel Files in Document Indexes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-excel-files-in-document-indexes",
    "content": "August 23rd, 2024\nWe now support uploading .xls and .xlsx files to Document Indexes for indexing and searching.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "support-for-excel-files-in-document-indexes",
        "title": "Support for Excel Files in Document Indexes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-prompt-caching-support-for-anthropic-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Prompt Caching Support for Anthropic",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-caching-support-for-anthropic",
    "content": "August 22nd, 2024\nAnthropic recently released some exciting API changes that allow for Prompt Caching.\nThis new feature allows for caching of frequently used portions of your Prompt for up to 5 minutes; which reduces the latency and cost of subsequent executions that include the same Prompt context.\nThis powerful feature is now natively supported within Vellum! In order to use it, simply toggle the new cache options on a given Prompt Block for the supported\nClaude Sonnet 3.5 and Claude Haiku 3.0 models.\nVellum Prompt Caching",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "prompt-caching-support-for-anthropic",
        "title": "Prompt Caching Support for Anthropic"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-prompt-execution-pages-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Prompt Execution Pages",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-execution-pages",
    "content": "August 22nd, 2024\nIf you wanted to drill into a single Prompt Execution, previously you‚Äôd have to navigate to the Prompt Deployment's Executions table and try to filter for the specific Execution ID\nyou're looking for. Now each row has a navigable link accessible from the table:\nPrompt Execution Link\nThis will navigate you to a dedicated page representing that specific Prompt Execution. From here, you can see details about the Execution like the raw HTTP data sent to and from the provider,\nany actuals recorded, the Vellum inputs and outputs to the prompt, and more!\nPrompt Execution Page",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "prompt-execution-pages",
        "title": "Prompt Execution Pages"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-historical-versions-of-entities-in-evaluation-reports-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Historical Versions of Entities in Evaluation Reports",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#historical-versions-of-entities-in-evaluation-reports",
    "content": "August 21st, 2024\nEarlier this month, we introduced Evaluation Report History, which allows you to view a history of all Evaluation runs and revisit the results of any prior state. We‚Äôve now enhanced this feature by adding the ability to preview or navigate directly to the version of the Workflow or Prompt as it existed during that specific run.\nEvaluation Report History",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "historical-versions-of-entities-in-evaluation-reports",
        "title": "Historical Versions of Entities in Evaluation Reports"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-gpt-4o-finetuning-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "GPT-4o Finetuning",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#gpt-4o-finetuning",
    "content": "August 19th, 2024\nOpenAI's newest GPT-4o models gpt-4o-2024-08-06 and gpt-4o-mini-2024-07-18 are now available as base models to add as OpenAI finetuned models.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "gpt-4o-finetuning",
        "title": "GPT-4o Finetuning"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-workflow-execution-replay--scrubbing-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Workflow Execution Replay & Scrubbing",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-execution-replay--scrubbing",
    "content": "August 18th, 2024\nYou can now replay and scrub through the execution of a Workflow in Workflow Sandbox and Deployment Execution Details pages.\nThis feature is particularly useful for debugging and understanding the flow of your Workflow, especially if it\ncontains loops where a single node might be run more than once.\nWorkflow Execution Replay & Scrubbing",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "workflow-execution-replay--scrubbing",
        "title": "Workflow Execution Replay & Scrubbing"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-openai-structured-outputs-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "OpenAI Structured Outputs Support",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#openai-structured-outputs-support",
    "content": "August 15th, 2024\nOpenAI released some API changes that allow their newest models to support Structured Outputs. This powerful new feature\nenables developers to strictly define the expected JSON object schemas from the model as part of the response through a model parameter, or through a function call. This new functionality is now natively integrated within Vellum!\nTo use within the context of Function Calling, simply toggle on the Strict checkbox for any given Function Call:\nFunction Call Strict\nTo enable Structured Outputs as part of a general OpenAI response, configure the JSON Schema setting as part of model parameters:\nJSON Schema Strict\nBoth places come with upload/download functionality built into the form. Note that for function calling, this means we've reduced the scope of the upload/download to be just the Parameters\nJSON schema field. This allows schemas to be cross-compatible between either location since we are working with an open specification.\nJSON Schema Strict",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "openai-structured-outputs-support",
        "title": "OpenAI Structured Outputs Support"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-native-json-input-variable-support-for-prompts-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Native JSON Input Variable Support for Prompts",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#native-json-input-variable-support-for-prompts",
    "content": "August 14th, 2024\nVellum Prompts have historically been able to accept strings and chat histories as dynamic inputs to their template.\nIf you wanted to operate on JSON, you'd have to pass it as a string and then parse it within the Prompt itself\n(i.e. perform json.loads() within a Jinja Block).\nVellum Prompts now support native JSON as inputs! When you add an input variable to a Prompt, you can now select the new \"JSON\" type.\nJSON Variables Dropdown\nJSON input values will render as prettified JSON objects when referenced in Rich Text Blocks and can be operated on directly\nwithout the need for json.loads() when referenced in Jinja Blocks.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "native-json-input-variable-support-for-prompts",
        "title": "Native JSON Input Variable Support for Prompts"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-workflow-deployment-executions-filtered-to-just-api-executions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Workflow Deployment Executions Filtered to Just API Executions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-deployment-executions-filtered-to-just-api-executions",
    "content": "August 12th, 2024\nOur Workflow Deployment Executions page used to list all executions of a Workflow Deployment, no matter where they were invoked from. However, this\nwould often get confusing because you'd see a mix of results from both eval runs and production traffic in the same view.\nOur Workflow Deployment Executions page now filters down to just those executions that were invoked via the API. Executions from evaluations are still accessible from within the Evaluations UI by hovering over a row and clicking the \"View Workflow Details\" button:\nView Workflow Details",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "workflow-deployment-executions-filtered-to-just-api-executions",
        "title": "Workflow Deployment Executions Filtered to Just API Executions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-add-specific-releases-to-evaluation-reports-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Add Specific Releases to Evaluation Reports",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#add-specific-releases-to-evaluation-reports",
    "content": "August 12th, 2024\nWe've updated Evaluation Reports to give you more control over the releases you evaluate. Previously, you could only add the latest release of a Deployment to your reports. Now, you can select specific releases by their tag, allowing you to compare different versions within your Evaluation Reports.\nAdd Deployment",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "add-specific-releases-to-evaluation-reports",
        "title": "Add Specific Releases to Evaluation Reports"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-workflow-sandbox-latency-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Workflow Sandbox Latency",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-sandbox-latency",
    "content": "August 9th, 2024\nYou can now view the latency of Workflow Sandboxes and their Nodes. To enable viewing latency click the Workflow Sandbox settings gear icon in the top right and turn on the \"View Latency\" option.\nWorkflow Sandbox Latency\nWorkflow Sandbox Latency Settings",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "workflow-sandbox-latency",
        "title": "Workflow Sandbox Latency"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-prompt-sandbox-cost-tracking-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Prompt Sandbox Cost Tracking",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-sandbox-cost-tracking",
    "content": "August 9th, 2024\nYou can now see the dollar cost of a Prompt's execution within both a Prompt Sandbox's Prompt Editor and Comparison Mode views.\nThese costs are calculated using model providers' publicly available pricing data in conjunction with the number of input/output tokens used.\nPrompt Sandbox With Cost Tracking\nPrompt Sandbox Comparison With Cost Tracking\nIf you're curious about a given model's pricing, you can view details in the Model's detail page.\nMLModel Detail Page with Billing Config\nMost popular models already have pricing information populated, with support for even more models following in the coming days.\nShowing cost information in Prompt Sandboxes is just the first step! We'll expose cost details throughout more of Vellum over time.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "prompt-sandbox-cost-tracking",
        "title": "Prompt Sandbox Cost Tracking"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-gpt-4o-2024-08-06-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "GPT-4o 2024-08-06",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#gpt-4o-2024-08-06",
    "content": "August 6th, 2024\nOpenAI's newest GPT-4o model gpt-4o-2024-08-06 is now available in Vellum and has been added to all workspaces!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "gpt-4o-2024-08-06",
        "title": "GPT-4o 2024-08-06"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-deployment-descriptions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Deployment Descriptions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#deployment-descriptions",
    "content": "August 2nd, 2024\nYou can now update your Prompt and Workflow Deployments to include a human-readable description. This is useful for giving other members of your team a high-level summary\nof what the Prompt or Workflow does without needing to parse through the configuration or control flow.\nUpdate Deployment Description\nOnce set, the description will appear as part of the Deployment Details page within the Deployment Info section:\nDisplay Deployment Description",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "deployment-descriptions",
        "title": "Deployment Descriptions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-08-evaluation-report-history-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-08",
    "pathname": "/changelog/2024/2024-08",
    "title": "Evaluation Report History",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#evaluation-report-history",
    "content": "August 1st, 2024\nIt used to be that you could only view the latest set of Evaluation results for a given Prompt or Workflow. But now,\nyou can view a history of all Evaluation runs and go back to view the results of any prior state.\nEvaluation Report History\nThis is particularly helpful if you want to do things like compare the results of two different Evaluation runs,\ndownload the results of a past Evaluation run, or simply view the Test Cases that existed at that time.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | August, 2024"
      },
      "h2": {
        "id": "evaluation-report-history",
        "title": "Evaluation Report History"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Changelog | July, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-metadata-filtering-in-search-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Metadata Filtering in Search Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#metadata-filtering-in-search-nodes",
    "content": "July 31st, 2024\nFor a while now you've been able to supply structured JSON metadata alongside Documents and then filtering on that\nmetadata when making an API call to search across Documents in a Document index (see here for more info).\nHowever, Search Nodes within Workflows didn't offer this same functionality through the UI. The workaround has been to use a\nCode Node or API Node and invoke Vellum's Search API manually.\nWe're happy to share that the UI has reached parity with the API and you can now filter on metadata natively in Search Nodes.\nYou'll be able to construct arbitrarily complex boolean logic using the new Metadata Filters section of the Search Node's\nAdvanced settings.\nSearch Node Metadata Filtering",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "metadata-filtering-in-search-nodes",
        "title": "Metadata Filtering in Search Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-test-suite-test-case-external-ids-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Test Suite Test Case External IDs",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#test-suite-test-case-external-ids",
    "content": "July 30th, 2024\nWe've added a new feature to Test Suites that allows you to optionally assign an external ID to each Test Case.\nThis is useful if you track your Test Cases in an external system and you want to periodically sync them with Vellum.\nYou assign an external ID to each Test Case upon creation and then later upsert Test Cases to that Test Suite,\nkeying off of the external ID.\nUpload Test Suite Test Cases Modal",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "test-suite-test-case-external-ids",
        "title": "Test Suite Test Case External IDs"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-index-page-sorting-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Index Page Sorting",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#index-page-sorting",
    "content": "July 30th, 2024\nWe've added another quality-of-life improvement for the index/file browser pages for Prompts, Documents, Test Suites, and Workflows. You'll now see a \"Sort by\" dropdown next to the other page-level controls. You can now sort both folders' and files' by created date, modified date, and label. If there are other sort fields that you'd find useful, please let us know!\nIndex page sort dropdown\nIndex page sort options",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "index-page-sorting",
        "title": "Index Page Sorting"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-auto-conversion-to-variable-chips-on-paste-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Auto-Conversion to Variable Chips on Paste",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#auto-conversion-to-variable-chips-on-paste",
    "content": "July 30, 2024\nBuilding on our recent update that introduced Prompt Variable Chips, we've improved the experience by adding support for copy/pasting variables across blocks of different types. Now, when you copy text that includes a {{ my_var }} variable reference from a Jinja block and paste it into a Rich Text block, it's seamlessly converted into a variable chip.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "auto-conversion-to-variable-chips-on-paste",
        "title": "Auto-Conversion to Variable Chips on Paste"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-google-vertex-ai-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Google Vertex AI Support",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#google-vertex-ai-support",
    "content": "July 29th, 2024\nWe now support Google Vertex AI models. Previously you could only use Google AI Studio for using Google's models. You can add them to your workspace from the models page.\nVertex AI Usage",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "google-vertex-ai-support",
        "title": "Google Vertex AI Support"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-expandable-meta-params-in-retrieve-provider-payload-endpoint-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Expandable Meta Params in Retrieve Provider Payload Endpoint",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#expandable-meta-params-in-retrieve-provider-payload-endpoint",
    "content": "July 26th, 2024\nFor a while now we've had an API for compiling a Prompt and retrieving the exact payload that Vellum would send\nto a model provider on your behalf. We now support a new parameter in this API ‚Äì expand_meta. With expand_meta,\nyou can opt-in to return additional metadata relating to the compiled prompt payload. Learn more about which\nfields are expandable in our API docs here.\nThis new field is available in our SDKs starting v0.7.3.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "expandable-meta-params-in-retrieve-provider-payload-endpoint",
        "title": "Expandable Meta Params in Retrieve Provider Payload Endpoint"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-prompt-node-usage-in-workflows-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Prompt Node Usage in Workflows",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-node-usage-in-workflows",
    "content": "July 25th, 2024\nYou can now see token counts and other usage metrics appear in Prompt Node results when invoking Workflows in the Workflow Sandbox:\nPrompt Node Usage\nThis setting is now on by default, but can be toggled off in the Workflow Builder Settings.\nYou can also now return usage data when invoking a Workflow Deployment via API, by passing in True\nto the expand_meta.usage parameter on either Execute Workflow endpoints.",
    "code_snippets": [
      {
        "lang": "python",
        "code": "stream = client.execute_workflow_stream(\n  workflow_deployment_name=\"demo\",\n  inputs=[\n    WorkflowRequestInputRequest_String(\n      type=\"STRING\",\n      name=\"foo\",\n      value=\"bar\",\n    ),\n  ],\n  event_types=[\"WORKFLOW\", \"NODE\"],\n  expand_meta=WorkflowExpandMetaRequest(\n    usage=True\n  )\n)\n\nfor event in stream:\n  if event.type == \"NODE\" and event.data.state == \"FULFILLED\":\n    node_result_data = event.data.data\n    if node_result_data and node_result_data.type == \"PROMPT\":\n      print(node_result_data.data.execution_meta.usage)"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "prompt-node-usage-in-workflows",
        "title": "Prompt Node Usage in Workflows"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-enabledisable-all-workflow-node-mocks-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Enable/Disable All Workflow Node Mocks",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#enabledisable-all-workflow-node-mocks",
    "content": "July 25th, 2024\nMocking Prompt Nodes helps to save token usage and time when developing the later stages of your Workflow. However, once the Workflow is in a good state, it's often useful to run\nthe full Workflow end-to-end without mocks to make sure it all comes together. Previously, you had to enable/disable each mock individually. Now, beneath the scenario inputs there\nis a toggle that allows you to enable/disable all mocks in a workflow at once.\nEnable Disable All Mocks",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "enabledisable-all-workflow-node-mocks",
        "title": "Enable/Disable All Workflow Node Mocks"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-support-for-bulk-upserting-test-suite-test-cases-via-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Support for Bulk Upserting Test Suite Test Cases via API",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-bulk-upserting-test-suite-test-cases-via-api",
    "content": "July 24th, 2024\nFor a while now we've had an API for creating, replacing, and deleting Test Cases in a Test Suite in bulk.\nWe now support a fourth operation in this API ‚Äì upsert. With upsert, you can provide an external_id and a Test Case\npayload. If there is already a Test Case with that external_id, it'll be replaced. Otherwise, it'll be created.\nThis new operation is available in our SDKs starting v0.6.12.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "support-for-bulk-upserting-test-suite-test-cases-via-api",
        "title": "Support for Bulk Upserting Test Suite Test Cases via API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-llama-31-on-groq-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Llama 3.1 on Groq",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#llama-31-on-groq",
    "content": "July 23rd, 2024\nMeta's newest Llama 3.1 models are now available in Vellum through our Groq integration!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "llama-31-on-groq",
        "title": "Llama 3.1 on Groq"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-deployed-prompt-variant-display-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Deployed Prompt Variant Display",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#deployed-prompt-variant-display",
    "content": "July 19th, 2024\nWhen on the Prompt Deployment Overview page, you can now see the name of the Prompt Variant that's been deployed.\nThis is useful if your Prompt Sandbox has multiple Prompt Variants that you were comparing against one another\nand you're not sure which one is currently deployed.\nDeployed Prompt Variant Display",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "deployed-prompt-variant-display",
        "title": "Deployed Prompt Variant Display"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-improvements-to-prompt-chat-history-variables-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Improvements to Prompt Chat History Variables",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#improvements-to-prompt-chat-history-variables",
    "content": "July 18th, 2024\nIt used to be that Prompts that accepted a dynamic Chat History required an input variable whose name was specifically $chat_history.\nThis nomenclature caused frequent confusion and was a bit cumbersome to work with.\nNow, you can name Chat History input variables whatever you want and even rename them after-the-fact. As part of this,\nwe've also centralized input variable definitions so that whether you want to create a String variable or a Chat History variable,\nyou can do so via the \"Add\" button in the \"Input Variables\" section of the Prompt Editor.\nAdd Prompt Input Variable Button",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "improvements-to-prompt-chat-history-variables",
        "title": "Improvements to Prompt Chat History Variables"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-copyable-text-to-clipboard-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Copyable Text to Clipboard",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#copyable-text-to-clipboard",
    "content": "July 18th, 2024\nWe‚Äôve introduced the ability to copy Prompt Variant IDs, Document Indexes, Models, Workflow Deployment Names and IDs, Document Keys, and Prompt Deployment Names and IDs to clipboard.\nThis feature comes with an enhanced UI with intuitive indicators and tooltips for copyable fields.\nCopy Text to Clipboard\nCopy Text to Clipboard",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "copyable-text-to-clipboard",
        "title": "Copyable Text to Clipboard"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-gpt-4o-mini-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "GPT-4o Mini",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#gpt-4o-mini",
    "content": "July 18th, 2024\nOpenAI's newest GPT-4o Mini models gpt-4o-mini & gpt-4o-mini-2024-07-18 are now available in Vellum and have been added to all workspaces!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "gpt-4o-mini",
        "title": "GPT-4o Mini"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-prompt-variable-chips-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Prompt Variable Chips",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-variable-chips",
    "content": "July 18th, 2024\nIt used to be that any time you wanted to reference a variable in a Prompt, you did so using {{ myVariable }} syntax.\nWhile powerful if you need to use more complex Jinja templating syntax, using double-curlies for simple variable substitution\ncan be a bit cumbersome.\nThey are harder to visually parse from the rest of your Prompt\n\nThey can get confusing when dealing with json, which also uses double-curly brackets\n\nWhenever you rename a variable, you need to hunt down its usages.\n\n\nTo make this easier, we've introduced a new way to reference variables in Prompts: Variable Chips.\nVariable Chips are small, clickable chips that you can reference in your Prompt text. You can add them by beginning to\ntype {{  or by typing /. Renaming a variable automatically renames all of its references.\nVariable chips can be used in the new \"Rich Text\" block type. New Prompt blocks will default to Rich Text, but you can\nchange existing blocks to Rich Text by clicking the block type dropdown in the block's toolbar and converting from Jinja\nto Rich Text and vice versa.\nCheck out a full video demo here:",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "prompt-variable-chips",
        "title": "Prompt Variable Chips"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-new-layout-for-sandbox-evaluations-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "New Layout for Sandbox Evaluations",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-layout-for-sandbox-evaluations",
    "content": "July 17th, 2024\nPreviously, when a Prompt/Workflow had multiple Test Suites associated with it, we'd shown them all on the page at once. This made navigation difficult (you had to scroll up and down to see each) and could also lead to performance issues. We've addressed these issues updating the page layout to display just one Test Suite at a time with a searchable select input that allows you to easily load and view each table one at a time.\nSandbox Evaluation Select",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "new-layout-for-sandbox-evaluations",
        "title": "New Layout for Sandbox Evaluations"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-new-add-document-to-document-index-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "New \"Add Document to Document Index\" API",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-add-document-to-document-index-api",
    "content": "July 16th, 2024\nWe've introduced a new API for adding previously uploaded Documents to a Document Index. This API is useful when you have a Document that\nhad previously been added to one Document Index and you want to add it to another without having to re-upload its contents altogether. It's available in our SDKs\nbeginning version 0.6.10. You can find docs for this new API here.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "new-add-document-to-document-index-api",
        "title": "New \"Add Document to Document Index\" API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-prompt-deployment-executions-table-improvements-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Prompt Deployment Executions Table Improvements",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-deployment-executions-table-improvements",
    "content": "July 12th, 2024\nWe've made several quality-of-life enhancements to the Prompt Deployment Executions table, simplifying the process of adding and editing 'Desired Output' values. The entire table has been updated to align with the design of our other tables, such as Evaluations, ensuring a familiar editing experience. Additionally, it is now easier than ever to expand/collapse and copy values.\nMoreover, we've significantly improved the consistency and usability of the 'Quality' column. You can now edit quality ratings with a single click, and the 'Desired Output' column will automatically update to reflect your rating where applicable.\nPrompt Deployment Executions Table",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "prompt-deployment-executions-table-improvements",
        "title": "Prompt Deployment Executions Table Improvements"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-constant-values-in-workflow-node-inputs-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Constant Values in Workflow Node Inputs",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#constant-values-in-workflow-node-inputs",
    "content": "July 11th, 2024\nIt's often the case that you might want to specify a constant value as a Workflow Node Input, either as the input's primary value or as its fallback value.\nThe solution up until now was to specify a Templating Node, have it output a constant value, and then feed its output to the downstream Node.\nToday, we are releasing the ability to inline constant values directly within Workflow Node inputs! First, start typing in the Node Input until the no options modal shows:\nNew Constant Link\nA modal will appear to specify your value:\nNew Constant Modal\nUpon confirming, Vellum will use an icon to denote that the input value represents a constant. As part of this work, we also added icons for all other Node Input types:\nConstant Value Display\nNote that constant values will always drop to the last fallback option of a given Node input, and there can only be maximum one constant defined per input.\nThis is due to the nature fallback values ‚Äì fallbacks are only used if other values aren't available (i.e. the node that produced the value hadn't executed yet). In the case of constants, their values are always present.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "constant-values-in-workflow-node-inputs",
        "title": "Constant Values in Workflow Node Inputs"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-test-case-csv-upload-in-evaluation-reports-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Test Case CSV Upload in Evaluation Reports",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#test-case-csv-upload-in-evaluation-reports",
    "content": "July 9th, 2024\nWe‚Äôve introduced the ability to upload Test Cases to a Test Suite directly from within the Evaluations tab of a Prompt or Workflow. Now, you'll find an \"Upload Test Cases\" button in the table header of every Evaluations table, for both Workflows and Prompt Sandboxes whereas previously, you needed to first navigate to the Test Suite itself and upload from there.\nTest Case Upload in Evaluation Reports",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "test-case-csv-upload-in-evaluation-reports",
        "title": "Test Case CSV Upload in Evaluation Reports"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-index-page-list-view-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Index Page List View",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#index-page-list-view",
    "content": "July 3rd, 2024\nWe‚Äôve introduced a list-view toggle to the index/file browser pages for Prompts, Documents, Test Suites, and Workflows. Your preferred view will be saved automatically by entity type, allowing you to, for instance, default to list view for Prompts and grid view for Documents.\nIndex Page List View",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "index-page-list-view",
        "title": "Index Page List View"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-07-collapsible-index-page-sections-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-07",
    "pathname": "/changelog/2024/2024-07",
    "title": "Collapsible Index Page Sections",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#collapsible-index-page-sections",
    "content": "July 2nd, 2024\nYou can now collapse sections on the index/file browser pages for Prompts, Documents, Test Suites, and Workflows. Simply click the heading of any section to toggle the visibility of all folders and items within that section.\nCollapsible Index Page Sections",
    "hierarchy": {
      "h0": {
        "title": "Changelog | July, 2024"
      },
      "h2": {
        "id": "collapsible-index-page-sections",
        "title": "Collapsible Index Page Sections"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Changelog | June, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-map-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Map Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#map-nodes",
    "content": "June 27th, 2024\nOften times when designing a workflow you need to iterate over an array and run the same operation on each item.\nPreviously this was only accomplishable by manually creating the loop by connecting Nodes in a tedious layout.\nTo make this process easier, we are now introducing Map Nodes! Map Nodes work in the same way that array map functions do in many common programming languages.\nThe Nodes take a JSON array as an input and iterate over it, running a Subworkflow for each item. The Subworkflow is provided with three input variables for the iteration item, index and the array.\nThe output of every Subworkflow is then combined into a single array as a Node output.\nMap Nodes also support up to 12 concurrent iterations.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "map-nodes",
        "title": "Map Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-inline-subworkflow-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Inline Subworkflow Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#inline-subworkflow-nodes",
    "content": "June 26th, 2024\nSubworkflow nodes are a powerful node within Vellum Workflows that allow users to create reusable units of node logic. However up until now, they necessitated\ndeveloping the Workflow in a separate Sandbox, and for that Workflow to be deployed in order to reference it in a particular Workflow.\nToday, we are releasing Inline Subworkflows! They empower users to create and group together modular units of nodes directly within the context of an existing\nWorkflow. The node spawns its own editor and supports similar UX as the parent Workflow such as all existing nodes and copy/paste.\n\nFor more details, check out our new help center doc.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "inline-subworkflow-nodes",
        "title": "Inline Subworkflow Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-claude-35-sonnet-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Claude 3.5 Sonnet Support",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#claude-35-sonnet-support",
    "content": "June 20th, 2024\nWe now support the new Claude 3.5 Sonnet model. It has already been automatically added to all workspaces.\nWe also support the model hosted through AWS Bedrock. You can add it to your workspace from the models page.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "claude-35-sonnet-support",
        "title": "Claude 3.5 Sonnet Support"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-workflow-notes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Workflow Notes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-notes",
    "content": "June 13th, 2024\nTo help you organize and document your Workflows we've added Workflow Notes with customizable colors and font sizes. You can find Workflow Notes in the Workflow Nodes drag and drop selector.\nWorkflow Notes",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "workflow-notes",
        "title": "Workflow Notes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-workflow-node-comments-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Workflow Node Comments",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-node-comments",
    "content": "June 13th, 2024\nYou can now add a comment to any Workflow Node to help you document your Workflow's logic. To add a comment click the chat bubble icon on the top right of the Node to open up the comment section.\nNode Comments",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "workflow-node-comments",
        "title": "Workflow Node Comments"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-breadcrumb-context-menus-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Breadcrumb Context Menus",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#breadcrumb-context-menus",
    "content": "June 11th, 2024\nYou'll now see breadcrumbs that show the folder path whenever visiting the details of an entity in Vellum. This is helpful for seeing the file structure and easily navigating up to a parent folder.\nWith this, you can also rename a parent folder by right-clicking on its breadcrumb rather than having to first navigate to its parent.\nLastly, can also now access all of an entity's \"More Menu\" options by right-clicking its card when on the entity's grid view.\nBreadcrumb Context Menus",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "breadcrumb-context-menus",
        "title": "Breadcrumb Context Menus"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-override-vellum-provided-api-keys-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Override Vellum Provided API Keys",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#override-vellum-provided-api-keys",
    "content": "June 10th, 2024\nYou can now provide your own API keys for models that Vellum provides API keys for such as Fireworks hosted models. To do so, click the 3 dot menu on a Model card and click the \"Set API Key\" option.\nAPI Key Override",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "override-vellum-provided-api-keys",
        "title": "Override Vellum Provided API Keys"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-undo-and-redo-for-workflow-sandboxes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Undo and Redo for Workflow Sandboxes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#undo-and-redo-for-workflow-sandboxes",
    "content": "June 7th, 2024\nMade a mistake while editing a workflow you want to undo? Good news, you can now undo and redo from within Workflow Sandboxes by using keyboard shortcuts or by clicking the new undo and redo buttons.\nWorkflow Undo Redo",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "undo-and-redo-for-workflow-sandboxes",
        "title": "Undo and Redo for Workflow Sandboxes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-support-for-multiple-outputs-in-workflow-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Support for Multiple Outputs in Workflow Metrics",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-multiple-outputs-in-workflow-metrics",
    "content": "June 7th, 2024\nUsing Vellum Workflows to power custom LLM Metrics (i.e. have one AI grade another AI) is super powerful, but to date,\nyou've only been able to use Workflows that produce a single score output.\nWe now have official support for Workflow Metrics that produce multiple outputs! As long as the Workflow used as\nyour Metric has at least one Final Output Node of type NUMBER named score, you can add as many additional Final Output Nodes\nwith custom names and types as you like.\nAll outputs are shown when the Metric is used in an Evaluation Report.\nWorkflow Sandbox and Variant IDs\nNote: only the score output is aggregated and shown in the aggregate view.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "support-for-multiple-outputs-in-workflow-metrics",
        "title": "Support for Multiple Outputs in Workflow Metrics"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-api-for-updating-a-test-suites-test-cases-in-bulk-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "API for Updating a Test Suite's Test Cases in Bulk",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#api-for-updating-a-test-suites-test-cases-in-bulk",
    "content": "June 6th, 2024\nFor a while now you've been able to programmatically upsert\nand delete Test Cases in a Test suite individually.\nHowever, this can be problematic if you want to operate on many Test Cases at once. To solve this, we've added an API to create, replace, and delete Test Cases in bulk.\nCheck out the new Bulk Test Case Operations API in our docs here.\nNote: this API is available in our SDKs beginning version 0.6.4.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "api-for-updating-a-test-suites-test-cases-in-bulk",
        "title": "API for Updating a Test Suite's Test Cases in Bulk"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-apis-for-programmatically-moving-release-tags-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "APIs for Programmatically Moving Release Tags",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#apis-for-programmatically-moving-release-tags",
    "content": "June 5th, 2024\nTo follow up the release of APIs for programmatically deploying Prompts and Workflows,\nwe're excited to also announce APIs for programmatically moving Release Tags.\nWith these APIs, you can create a CI/CD pipeline that automatically moves a Release Tag for one environment from one version of a Prompt/Workflow to another.\nFor example, you might run certain tests or QA processes before promoting STAGING to PRODUCTION.\nTo move a Prompt Deployment Release Tag, check out the API docs here.\nTo move a Workflow Deployment Release Tag, see the API docs here.\nNote: these APIs are available in our SDKs beginning version 0.6.3.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "apis-for-programmatically-moving-release-tags",
        "title": "APIs for Programmatically Moving Release Tags"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-apis-for-programmatically-deploying-promptsworkflows-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "APIs for Programmatically Deploying Prompts/Workflows",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#apis-for-programmatically-deploying-promptsworkflows",
    "content": "June 5th, 2024\nThanks to the desires of a few very forward-thinking customers, we now have APIs to support programmatically deploying prompts and workflows.\nThese APIs can be used as the basis for CI/CD pipelines for Vellum-managed entities.\nWe're super bullish on integrating Vellum with existing release management systems (think, Github Actions) and you can expect\nto see more from us here, soon!\nTo deploy a Prompt, you'll need the IDs of the Prompt Sandbox and the Prompt Variant shown here:\nPrompt Sandbox and Variant IDs\nAnd can then hit the Deploy Prompt endpoint found here.\nSimilarly, to deploy a Workflow, you'll need the IDs of the Workflow Sandbox and the Workflow shown here:\nWorkflow Sandbox and Variant IDs\nAnd can then hit the Deploy Workflow endpoint found here.\nNote: these APIs are available in our SDKs beginning version 0.6.3.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "apis-for-programmatically-deploying-promptsworkflows",
        "title": "APIs for Programmatically Deploying Prompts/Workflows"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-06-image-support-in-claude-3-and-gemini-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-06",
    "pathname": "/changelog/2024/2024-06",
    "title": "Image Support in Claude 3 and Gemini Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#image-support-in-claude-3-and-gemini-models",
    "content": "June 3rd, 2024\nUntil now, GPT-4 was the only multi-modal family of models supported in Vellum that let you parse images and return text.\nVellum now also supports multi-modality for Claude 3 and Gemini models. This means you can now use Vellum's prompt comparison UI and normalized API layer to compare and easily swap between multi-modal models.\nThis is particularly useful if you're trying to extract text from images, classify pictures, and more, and need to find the best model for your specific use-case.\nFor more on how to work with images in Vellum, see our help docs here.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | June, 2024"
      },
      "h2": {
        "id": "image-support-in-claude-3-and-gemini-models",
        "title": "Image Support in Claude 3 and Gemini Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Changelog | May, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-context-menu-for-workflow-edges-and-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Context Menu for Workflow Edges and Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#context-menu-for-workflow-edges-and-nodes",
    "content": "May 31th, 2024\nYou can now right-click on Workflow Edges to open a context menu to allow you to delete them without having to hunt down the trash icon. You can also now right-click on Workflow Nodes to delete them as well.\nWorkflow Context Menu",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "context-menu-for-workflow-edges-and-nodes",
        "title": "Context Menu for Workflow Edges and Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-breadcrumbs-and-page-header-improvements-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Breadcrumbs and Page Header Improvements",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#breadcrumbs-and-page-header-improvements",
    "content": "May 31th, 2024\nWe've significantly improved folder and page breadcrumbs throughout the app. Prompts, Test Suites, Workflows, and Documents now display the entire folder path of your current page, making it much easier to navigate through your folder structure. We've also updated the overflow styling for breadcrumbs: instead of an ellipsis, you'll now see a count of hidden breadcrumbs, which can be accessed via a dropdown menu.\nAdditionally, the pages mentioned above, along with Workflow/Prompt Evaluations and Deployments, now feature the same updated header design.\nBreadcrumbs and header updates",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "breadcrumbs-and-page-header-improvements",
        "title": "Breadcrumbs and Page Header Improvements"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-subworkflow-node-navigation-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Subworkflow Node Navigation",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#subworkflow-node-navigation",
    "content": "May 31st, 2024\nWhen viewing the execution details of a Workflow, Subworkflow nodes executed as part of that run will now have a link to its execution page.\nSubworkflow Navigation",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "subworkflow-node-navigation",
        "title": "Subworkflow Node Navigation"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-prompt-deployment-actuals-metadata-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Prompt Deployment Actuals Metadata",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-deployment-actuals-metadata",
    "content": "May 29th, 2024\nWhen submitting execution Actuals for Prompts, you can now optionally include a metadata field. This field can contain arbitrary data, and will be saved and shown in the Executions tab of your Prompt Deployment.\nPrompt Actuals Metadata\nThis is particularly helpful if you want to capture feedback/quality across multiple custom dimensions. Learn more in our\nAPI docs here.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "prompt-deployment-actuals-metadata",
        "title": "Prompt Deployment Actuals Metadata"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-replay-workflow-from-node-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Replay Workflow from Node",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#replay-workflow-from-node",
    "content": "May 29th, 2024\nOne of the biggest burdens when developing Workflows in Vellum is having to rerun your entire Workflow whenever you want to make\na change to just a single node and want to see its downstream effects.\nYou can now re-run a Workflow from a specific Node! After running a Workflow for the first time, you'll see this new play icon above each Node.\nReplay From Node Icon\nDoing so will re-use results from the previous execution for all upstream nodes and only actually execute the target node and all nodes downstream of it.\nReplay From Node Execution\nWe hope this helps you decrease iteration cycles and save on LLM costs!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "replay-workflow-from-node",
        "title": "Replay Workflow from Node"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-improvements-to-saving-executions-as-scenarios--test-cases-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Improvements to Saving Executions as Scenarios & Test Cases",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#improvements-to-saving-executions-as-scenarios--test-cases",
    "content": "May 29th, 2024\nSaving Prompt/Workflow Deployment Executions from production API calls to an Evaluation dataset as Test Cases is a great\nway to close the feedback loop between monitoring and experimentation. However, this process has historically been\ntime-consuming when you have many Executions to save.\nWe've made a number of improvements to this process:\nYou can now multi-select to bulk save Executions as Test Cases\n\nWe now default to the correct Sandbox/Test Suite when saving Executions as Scenarios/Test Cases\n\nYou'll now see warnings if the Sandbox/Test Suite you're saving to has required variables that are missing from the Execution\n\n\nCheck out a full demo here:",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "improvements-to-saving-executions-as-scenarios--test-cases",
        "title": "Improvements to Saving Executions as Scenarios & Test Cases"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-prompt-sandbox-history-update-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Prompt Sandbox History Update",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-sandbox-history-update",
    "content": "May 28th, 2024\nPreviously, editing past versions of a Prompt Sandbox could be confusing, with unclear indications of which version you were modifying and how it was being saved.\nNow, the history view for a Prompt Sandbox is read-only. To edit a previous version, simply click the Restore button, and a new editable version will be created from that specific version.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "prompt-sandbox-history-update",
        "title": "Prompt Sandbox History Update"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-workflow-deployment-actuals-metadata-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Workflow Deployment Actuals Metadata",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-deployment-actuals-metadata",
    "content": "May 28th, 2024\nWhen submitting execution Actuals for Workflows, you can now optionally include a metadata field. This field can contain arbitrary data, and will be saved and shown in the Executions tab of your Workflow Deployment.\nThis is particularly helpful if you want to capture feedback/quality across multiple custom dimensions.",
    "code_snippets": [
      {
        "code": "curl -X POST https://predict.vellum.ai/v1/submit-workflow-execution-actuals \\\n     -H \"X_API_KEY: \"$VELLUM_API_KEY\"\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"execution_id\": \"be975a69-33c7-4ff0-b6ac-d8008198db1e\",\n  \"actuals\": [\n    {\n      \"output_type\": \"STRING\",\n      \"output_key\": \"final-output\",\n      \"quality\": 0.8,\n      \"metadata\": {\n        \"user_score\": 1.0,\n        \"internal_score\": 1.0,\n        \"internal_notes\": \"The output was not factually correct.\"\n      }\n    }\n  ]\n}'"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "workflow-deployment-actuals-metadata",
        "title": "Workflow Deployment Actuals Metadata"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-guardrail-workflow-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Guardrail Workflow Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#guardrail-workflow-nodes",
    "content": "May 23rd, 2024\nYou can now use Metrics inside of Workflows with the new Guardrail Node! Guardrail Nodes let you run pre-defined evaluation criteria at runtime as part of a Workflow execution so that you can drive downstream behavior based on that Metric's score.\nFor example, if building a RAG application, you might determine whether the generated response passes some threshold for Ragas Faithfulness and if not, loop around to try again.\nGuardrail Nodes",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "guardrail-workflow-nodes",
        "title": "Guardrail Workflow Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-chat-mode-revamp-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Chat Mode Revamp",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#chat-mode-revamp",
    "content": "May 22th, 2024\nChat Mode in Prompt Sandboxes has received a major facelift! The left side of the new interface will be familiar to anyone using the Prompt Editor, while the rest of the interface retains its functionality with a fresh new look. We've also fixed some UX wonk and minor bugs during the restyling process.\nChat Mode Styling Update",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "chat-mode-revamp",
        "title": "Chat Mode Revamp"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-double-click-to-resize-rows--columns-in-prompt-sandboxes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Double-Click to Resize Rows & Columns in Prompt Sandboxes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#double-click-to-resize-rows--columns-in-prompt-sandboxes",
    "content": "May 22th, 2024\nYou can now double-click on resizable row and column edges in both Comparison and Chat modes to auto-expand that row/column to its maximum size. If already at maximum size, double-clicking will reset them to their default size. Additionally, in Comparison mode, double-clicking on cell corners will auto-resize both dimensions simultaneously.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "double-click-to-resize-rows--columns-in-prompt-sandboxes",
        "title": "Double-Click to Resize Rows & Columns in Prompt Sandboxes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-improved-image-support-in-chat-history-fields-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Improved Image Support in Chat History Fields",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#improved-image-support-in-chat-history-fields",
    "content": "May 22th, 2024\nWe've made several changes to enhance the UX of working with images. Chat History messages now include an explicit content-type selector, making it easier to work with image content using supported models. You can now add publicly-hosted images in multiple ways: by pasting an image URL, pasting a copied image, or dragging and dropping an image from another window.\nAdditionally, we've added limited support for embedded images. You can embed an image directly into the prompt by copy/pasting or dragging/dropping an image file from your computer's file browser. This method has a 1MB size limit and is an interim solution as we continue to explore image upload and hosting options.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "improved-image-support-in-chat-history-fields",
        "title": "Improved Image Support in Chat History Fields"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-gemini-15-flash-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Gemini 1.5 Flash",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#gemini-15-flash",
    "content": "May 20th, 2024\nGoogle's Gemini 1.5 Flash model is now available in Vellum. You can add it to your workspace from the models page.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "gemini-15-flash",
        "title": "Gemini 1.5 Flash"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-llama-3-models-on-bedrock-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Llama 3 Models on Bedrock",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#llama-3-models-on-bedrock",
    "content": "May 14th, 2024\nWe now support both of the Llama 3 models on AWS Bedrock. You can add them to your workspace from the models page.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "llama-3-models-on-bedrock",
        "title": "Llama 3 Models on Bedrock"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-gpt-4o-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "GPT-4o Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#gpt-4o-models",
    "content": "May 13th, 2024\nOpenAI's newest GPT-4o models gpt-4o & gpt-4o-2024-05-13 are now available in Vellum and have been added to all workspaces!\nGPT 4o",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "gpt-4o-models",
        "title": "GPT-4o Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-organization-and-workspace-names-in-side-nav-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Organization and Workspace Names in Side Nav",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#organization-and-workspace-names-in-side-nav",
    "content": "May 13th, 2024\nYou can now view the active Organization's name and the active Workspace's name in the left sidebar navigation.\nWorkspace and Org Name Nav",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "organization-and-workspace-names-in-side-nav",
        "title": "Organization and Workspace Names in Side Nav"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-run-all-button-on-evaluation-reports-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Run All Button on Evaluation Reports",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#run-all-button-on-evaluation-reports",
    "content": "May 10th, 2024\nThere's now a \"Run All\" button on evaluation reports that runs a test suite for all variants. Instead of running each variant individually, you can now run them all with one click.\nPrompt Node Execution",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "run-all-button-on-evaluation-reports",
        "title": "Run All Button on Evaluation Reports"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-prompt-node-monitoring-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Prompt Node Monitoring",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-node-monitoring",
    "content": "May 9th, 2024\nVellum is now capturing monitoring data for deployed Prompt Nodes. Whenever a deployed Workflow invokes a Prompt Node, it will now show a link displaying the Prompt Deployment label:\nPrompt Node Monitoring\nClicking on the link will take you to the Prompt's executions page, where you can then see all metadata captured for the execution, including the raw request data sent to the model:\nPrompt Node Execution",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "prompt-node-monitoring",
        "title": "Prompt Node Monitoring"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-groq-support-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Groq Support",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#groq-support",
    "content": "May 9th, 2024\nVellum now has a native integration with the LPU Inference Engine, Groq. All public models on Groq are now available to add to your workspace. Be sure to add your API key as a Secret named GROQ_API_KEY on the API Keys page.\nGroq is an LLM hosting provider that offers incredible inference speed for open source LLMs, including the recently released (and very hyped!) Llama 3 model.\nGroq Support",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "groq-support",
        "title": "Groq Support"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-function-calling-in-prompt-evaluation-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Function Calling in Prompt Evaluation",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#function-calling-in-prompt-evaluation",
    "content": "May 8th, 2024\nPrompts that output function calls can now be evaluated via Test Suites. This allows you to define Test Cases consisting of the inputs to the prompt, and the expected function call, then assert that there's a match. For more, check out our docs.\nFunction Call Prompts",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "function-calling-in-prompt-evaluation",
        "title": "Function Calling in Prompt Evaluation"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-out-of-box-ragas-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Out-of-Box Ragas Metrics",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#out-of-box-ragas-metrics",
    "content": "May 7th, 2024\nTest-driven development for your RAG-based LLM pipelines is now easier than ever within Vellum!\nThree new Ragas Metrics ‚Äì Context Revelancy, Answer Relevance and Faithfulness ‚Äì are now available out-of-box in Vellum. These can be used within Workflow Evaluations to measure the quality of a RAG system.\nFor more info, check out our new help center article on Evaluating RAG Pipelines.\nRagas Metrics",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "out-of-box-ragas-metrics",
        "title": "Out-of-Box Ragas Metrics"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-subworkflow-node-streaming-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Subworkflow Node Streaming",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#subworkflow-node-streaming",
    "content": "May 7th, 2024\nSubworkflow Nodes can now stream their output(s) to parent workflows.\nThis allows you to compose workflows using modular subworkflows without sacrificing the ability to delivery incremental results to your end user.\nNote that only nodes immediately prior to Final Output Nodes can have their output(s) streamed.\nSubworkflow Streaming",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "subworkflow-node-streaming",
        "title": "Subworkflow Node Streaming"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-05-default-test-case-concurrency-in-evaluations-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-05",
    "pathname": "/changelog/2024/2024-05",
    "title": "Default Test Case Concurrency in Evaluations",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#default-test-case-concurrency-in-evaluations",
    "content": "May 4th, 2024\nYou can now configure how many Test Cases should be run in parallel during an Evaluation. You might lower this value\nif you're running into rate limits from the LLM provider, or might increase this value if your rate limits are high.\nTest Case Concurrency",
    "hierarchy": {
      "h0": {
        "title": "Changelog | May, 2024"
      },
      "h2": {
        "id": "default-test-case-concurrency-in-evaluations",
        "title": "Default Test Case Concurrency in Evaluations"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Changelog | April, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-support-for-gemini-15-pro-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Support for Gemini 1.5 Pro",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-gemini-15-pro",
    "content": "April 30th, 2024\nGemini 1.5 Pro is now available in Vellum.\nYou can add it to your workspace through the models page.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "support-for-gemini-15-pro",
        "title": "Support for Gemini 1.5 Pro"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-improved-monitoring-on-workflow-deployments-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Improved Monitoring on Workflow Deployments",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#improved-monitoring-on-workflow-deployments",
    "content": "April 30th, 2024\nWe've added new functionality to the monitoring tab on workflow deployments. It's now possible\nto see a breakdown of executions by the release tag used, and further filter down based\non a specific release tag.\nRelease Tag Monitoring",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "improved-monitoring-on-workflow-deployments",
        "title": "Improved Monitoring on Workflow Deployments"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-reusable-metrics-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Reusable Metrics",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#reusable-metrics",
    "content": "April 30th, 2024\nIntroducing Reusable Metrics!\nMetrics can now be shared across your Test Suites making it easier for you to consistently test and evaluate your Prompt / Workflow quality.\nDefine a suite of Custom Metrics tailored to your business logic and use-case to save time and ensure standardized evaluation criteria.\nMetric Definition",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "reusable-metrics",
        "title": "Reusable Metrics"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-prompt-blocks-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Prompt Blocks",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-blocks",
    "content": "April 30th, 2024\nPrompts can now be be broken down into multiple sections and organized using \"blocks.\" Prompt blocks can be reordered,\nand toggled on or off.\nSplitting your Prompt into multiple blocks can make it easier to navigate complex Prompts and help you focus\non iterating on specific sections. Check out the demo below to see how it works!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "prompt-blocks",
        "title": "Prompt Blocks"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-filtering-executions-on-release-tags-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Filtering Executions on Release Tags",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#filtering-executions-on-release-tags",
    "content": "April 29th, 2024\nIt's now possible to filter workflow deployment executions by the release tag used when executing the workflow.\nThis can be very useful for monitoring differences between releases of a deployment. Are you still using an older\nrelease in production? Are executions of your new release behaving as expected?\nExecution Release Tags",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "filtering-executions-on-release-tags",
        "title": "Filtering Executions on Release Tags"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-faster-queries-on-workflow-deployment-executions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Faster Queries on Workflow Deployment Executions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#faster-queries-on-workflow-deployment-executions",
    "content": "April 26th, 2024\nThe executions tab of the workflow deployments page now fetches historical executions much faster. This tab is a\ngreat way to see how your customers are actually using your deployments.\nIn our test for deployments with over 200k executions, data now loads in under 4 seconds instead of the\nprevious 15+ seconds - a 4x speed improvement.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "faster-queries-on-workflow-deployment-executions",
        "title": "Faster Queries on Workflow Deployment Executions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-support-for-evaluating-external-functions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Support for Evaluating External Functions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-evaluating-external-functions",
    "content": "April 25th, 2024\nVellum's Evaluation framework can now be used to test arbitrary functions defined in your codebase ‚Äì not just\nPrompts and Workflows managed by Vellum.\nFor example, you might test a prompt chain that lives in your codebase and that's defined using another third party\nlibrary. This can be particularly useful if you want to incrementally migrate to Vellum Prompts/Workflows, but ensure\nthat the outputs remain consistent.\nFor a detailed example of how to use Vellum's evaluation framework to test external functions, see the\npython example here",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "support-for-evaluating-external-functions",
        "title": "Support for Evaluating External Functions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-fireworks-finetuned-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Fireworks Finetuned Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#fireworks-finetuned-models",
    "content": "April 24th, 2024\nVellum now supports models that you've fine-tuned on Fireworks AI. You can add your fine-tuned Fireworks model by navigating to the Models page and clicking on the featured model template at the top.\nFireworks Model Template\nNote that only the Mistral family of models are supported currently. If there are other base models that you would like to see supported, please reach out to us!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "fireworks-finetuned-models",
        "title": "Fireworks Finetuned Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-updated-prompt-ui-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Updated Prompt UI",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#updated-prompt-ui",
    "content": "April 23rd, 2024\nWe've updated the prompt editing UI throughout Vellum. You‚Äôll see the new look in the Prompt Editor, Comparison Mode, Chat Mode, Prompt Nodes in Workflows, and Deployment Overviews. This is the first in a series of exciting improvements to the prompt editing experience that will be rolling out over the coming weeks and months.\nNew Prompt Block UI",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "updated-prompt-ui",
        "title": "Updated Prompt UI"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-new-upsert-prompt-sandbox-scenario-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "New Upsert Prompt Sandbox Scenario API",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-upsert-prompt-sandbox-scenario-api",
    "content": "April 23rd, 2024\nThe API for upserting a Prompt Sandbox Scenario now requests and responds with schemas that are more consistent with\nother Vellum APIs, using discriminated unions for improved type safety. This API is available on version 0.4.0 of\nour SDKs.\nYou can find the API documentation for it here.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "new-upsert-prompt-sandbox-scenario-api",
        "title": "New Upsert Prompt Sandbox Scenario API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-function-call-input-in-test-cases-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Function Call Input in Test Cases",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#function-call-input-in-test-cases",
    "content": "April 23rd, 2024\nWorkflows support Function Call values as a valid output type. Because these function calls often come from models, it is valuable to have evaluations on these workflows that ensure that the function call output is what we expect. Test suites in Vellum now support specifying test case input and evaluation values.\nTest Case Function Call",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "function-call-input-in-test-cases",
        "title": "Function Call Input in Test Cases"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-support-for-additional-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Support for Additional Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-additional-models",
    "content": "April 19th, 2024\nThe following models are now available in Vellum:\nLlama-3-70B-Instruct\n\nLlama-3-8B-Instruct\n\nMixtral-8x22B-Instruct-v0.1\n\n\nThey can be added to your workspace through the models page.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "support-for-additional-models",
        "title": "Support for Additional Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-claude-3-opus-prompt-generators-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Claude 3 Opus Prompt Generators",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#claude-3-opus-prompt-generators",
    "content": "April 18th, 2024\nIf you've been using GPT models, you've likely relied on prompt engineering tips that worked well for those models.\nBut when you apply the same prompts to Claude 3 Opus, you might notice they don't perform as expected.\nThis happens because Claude 3 Opus is trained using different methods and data, so the way you prompt it differs\nfrom how you would prompt GPT-4. We have some helpful tips in our guide,\nbut as of today, you can convert your prompts even faster...",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "claude-3-opus-prompt-generators",
        "title": "Claude 3 Opus Prompt Generators"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-gpt-4-to-claude-3-opus-prompts-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "GPT-4 to Claude 3 Opus Prompts",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#gpt-4-to-claude-3-opus-prompts",
    "content": "We've released a free tool for that allows you to paste your GPT-4 prompt and get an adapted Claude 3 Opus prompt\nwith suggestions for dynamic variables. You can try the tool here.\nGPT-4 to Claude 3 Opus",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "claude-3-opus-prompt-generators",
        "title": "Claude 3 Opus Prompt Generators"
      },
      "h3": {
        "id": "gpt-4-to-claude-3-opus-prompts",
        "title": "GPT-4 to Claude 3 Opus Prompts"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-claude-3-opus-prompt-generator-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Claude 3 Opus Prompt Generator",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#claude-3-opus-prompt-generator",
    "content": "If you don't have a working GPT-4 prompt but need to create a prompt for Claude 3 Opus from scratch, you can use our\nsecond new free tool ‚Äì \"Claude Prompt Generator.\"\nThis generator lets you input your 'prompt objective' and creates a suitable prompt for Claude 3 Opus, with\nsuggestions for dynamic variables that you should include. You can try the tool here.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "claude-3-opus-prompt-generators",
        "title": "Claude 3 Opus Prompt Generators"
      },
      "h3": {
        "id": "claude-3-opus-prompt-generator",
        "title": "Claude 3 Opus Prompt Generator"
      }
    },
    "level": "h3"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-max-tokens-warning-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Max Tokens Warning",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#max-tokens-warning",
    "content": "April 10th, 2024\nWhen iterating on a Prompt in Vellum's Prompt Sandbox, you may find that its output stops mid-sentence. This is often\nbecause the \"Max Tokens\" parameter is set too low, or the prompt itself is too long. To help you identify when this is\nthe case, we've added a warning that will appear when this max is hit.\nMax Tokens Warning",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "max-tokens-warning",
        "title": "Max Tokens Warning"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-gpt-4-turbo-04092024-model-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "GPT-4 Turbo 04/09/2024 Model",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#gpt-4-turbo-04092024-model",
    "content": "April 9th, 2024\nOpenAI's newest GPT-4 Turbo model gpt-4-turbo-2024-04-09 is now available in Vellum!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "gpt-4-turbo-04092024-model",
        "title": "GPT-4 Turbo 04/09/2024 Model"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-usage-tracking-in-prompt-sandbox-and-prompt-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Usage Tracking in Prompt Sandbox and Prompt API",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#usage-tracking-in-prompt-sandbox-and-prompt-api",
    "content": "April 9th, 2024\nWe have added the ability for you to track model host usage from the execute-prompt API. This API update is available on version 0.3.21 of our SDKs.\nYou can also now view model host usage in the Prompt Sandbox by enabling the \"Track Usage\" toggle in your Prompt Sandbox's settings.\nUsage Tracking Sandbox",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "usage-tracking-in-prompt-sandbox-and-prompt-api",
        "title": "Usage Tracking in Prompt Sandbox and Prompt API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-new-api-for-listing-a-test-suites-test-cases-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "New API for Listing a Test Suite's Test Cases",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-api-for-listing-a-test-suites-test-cases",
    "content": "April 8th, 2024\nWe have a new API available in beta for listing the Test Cases belonging to a Test Suite at GET /v1/test-suites/{id}/test-cases.\nThis API is available on version 0.3.20 of our SDKs.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "new-api-for-listing-a-test-suites-test-cases",
        "title": "New API for Listing a Test Suite's Test Cases"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-prompt-editor-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Prompt Editor",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-editor",
    "content": "April 5th, 2024\nPrompt Sandboxes have an entirely new view mode: Prompt Editor. It's a dedicated space for iterating on a single Variant and Scenario. All of the features you need to work quickly are easily accessible, and collapsible sections make it simple to free up screen space. There are even more improved experiences and exciting coming down the pike for Prompt Editor, and many of those improvements will make their way into Comparison and Chat Modes, as well.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "prompt-editor",
        "title": "Prompt Editor"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-copy-and-paste-logit-bias-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Copy and Paste Logit Bias",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#copy-and-paste-logit-bias",
    "content": "April 5th, 2024\nYou can now copy logit bias parameters from one Prompt Variant and paste them into another Prompt. This works in both Prompt Sandboxes and Prompt Nodes within Workflows.\nLogit Bias Copy",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "copy-and-paste-logit-bias",
        "title": "Copy and Paste Logit Bias"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-test-suite-improvements-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "Test Suite Improvements",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#test-suite-improvements",
    "content": "April 4th, 2024\nWe've made some changes to our Test Suite UX. Here's what's new:\nSimplified Creation Process: We've broken down the test suite creation into clear, manageable steps, ensuring a more guided and less overwhelming setup.\n\nIn-Context Editing: You can now edit test suites directly from the Prompt or Workflow evaluations page via a new, sleek modal.\n\nEnhanced Error Messaging: We've revamped our error messages to be clearer and more actionable. You'll now receive specific feedback that pinpoints exactly where things went wrong.\n\n\nTest Suite Improvements",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "test-suite-improvements",
        "title": "Test Suite Improvements"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-04-new-apis-for-accessing-test-suite-runs-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-04",
    "pathname": "/changelog/2024/2024-04",
    "title": "New APIs for Accessing Test Suite Runs",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#new-apis-for-accessing-test-suite-runs",
    "content": "April 3rd, 2024\nWe have two new APIs available in beta for accessing your Test Suite Runs:\nA Retrieve endpoint to fetch metadata about the test suite run like it's current state at GET /v1/test_suite_runs/{id}\n\nA List executions endpoint to fetch the results of the test suite run at GET /v1/test_suite_runs/{id}/executions\n\n\nThese APIs are available on version 0.3.15 of our SDKs.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | April, 2024"
      },
      "h2": {
        "id": "new-apis-for-accessing-test-suite-runs",
        "title": "New APIs for Accessing Test Suite Runs"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Changelog | March, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-configurable-chunk-settings-for-document-indexes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Configurable Chunk Settings for Document Indexes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#configurable-chunk-settings-for-document-indexes",
    "content": "March 26th, 2024\nWe've added the ability to configure the chunk size and the overlap between consecutive chunks for Document Indexes.\nYou can find it under the \"Advanced\" section when creating or cloning a Document Index.\nDocument Index Chunk Settings",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "configurable-chunk-settings-for-document-indexes",
        "title": "Configurable Chunk Settings for Document Indexes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-template-node-debugging-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Template Node Debugging",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-template-node-debugging",
    "content": "March 26th, 2024\nThere's a new debugging feature for iterating on Workflow Template Nodes. You can click the new \"Test\" button in the full-screen editor and test your template without having to run the whole Workflow. Then you can further iterate on your template by modifying your test data in the \"Test Data\" tab.\nWorkflow Template Debugger",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-template-node-debugging",
        "title": "Workflow Template Node Debugging"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-node-search-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Node Search",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-node-search",
    "content": "March 26th, 2024\nWe have added a new Workflow node search feature to help you find your way in large and complex Workflows. Click the new search icon in the top right to quickly find the node you are looking for, or use the ‚åò + shift + F shortcut (ctrl + shift + F on windows).\nWorkflow Node Search",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-node-search",
        "title": "Workflow Node Search"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-node-mocking-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Node Mocking",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-node-mocking",
    "content": "March 26th, 2024\nWhile iteratively developing a Workflow in Vellum, you often want to focus on improving a specific branch or node. It can be cumbersome to re-run the entire Workflow just to test the part you're iterating on, especially if you already know what the upstream nodes are going to output.\nTo help address this, Vellum now supports node mocking. You can now mock out a Prompt or Subworkflow Node such that its execution is skipped and a hard-coded value is returned.\nThis can help you dramatically speed up your Workflow development since you no longer have to wait for early Prompt Nodes to complete. This has the added benefit of saving the expense of tokens with LLM providers!\nFor more information on Workflow Node Mocking, visit our new help center page.\nWorkflow Node Mocking",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-node-mocking",
        "title": "Workflow Node Mocking"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-claude-3-and-mistral-on-bedrock-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Claude 3 and Mistral on Bedrock",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#claude-3-and-mistral-on-bedrock",
    "content": "March 23rd, 2024\nWe now support both of the Claude 3 and both of the Mistral models on AWS Bedrock. Add these models to your workspace by heading to the models page and searching for the one you need from the search bar.\nBedrock Models",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "claude-3-and-mistral-on-bedrock",
        "title": "Claude 3 and Mistral on Bedrock"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-navigation-updates-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Navigation Updates",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#navigation-updates",
    "content": "March 22nd, 2024\nWe've made some significant changes to Vellum's navigation UI.\nThe app sidebar has been reorganized with the goal of making it easier to navigate between a Prompt/Workflow's Sandbox,\nEvaluations, and Deployments. You'll find that after you've clicked on a \"Prompt\" or \"Workflow,\" there's an integrated\nsubmenu within the navigation sidebar that shows \"Sandbox,\" \"Evaluations,\" and \"Deployments.\"\nAdditionally, you'll find that some nav items, such as \"Deployments\", \"Models,\" \"API Keys,\" \"Organization,\" and\n\"Profile\" have been grouped into the new \"More\" and \"Settings\" nav items.\nNavigation Updates",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "navigation-updates",
        "title": "Navigation Updates"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-read-only-workflow-diagrams-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Read-only Workflow Diagrams",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#read-only-workflow-diagrams",
    "content": "March 22th, 2024\nYou can now see a read-only view of workflow diagrams for Workflow Deployment Executions, Workflow Test Case Executions, and Workflow Releases. You can access the diagram by clicking the \"Graph View\" icon tab on the top right.\nThis is particularly helpful if you want to visualize what your Workflow looked like at that time, as well as visualize the execution path your Workflow took.\nWorkflow Deployment Execution",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "read-only-workflow-diagrams",
        "title": "Read-only Workflow Diagrams"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-test-suite-table-updates-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Test Suite Table Updates",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#test-suite-table-updates",
    "content": "March 21th, 2024\nThe Test Cases table on the Test Suites page has been updated to use the same new styling and functionality as the Test Cases table that you'll find when viewing a Prompt/Workflow Evaluation Report. With this, adding, editing, and deleting Test Cases is generally more reliable. Additionally, special variables types, like Chat History, have an improved display are are no longer displayed as raw JSON.\nTest Suite Table Updates",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "test-suite-table-updates",
        "title": "Test Suite Table Updates"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-additional-headers-on-api-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Additional Headers on API Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#additional-headers-on-api-nodes",
    "content": "March 20th, 2024\nPreviously, API Nodes only accepted one configurable header, defined on the Authorization section on the node. You can now configure additional headers in the new advanced Settings section. Header values could be regular STRING values or Secrets, and any headers defined here would override the Authorization header.\nAPI Node Headers",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "additional-headers-on-api-nodes",
        "title": "Additional Headers on API Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-indicators-for-deployed-promptworkflow-sandboxes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Indicators for Deployed Prompt/Workflow Sandboxes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#indicators-for-deployed-promptworkflow-sandboxes",
    "content": "March 19th, 2024\nYou can now tell at a glance whether a given Prompt/Workflow Sandbox has been deployed. You can also hover over the tag to see when it was last deployed.\nSandbox Deployment Tag",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "indicators-for-deployed-promptworkflow-sandboxes",
        "title": "Indicators for Deployed Prompt/Workflow Sandboxes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-cancellable-workflow-deployment-executions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Cancellable Workflow Deployment Executions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#cancellable-workflow-deployment-executions",
    "content": "March 18th, 2024\nYou can now cancel running Workflow Deployment Executions. Simply click the cancel button on the Workflow Execution details page.\nCancellable Workflows",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "cancellable-workflow-deployment-executions",
        "title": "Cancellable Workflow Deployment Executions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-code-execution-metric-debugging-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Code Execution Metric Debugging",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code-execution-metric-debugging",
    "content": "March 18th, 2024\nThere's a new debugging feature for iterating on custom Code Metrics. You can click the new \"Test\" button and test your code without having to run the whole test suite. You can update the example data that's passed into your Code Metric by going to the \"Test Data\" tab.\nWorkflow Code Execution Debugger",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "code-execution-metric-debugging",
        "title": "Code Execution Metric Debugging"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-details-for-workflow-evaluations-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Details for Workflow Evaluations",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-details-for-workflow-evaluations",
    "content": "March 18th, 2024\nYou can now view Workflow Execution details from the Workflow Evaluations table! To view the details, click on the new \"View Workflow Details\" button located within a test case's value cell.\nWorkflow Executions2\nWorkflow Executions1",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-details-for-workflow-evaluations",
        "title": "Workflow Details for Workflow Evaluations"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-subworkflow-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Subworkflow Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#subworkflow-nodes",
    "content": "March 14th, 2024\nAre your Workflows becoming giant and unwieldy? Wish you could define composable groups of nodes to be used across Workflows?\nWe're excited to introduce the latest node type in the Workflows node picker - Subworkflow Nodes! With Subworkflow Nodes, you can now link directly to deployed Workflows to reuse commonly grouped nodes and execution logic. Subworkflow Nodes also supports release tagging, giving users the flexibility to either pin to a specific version (say, production) or always automatically update with LATEST.\nSubworkflow Nodes\nFor more details, check out our new help center doc.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "subworkflow-nodes",
        "title": "Subworkflow Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-image-support-in-the-ui-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Image Support in the UI",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#image-support-in-the-ui",
    "content": "March 13th, 2024\nImage support is LIVE in the Vellum UI for OpenAI's GPT-4 Turbo with Vision! Vellum API's have had image support for a while and now you can add images in your Prompt and Workflow Sandbox scenarios!\nImage Support in Vellum UI\nFor more details on supported image formats and working with OpenAI's vision models in Vellum, check out our new help center doc.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "image-support-in-the-ui",
        "title": "Image Support in the UI"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-node-input-value-display-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Node Input Value Display",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-node-input-value-display",
    "content": "March 11th, 2024\nYou can now view a Node's input values directly from the Workflow Editor! This makes it easier to understand what data is being passed into a Node and to debug issues.\nWorkflow Node Input Value Display",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-node-input-value-display",
        "title": "Workflow Node Input Value Display"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-inline-editing-for-evaluations-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Inline Editing for Evaluations",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#inline-editing-for-evaluations",
    "content": "March 11th, 2024\nYou can now edit test cases directly from the \"Evaluations\" tab in Workflows and Prompts!\nThe new editing interface makes it easier than ever to make changes to test cases with long variable values, allows you to edit Chat History values with the same drag-and-drop editor you use elsewhere in the app, and adds support for formatted editing of JSON.\nWe're continuing to add support for more variable types and will soon be applying this new edit flow to other tables throughout the app.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "inline-editing-for-evaluations",
        "title": "Inline Editing for Evaluations"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-node-reject-on-error-toggle-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Node 'Reject on Error' Toggle",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-node-reject-on-error-toggle",
    "content": "March 9th, 2024\nPreviously, if a Node in a Workflow errored, the Workflow would proceed to execute until another downstream Node tried to use the output of the Node that errored and would only then terminate. This made Workflows hard to debug and put the onus on you to implement error handling.\nGoing forward, by default, Workflows will immediately terminate if a Node errors. There are still cases in which you might want to continue despite a Node error (e.g. implementing your own error handling or retry logic). In this cases, you can disable the new \"Reject on Error\" toggle.\nWorkflow Node Reject on Error\nHistorical Workflow Nodes have this toggle disabled so that there's no change in behavior. New Nodes going forward will have this toggle enabled by default.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-node-reject-on-error-toggle",
        "title": "Workflow Node 'Reject on Error' Toggle"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-code-execution-node-debugging-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Code Execution Node Debugging",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-code-execution-node-debugging",
    "content": "March 8th, 2024\nWe have introduced a new debugging feature for workflow code execution nodes! You can click the new \"Test\" button in the full-screen editor and test your code without having to run the whole workflow! Then you can further iterate on your code by modifying your test data in the \"Test Data\" tab.\nWorkflow Code Execution Debugger",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-code-execution-node-debugging",
        "title": "Workflow Code Execution Node Debugging"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-list-document-indexes-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "List Document Indexes API",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#list-document-indexes-api",
    "content": "March 7th, 2024\nWe've exposed a new API endpoint to list all the Document Indexes in a Workspace.\nYou can find the details of the API here.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "list-document-indexes-api",
        "title": "List Document Indexes API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-in-progress-workflows-executions-now-available-in-monitoring-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "In-Progress Workflows Executions Now Available in Monitoring",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#in-progress-workflows-executions-now-available-in-monitoring",
    "content": "March 6th, 2024\nYou previously had to wait for a workflow to fully resolve before seeing it in the Workflow Executions table. We now start publishing executions as soon as Workflows are initiated! This allows users building complex Workflows to see any that are still in progress:\nIn Progress Workflow Executions Table\nWe also updated the Workflow Execution Details page to also reflect in progress workflows:\nIn Progress Workflow Execution Details",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "in-progress-workflows-executions-now-available-in-monitoring",
        "title": "In-Progress Workflows Executions Now Available in Monitoring"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-expand-scenario-in-prompt-sandbox-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Expand Scenario in Prompt Sandbox",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#expand-scenario-in-prompt-sandbox",
    "content": "March 6th, 2024\nLooking for more room to edit your scenarios in the prompt sandbox? We've just added an expand scenario modal! You can now easily make changes to scenarios with longer inputs.\nExpand Scenario Modal",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "expand-scenario-in-prompt-sandbox",
        "title": "Expand Scenario in Prompt Sandbox"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-code-execution-logs-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Code Execution Logs",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code-execution-logs",
    "content": "March 6th, 2024\nYou can now use print or console.log statements in code execution nodes and view the logs by looking at a node's result and clicking the logs tab.\nCode Logs Exec Nodes\nWe've also added logs for Metrics. You can view them by enabling the logs column in the table columns settings.\nCode Logs Eval",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "code-execution-logs",
        "title": "Code Execution Logs"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-code-execution-improvements-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Code Execution Improvements",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#code-execution-improvements",
    "content": "March 6th, 2024\nWe've made some huge improvements to code execution! You can now include custom packages for Code Execution Workflow nodes and Code Execution Metrics. On top of this, we have added support for TypeScript. You can select the programming language you want from the new \"Runtime\" dropdown.\nWe have also introduced a few smaller improvements:\nThe maximum size for code input values has been increased to 10mb, a significant leap from the previous cap of 128k characters\n\nThe layout of the workflow code execution node editor has been revamped with a new side by side layout\n\nAll Vellum input types are now supported for code execution node input variables\n\nLine numbers in the code editor will no longer be squished together\n\n\nCode Execution Improvements",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "code-execution-improvements",
        "title": "Code Execution Improvements"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-claude-3-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Claude 3",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#claude-3",
    "content": "March 5th, 2024\nAnthropic's two newest models, Claude 3 Opus and Claude 3 Sonnet, are now both available in Vellum! These models have been added to all workspaces so they should be selectable from prompt sandboxes upon refresh.\nClaude 3",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "claude-3",
        "title": "Claude 3"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-in-app-support-now-accessed-via-get-help-button-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "In-App Support Now Accessed via \"Get Help\" Button",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#in-app-support-now-accessed-via-get-help-button",
    "content": "March 5th, 2024\nIt used to be that the In-App Support Widget we showed in the bottom right corner of the screen would get in the way of other actions like Save buttons.\nNow, that widget is hidden by default and you can open it by clicking the \"Get Help\" button in the side navigation. Once opened, we\nalso now display bookmarked links to useful resources like the Vellum Help Docs.\nGet Help Button Opens Chat Widget",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "in-app-support-now-accessed-via-get-help-button",
        "title": "In-App Support Now Accessed via \"Get Help\" Button"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-workflow-error-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Workflow Error Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-error-nodes",
    "content": "March 4th, 2024\nIt's now possible to terminal a Workflow and raise an error through the use of Error Nodes. You can either re-raise an error from an upstream node, or construct and raise a custom error message.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "workflow-error-nodes",
        "title": "Workflow Error Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-03-retrieve-workflow-deployment-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-03",
    "pathname": "/changelog/2024/2024-03",
    "title": "Retrieve Workflow Deployment API",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#retrieve-workflow-deployment-api",
    "content": "March 1st, 2024\nWe've exposed a new API endpoint to retrieve details of a Workflow Deployment. This is useful if you want to do things like programmatically detect if a Workflow Deployment with a specific name exists, or has the inputs/outputs you expect.\nYou can find the details of the API here.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | March, 2024"
      },
      "h2": {
        "id": "retrieve-workflow-deployment-api",
        "title": "Retrieve Workflow Deployment API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Changelog | February, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "Discover the newest features and improvements in Vellum's product update for February."
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-add-entity-to-folder-api-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Add Entity to Folder API",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#add-entity-to-folder-api",
    "content": "February 29th, 2024\nWe've exposed a new API endpoint to add an existing entity to an existing folder. This is useful if you want to programmatically organize your entities in Vellum. You can find the new endpoint and details on how to invoke it in our API documentation.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "add-entity-to-folder-api",
        "title": "Add Entity to Folder API"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-vellum-is-soc-2-type-2-compliant-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Vellum is SOC 2 Type 2 Compliant",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#vellum-is-soc-2-type-2-compliant",
    "content": "February 28th, 2024\nVellum is now SOC 2 Type 2 compliant! This means that an independent auditor has verified that Vellum's information security practices, policies, and procedures meet the SOC 2 standards for security, availability, processing integrity, confidentiality, and privacy.\nIf you'd like to learn more about Vellum's security practices or request a copy of our SOC 2 report, please reach out to us at security@vellum.ai.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "vellum-is-soc-2-type-2-compliant",
        "title": "Vellum is SOC 2 Type 2 Compliant"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-save-workflow-execution-from-details-page-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Save Workflow Execution from Details Page",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#save-workflow-execution-from-details-page",
    "content": "February 23rd, 2024\nPreviously you were able to save your workflow execution to a test suite or sandbox scenario from the executions table. Now you can do the same from each execution's details page! Both the \"Save As Test Case\" and \"Save As Scenario\" buttons should now appear on the top right of the execution:\nSave Workflow Execution Details",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "save-workflow-execution-from-details-page",
        "title": "Save Workflow Execution from Details Page"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-workflow-builder-ui-settings-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Workflow Builder UI Settings",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-builder-ui-settings",
    "content": "February 21st, 2024\nHave you ever wanted to pan around workflows using the W-A-S-D keys? Looking for more control over your screen real estate?\nGood news! You can now adjust these settings and more in the new workflow UI settings! Access the settings by clicking the new gear icon in the top right of your workflow builder.\nWorkflow Builder Settings",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "workflow-builder-ui-settings",
        "title": "Workflow Builder UI Settings"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-custom-release-tags-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Custom Release Tags",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#custom-release-tags",
    "content": "February 21st, 2024\nYou can now manage your Prompt and Workflow release process with greater flexibility and control using Custom Release Tags! Pin your Vellum API requests to tags you define for a given Prompt/Workflow Deployment. These tags can be easily re-assigned within the Vellum app so you can update your production, staging or other custom environment to point to a new version of a prompt or workflow ‚Äî all without making any code changes!\nGoing forward, new customers of Vellum will no longer see the legacy \"Environment\" tags in Vellum's UI. Custom Release Tags are the new, first-class mechanism for managing different releases of the same prompt/workflow in Vellum. We will slowly be deprecating and removing the legacy \"Environment\" tags for existing customers.\nLearn more about Managing Releases in our Help Center article or watch the video walkthrough below:",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "custom-release-tags",
        "title": "Custom Release Tags"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-better-function-call-display-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Better Function Call Display",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#better-function-call-display",
    "content": "February 15th, 2024\nWe've beautified the display of model function calls in both prompt sandboxes and workflow prompt nodes! Say goodbye to the hard to read and mundane JSON strings.\nFireworks Function Call Model",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "better-function-call-display",
        "title": "Better Function Call Display"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-evaluation-reports-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Evaluation Reports",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#evaluation-reports",
    "content": "February 12th, 2024\nTest Suite Runs have received a big upgrade, and now live in its own tab - Evaluations. You are now able to compare a Prompt or Workflow Variant against a Deployment, and view aggregate Metrics like Median or P90.\nSee a demo of the complete set of updates here:",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "evaluation-reports",
        "title": "Evaluation Reports"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-fireworks-function-calling-model-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Fireworks Function Calling Model",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#fireworks-function-calling-model",
    "content": "February 5nd, 2024\nOpenAI's GPT models have traditionally led the way in supporting structured data generation through function calling. But late last year Fireworks AI splashed in with their own function calling model! This model is now available in Vellum for those interested in an open source alternative to GPT.\nFireworks Function Call Model",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "fireworks-function-calling-model",
        "title": "Fireworks Function Calling Model"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-cloning-workflow-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Cloning Workflow Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#cloning-workflow-nodes",
    "content": "February 2nd, 2024\nWhen you hover over any node in your Workflow editor, you will see a new Duplicate Node icon. Clicking on this will create a new copy of a node! Never again will you need to start a node from scratch when you want to just tweak a field or two.\nClone Nodes",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "cloning-workflow-nodes",
        "title": "Cloning Workflow Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-02-prompt-node-retries-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-02",
    "pathname": "/changelog/2024/2024-02",
    "title": "Prompt Node Retries",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-node-retries",
    "content": "February 1st, 2024\nYou can now detect when a Prompt Node within a Workflow errors by using a Conditional Node. Using this, you can now build out retry logic around Prompt Nodes within your Workflow! This is useful if you want to catch retryable errors (like rate limit errors from an LLM provider) and try making the call to the LLM again.\nSee a demo of it in action here:",
    "hierarchy": {
      "h0": {
        "title": "Changelog | February, 2024"
      },
      "h2": {
        "id": "prompt-node-retries",
        "title": "Prompt Node Retries"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Changelog | January, 2024",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "type": "markdown",
    "description": "In January, 2024 Vellum released prompt usage tracking, single editor mode, and more!"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-prompt-deployment-usage-tracking-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Prompt Deployment Usage Tracking",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#prompt-deployment-usage-tracking",
    "content": "January 29th, 2024\nGoing forward, Vellum will now keep track of the token utilization of your Prompt Deployments. You can keep tabs on\ninput, output, and total tokens used per request.\nToken Count Row Data\nYou can also view this data in aggregate in the Monitoring tab.\nToken Count Time-Series Data\nThis is a precursor to more advanced usage and billing features coming down the road. If there's more you'd like to see\nhere, please share your feedback with us!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "prompt-deployment-usage-tracking",
        "title": "Prompt Deployment Usage Tracking"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-model-search-bar-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Model Search Bar",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#model-search-bar",
    "content": "January 29th, 2024\nAs the number of models available in Vellum grows, it's become harder to find the model you're looking for. To help with\nthis, we've added a search bar to the model selection dropdown in the Prompt and Workflow editors. This will make it\neasier to find the model you're looking for, especially as we continue to add more models to the platform.\nModel Search Bar",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "model-search-bar",
        "title": "Model Search Bar"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-single-editor-mode-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Single Editor Mode",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#single-editor-mode",
    "content": "January 25th, 2024\nWe've collaborated with our friends at velt.dev to deliver an all new \"Single Editor Mode\" in\nPrompt and Workflow Sandboxes. With this, only one person can edit a Prompt/Workflow at a time and you can hand off\nediting control to another collaborator. This is useful for avoiding conflicts when multiple people are\ntrying to edit the same Prompt/Workflow at the same time. Check out the video below to see it in action!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "single-editor-mode",
        "title": "Single Editor Mode"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-api-to-execute-workflow-wo-streaming-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "API to Execute Workflow w/o Streaming",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#api-to-execute-workflow-wo-streaming",
    "content": "January 23rd, 2024\nWe've added a new API endpoint for executing a Workflow Deployment without streaming back its incremental results. This is useful\nwhen you want to execute a Workflow and only care about its final result or if you're invoking your Workflow\nvia a service that doesn't support HTTP Streaming like Zapier.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "api-to-execute-workflow-wo-streaming",
        "title": "API to Execute Workflow w/o Streaming"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-workflow-deployment-execution-visualization-improvements-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Workflow Deployment Execution Visualization Improvements",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#workflow-deployment-execution-visualization-improvements",
    "content": "January 22nd, 2024\nNow, when visiting the details page for a Workflow Deployment Execution, you'll find an improved loading state as well\nas a simplified view for Conditional Nodes.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "workflow-deployment-execution-visualization-improvements",
        "title": "Workflow Deployment Execution Visualization Improvements"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-uploaddownload-of-function-definitions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Upload/Download of Function Definitions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#uploaddownload-of-function-definitions",
    "content": "January 18th, 2024\nYou can now easily import your existing function definition files (JSON or YAML) into Vellum function calling blocks\nas well as export functions you've already defined in Vellum to pass along to engineers for implementation. Check it\nout below!",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "uploaddownload-of-function-definitions",
        "title": "Upload/Download of Function Definitions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-image-support-for-openai-vision-models-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Image Support for OpenAI Vision Models",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#image-support-for-openai-vision-models",
    "content": "January 18th, 2024\nVellum now has API support for interacting with OpenAI's vision models, such as gpt-4-vision-preview.\nYou can learn more about OpenAI Vision models here. Note that there is\nlimited support for images in the Vellum UI at this time, but you can still use the API to interact with OpenAI Vision models.\nUI support coming soon!\nHere's a quick example on how to send an image to the model, using our python sdk:",
    "code_snippets": [
      {
        "lang": "python",
        "code": "image_link = \"https://storage.googleapis.com/vellum-public/help-docs/add_prompt_block_button.png\"\nresponse = client.execute_prompt(\n    prompt_deployment_name=\"github-loom-demo\",\n    inputs=[\n        PromptDeploymentInputRequest_ChatHistory(\n            name=\"$chat_history\",\n            value=[\n                ChatMessageRequest(\n                    role=ChatMessageRole.USER,\n                    content={\n                        \"type\": \"ARRAY\",\n                        \"value\": [\n                            {\"type\": \"STRING\", \"value\": \"What's in this image?\"},\n                            {\"type\": \"IMAGE\", \"value\": {\"src\": image_link}},\n                        ],\n                    },\n                )\n            ],\n            type=VellumVariableType.CHAT_HISTORY,\n        ),\n    ],\n)\nprint(response.outputs[0].value)"
      }
    ],
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "image-support-for-openai-vision-models",
        "title": "Image Support for OpenAI Vision Models"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-folders-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Folders",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#folders",
    "content": "January 12th, 2024\nYou can now organize entities in Vellum via folders! You can nest folders, share them by url, and move entities between folders.",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "folders",
        "title": "Folders"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-support-for-google-gemini-safety-settings-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Support for Google Gemini Safety Settings",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-google-gemini-safety-settings",
    "content": "January 12th, 2024\nThere is now native support for setting the safetySetting parameters in Google Gemini prompts. You can learn more\nabout how these parameters are used by Google in their docs here.\nGemini Custom Parameters",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "support-for-google-gemini-safety-settings",
        "title": "Support for Google Gemini Safety Settings"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-support-for-openai-json-mode-user-id-and-seed-params-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Support for OpenAI JSON Mode, User ID, and Seed Params",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#support-for-openai-json-mode-user-id-and-seed-params",
    "content": "January 11th, 2024\nThere is now native support for setting the user and seed parameters in OpenAI API requests, as well as specifying\nthat the response format be of type JSON. You can learn more about how these parameters are used by OpenAI in\ntheir docs here.\nOpenAI Custom Parameters",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "support-for-openai-json-mode-user-id-and-seed-params",
        "title": "Support for OpenAI JSON Mode, User ID, and Seed Params"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-cloning-workflow-scenarios-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Cloning Workflow Scenarios",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#cloning-workflow-scenarios",
    "content": "January 9th, 2024\nYou can now clone a Workflow Scenario to create a new Scenario based on an existing one. This is useful when you want to\ncreate a new Scenario that is similar to an existing one, but with some changes.\nClone Workflow Scenario",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "cloning-workflow-scenarios",
        "title": "Cloning Workflow Scenarios"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-api-key-metadata-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "API Key Metadata",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#api-key-metadata",
    "content": "January 9th, 2024\nNow you can add and view metadata for your Vellum API keys. For example, you can see when an API key was created and by whom.\nYou can also assign a label to an API key to help you keep track of its purpose and an environment tag so that you know\nwhere it's used.\nAPI Key Metadata",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "api-key-metadata",
        "title": "API Key Metadata"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-top-level-workflow-execution-actions-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Top-Level Workflow Execution Actions",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#top-level-workflow-execution-actions",
    "content": "January 4th, 2024\nYou can now find the following actions at the top-level of the Workflow and Prompt Deployment Execution pages:\nSave as Scenario: Useful for saving an edge case seen in production as a Scenario for qualitative eval.\n\nSave as Test Case: Useful for saving an edge case seen in production to your bank of Test Cases for quantitative eval.\n\nView Details: Drill in to see specifics about that specific Execution.\n\n\nTop-Level Workflow Execution Actions",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "top-level-workflow-execution-actions",
        "title": "Top-Level Workflow Execution Actions"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:root.uv.changelog.changelog.2024.2024-01-improved-error-messages-in-code--api-nodes-chunk:0",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/changelog/2024/2024-01",
    "pathname": "/changelog/2024/2024-01",
    "title": "Improved Error Messages in Code & API Nodes",
    "breadcrumb": [
      {
        "title": "2024",
        "pathname": "/changelog/2024"
      }
    ],
    "tab": {
      "title": "Changelog",
      "pathname": "/changelog"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 1,
    "type": "markdown",
    "hash": "#improved-error-messages-in-code--api-nodes",
    "content": "January 2nd, 2024\nAPI Nodes and Code Nodes within Workflows now have improved error messages. When an error occurs, the error message\nwill now include the line number and column number where the error occurred. This will make it easier to debug errors\nin your Workflows.\nImproved Error Messages in Code & API Nodes",
    "hierarchy": {
      "h0": {
        "title": "Changelog | January, 2024"
      },
      "h2": {
        "id": "improved-error-messages-in-code--api-nodes",
        "title": "Improved Error Messages in Code & API Nodes"
      }
    },
    "level": "h2"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.execute-prompt",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/execute-prompt",
    "pathname": "/api-reference/prompts/execute-prompt",
    "title": "Execute Prompt",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_.execute-prompt",
    "method": "POST",
    "endpoint_path": "/v1/execute-prompt",
    "endpoint_path_alternates": [
      "/v1/execute-prompt",
      "https://predict.vellum.ai/v1/execute-prompt",
      "https://predict.vellum.ai/v1/execute-prompt"
    ],
    "response_type": "json",
    "description": "Executes a deployed Prompt and returns the result.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://predict.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.execute-prompt-stream",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/execute-prompt-stream",
    "pathname": "/api-reference/prompts/execute-prompt-stream",
    "title": "Execute Prompt as Stream",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_.execute-prompt-stream",
    "method": "POST",
    "endpoint_path": "/v1/execute-prompt-stream",
    "endpoint_path_alternates": [
      "/v1/execute-prompt-stream",
      "https://predict.vellum.ai/v1/execute-prompt-stream",
      "https://predict.vellum.ai/v1/execute-prompt-stream"
    ],
    "response_type": "stream",
    "description": "Executes a deployed Prompt and streams back the results.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://predict.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "stream",
      "ExecutePromptEvent",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.submit-completion-actuals",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/submit-completion-actuals",
    "pathname": "/api-reference/prompts/submit-completion-actuals",
    "title": "Submit Prompt Execution Actuals",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_.submit-completion-actuals",
    "method": "POST",
    "endpoint_path": "/v1/submit-completion-actuals",
    "endpoint_path_alternates": [
      "/v1/submit-completion-actuals",
      "https://predict.vellum.ai/v1/submit-completion-actuals",
      "https://predict.vellum.ai/v1/submit-completion-actuals"
    ],
    "description": "Used to submit feedback regarding the quality of previously generated completions.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://predict.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "SubmitCompletionActualsErrorResponse",
      "SubmitCompletionActualsErrorResponse",
      "SubmitCompletionActualsErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.retrieve_provider_payload",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/retrieve-provider-payload",
    "pathname": "/api-reference/prompts/retrieve-provider-payload",
    "title": "Retrieve Provider Payload",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_deployments.retrieve_provider_payload",
    "method": "POST",
    "endpoint_path": "/v1/deployments/provider-payload",
    "endpoint_path_alternates": [
      "/v1/deployments/provider-payload",
      "https://api.vellum.ai/v1/deployments/provider-payload",
      "https://api.vellum.ai/v1/deployments/provider-payload"
    ],
    "response_type": "json",
    "description": "Given a set of input variable values, compile the exact payload that Vellum would send to the configured model provider\nfor execution if the execute-prompt endpoint had been invoked. Note that this endpoint does not actually execute the\nprompt or make an API call to the model provider.\nThis endpoint is useful if you don't want to proxy LLM provider requests through Vellum and prefer to send them directly\nto the provider yourself. Note that no guarantees are made on the format of this API's response schema, other than\nthat it will be a valid payload for the configured model provider. It's not recommended that you try to parse or\nderive meaning from the response body and instead, should simply pass it directly to the model provider as is.\nWe encourage you to seek advise from Vellum Support before integrating with this API for production use.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse",
      "ExecutePromptApiErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.deploy_prompt",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/sandboxes/deploy-prompt",
    "pathname": "/api-reference/prompts/sandboxes/deploy-prompt",
    "title": "Deploy Prompt Sandbox",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      },
      {
        "title": "Prompt Sandboxes",
        "pathname": "/api-reference/prompts/sandboxes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_sandboxes.deploy_prompt",
    "method": "POST",
    "endpoint_path": "/v1/sandboxes/:id/prompts/:prompt_variant_id/deploy",
    "endpoint_path_alternates": [
      "/v1/sandboxes/{id}/prompts/{prompt_variant_id}/deploy",
      "https://api.vellum.ai/v1/sandboxes/:id/prompts/:prompt_variant_id/deploy",
      "https://api.vellum.ai/v1/sandboxes/%7Bid%7D/prompts/%7Bprompt_variant_id%7D/deploy"
    ],
    "response_type": "json",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.upsert_sandbox_scenario",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/sandboxes/upsert-scenario",
    "pathname": "/api-reference/prompts/sandboxes/upsert-scenario",
    "title": "Upsert Prompt Sandbox Scenario",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      },
      {
        "title": "Prompt Sandboxes",
        "pathname": "/api-reference/prompts/sandboxes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_sandboxes.upsert_sandbox_scenario",
    "method": "POST",
    "endpoint_path": "/v1/sandboxes/:id/scenarios",
    "endpoint_path_alternates": [
      "/v1/sandboxes/{id}/scenarios",
      "https://api.vellum.ai/v1/sandboxes/:id/scenarios",
      "https://api.vellum.ai/v1/sandboxes/%7Bid%7D/scenarios"
    ],
    "response_type": "json",
    "description": "Upserts a new scenario for a sandbox, keying off of the optionally provided scenario id.\nIf an id is provided and has a match, the scenario will be updated. If no id is provided or no match\nis found, a new scenario will be appended to the end.\nNote that a full replacement of the scenario is performed, so any fields not provided will be removed\nor overwritten with default values.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.delete_sandbox_scenario",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/sandboxes/delete-scenario",
    "pathname": "/api-reference/prompts/sandboxes/delete-scenario",
    "title": "Delete Prompt Sandbox Scenario",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      },
      {
        "title": "Prompt Sandboxes",
        "pathname": "/api-reference/prompts/sandboxes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_sandboxes.delete_sandbox_scenario",
    "method": "DELETE",
    "endpoint_path": "/v1/sandboxes/:id/scenarios/:scenario_id",
    "endpoint_path_alternates": [
      "/v1/sandboxes/{id}/scenarios/{scenario_id}",
      "https://api.vellum.ai/v1/sandboxes/:id/scenarios/:scenario_id",
      "https://api.vellum.ai/v1/sandboxes/%7Bid%7D/scenarios/%7Bscenario_id%7D"
    ],
    "description": "Deletes an existing scenario from a sandbox, keying off of the provided scenario id.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.list",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/deployments/list",
    "pathname": "/api-reference/prompts/deployments/list",
    "title": "List Prompt Deployments",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      },
      {
        "title": "Prompt Deployments",
        "pathname": "/api-reference/prompts/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_deployments.list",
    "method": "GET",
    "endpoint_path": "/v1/deployments",
    "endpoint_path_alternates": [
      "/v1/deployments",
      "https://api.vellum.ai/v1/deployments",
      "https://api.vellum.ai/v1/deployments"
    ],
    "response_type": "json",
    "description": "Used to list all Prompt Deployments.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.retrieve",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/deployments/retrieve",
    "pathname": "/api-reference/prompts/deployments/retrieve",
    "title": "Retrieve Prompt Deployment",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      },
      {
        "title": "Prompt Deployments",
        "pathname": "/api-reference/prompts/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_deployments.retrieve",
    "method": "GET",
    "endpoint_path": "/v1/deployments/:id",
    "endpoint_path_alternates": [
      "/v1/deployments/{id}",
      "https://api.vellum.ai/v1/deployments/:id",
      "https://api.vellum.ai/v1/deployments/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Used to retrieve a Prompt Deployment given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.retrieve_deployment_release_tag",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/deployments/retrieve-release-tag",
    "pathname": "/api-reference/prompts/deployments/retrieve-release-tag",
    "title": "Retrieve Prompt Deployment Release Tag",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      },
      {
        "title": "Prompt Deployments",
        "pathname": "/api-reference/prompts/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_deployments.retrieve_deployment_release_tag",
    "method": "GET",
    "endpoint_path": "/v1/deployments/:id/release-tags/:name",
    "endpoint_path_alternates": [
      "/v1/deployments/{id}/release-tags/{name}",
      "https://api.vellum.ai/v1/deployments/:id/release-tags/:name",
      "https://api.vellum.ai/v1/deployments/%7Bid%7D/release-tags/%7Bname%7D"
    ],
    "response_type": "json",
    "description": "Retrieve a Deployment Release Tag by tag name, associated with a specified Deployment.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.update_deployment_release_tag",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/prompts/deployments/update-release-tag",
    "pathname": "/api-reference/prompts/deployments/update-release-tag",
    "title": "Update Prompt Deployment Release Tag",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Prompts",
        "pathname": "/api-reference/prompts"
      },
      {
        "title": "Prompt Deployments",
        "pathname": "/api-reference/prompts/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_deployments.update_deployment_release_tag",
    "method": "PATCH",
    "endpoint_path": "/v1/deployments/:id/release-tags/:name",
    "endpoint_path_alternates": [
      "/v1/deployments/{id}/release-tags/{name}",
      "https://api.vellum.ai/v1/deployments/:id/release-tags/:name",
      "https://api.vellum.ai/v1/deployments/%7Bid%7D/release-tags/%7Bname%7D"
    ],
    "response_type": "json",
    "description": "Updates an existing Release Tag associated with the specified Deployment.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.execute-workflow",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/execute-workflow",
    "pathname": "/api-reference/workflows/execute-workflow",
    "title": "Execute Workflow",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_.execute-workflow",
    "method": "POST",
    "endpoint_path": "/v1/execute-workflow",
    "endpoint_path_alternates": [
      "/v1/execute-workflow",
      "https://predict.vellum.ai/v1/execute-workflow",
      "https://predict.vellum.ai/v1/execute-workflow"
    ],
    "response_type": "json",
    "description": "Executes a deployed Workflow and returns its outputs.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://predict.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json",
      "ExecuteWorkflowErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.execute-workflow-stream",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/execute-workflow-stream",
    "pathname": "/api-reference/workflows/execute-workflow-stream",
    "title": "Execute Workflow as Stream",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_.execute-workflow-stream",
    "method": "POST",
    "endpoint_path": "/v1/execute-workflow-stream",
    "endpoint_path_alternates": [
      "/v1/execute-workflow-stream",
      "https://predict.vellum.ai/v1/execute-workflow-stream",
      "https://predict.vellum.ai/v1/execute-workflow-stream"
    ],
    "response_type": "stream",
    "description": "Executes a deployed Workflow and streams back its results.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://predict.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "stream",
      "WorkflowStreamEvent",
      "ExecuteWorkflowStreamErrorResponse",
      "ExecuteWorkflowStreamErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.submit-workflow-execution-actuals",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/submit-workflow-execution-actuals",
    "pathname": "/api-reference/workflows/submit-workflow-execution-actuals",
    "title": "Submit Workflow Execution Actuals",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_.submit-workflow-execution-actuals",
    "method": "POST",
    "endpoint_path": "/v1/submit-workflow-execution-actuals",
    "endpoint_path_alternates": [
      "/v1/submit-workflow-execution-actuals",
      "https://predict.vellum.ai/v1/submit-workflow-execution-actuals",
      "https://predict.vellum.ai/v1/submit-workflow-execution-actuals"
    ],
    "description": "Used to submit feedback regarding the quality of previous workflow execution and its outputs.\nNote: Uses a base url of https://predict.vellum.ai.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://predict.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742:endpoint_workflowSandboxes.deploy_workflow",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/sandboxes/deploy-workflow",
    "pathname": "/api-reference/workflows/sandboxes/deploy-workflow",
    "title": "Deploy Workflow",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      },
      {
        "title": "Workflow Sandboxes",
        "pathname": "/api-reference/workflows/sandboxes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_workflowSandboxes.deploy_workflow",
    "method": "POST",
    "endpoint_path": "/v1/workflow-sandboxes/:id/workflows/:workflow_id/deploy",
    "endpoint_path_alternates": [
      "/v1/workflow-sandboxes/{id}/workflows/{workflow_id}/deploy",
      "https://api.vellum.ai/v1/workflow-sandboxes/:id/workflows/:workflow_id/deploy",
      "https://api.vellum.ai/v1/workflow-sandboxes/%7Bid%7D/workflows/%7Bworkflow_id%7D/deploy"
    ],
    "response_type": "json",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_workflowDeployments.list",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/deployments/list",
    "pathname": "/api-reference/workflows/deployments/list",
    "title": "List Workflow Deployments",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      },
      {
        "title": "Workflow Deployments",
        "pathname": "/api-reference/workflows/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_workflowDeployments.list",
    "method": "GET",
    "endpoint_path": "/v1/workflow-deployments",
    "endpoint_path_alternates": [
      "/v1/workflow-deployments",
      "https://api.vellum.ai/v1/workflow-deployments",
      "https://api.vellum.ai/v1/workflow-deployments"
    ],
    "response_type": "json",
    "description": "Used to list all Workflow Deployments.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_workflowDeployments.retrieve",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/deployments/retrieve",
    "pathname": "/api-reference/workflows/deployments/retrieve",
    "title": "Retrieve Workflow Deployment",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      },
      {
        "title": "Workflow Deployments",
        "pathname": "/api-reference/workflows/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_workflowDeployments.retrieve",
    "method": "GET",
    "endpoint_path": "/v1/workflow-deployments/:id",
    "endpoint_path_alternates": [
      "/v1/workflow-deployments/{id}",
      "https://api.vellum.ai/v1/workflow-deployments/:id",
      "https://api.vellum.ai/v1/workflow-deployments/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Used to retrieve a workflow deployment given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_workflowDeployments.retrieve_workflow_release_tag",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/deployments/retrieve-release-tag",
    "pathname": "/api-reference/workflows/deployments/retrieve-release-tag",
    "title": "Retrieve Workflow Deployment Release Tag",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      },
      {
        "title": "Workflow Deployments",
        "pathname": "/api-reference/workflows/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_workflowDeployments.retrieve_workflow_release_tag",
    "method": "GET",
    "endpoint_path": "/v1/workflow-deployments/:id/release-tags/:name",
    "endpoint_path_alternates": [
      "/v1/workflow-deployments/{id}/release-tags/{name}",
      "https://api.vellum.ai/v1/workflow-deployments/:id/release-tags/:name",
      "https://api.vellum.ai/v1/workflow-deployments/%7Bid%7D/release-tags/%7Bname%7D"
    ],
    "response_type": "json",
    "description": "Retrieve a Workflow Release Tag by tag name, associated with a specified Workflow Deployment.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_workflowDeployments.update_workflow_release_tag",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/workflows/deployments/update-release-tag",
    "pathname": "/api-reference/workflows/deployments/update-release-tag",
    "title": "Update Workflow Deployment Release Tag",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Workflows",
        "pathname": "/api-reference/workflows"
      },
      {
        "title": "Workflow Deployments",
        "pathname": "/api-reference/workflows/deployments"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_workflowDeployments.update_workflow_release_tag",
    "method": "PATCH",
    "endpoint_path": "/v1/workflow-deployments/:id/release-tags/:name",
    "endpoint_path_alternates": [
      "/v1/workflow-deployments/{id}/release-tags/{name}",
      "https://api.vellum.ai/v1/workflow-deployments/:id/release-tags/:name",
      "https://api.vellum.ai/v1/workflow-deployments/%7Bid%7D/release-tags/%7Bname%7D"
    ],
    "response_type": "json",
    "description": "Updates an existing Release Tag associated with the specified Workflow Deployment.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documentIndexes.search",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/search",
    "pathname": "/api-reference/document-indexes/search",
    "title": "Search",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_.search",
    "method": "POST",
    "endpoint_path": "/v1/search",
    "endpoint_path_alternates": [
      "/v1/search",
      "https://predict.vellum.ai/v1/search",
      "https://predict.vellum.ai/v1/search"
    ],
    "response_type": "json",
    "description": "Perform a search against a document index.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://predict.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json",
      "SearchErrorResponse",
      "SearchErrorResponse",
      "SearchErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documentIndexes.add_document",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/add-document",
    "pathname": "/api-reference/document-indexes/add-document",
    "title": "Add Document",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.add_document",
    "method": "POST",
    "endpoint_path": "/v1/document-indexes/:id/documents/:document_id",
    "endpoint_path_alternates": [
      "/v1/document-indexes/{id}/documents/{document_id}",
      "https://api.vellum.ai/v1/document-indexes/:id/documents/:document_id",
      "https://api.vellum.ai/v1/document-indexes/%7Bid%7D/documents/%7Bdocument_id%7D"
    ],
    "description": "Adds a previously uploaded Document to the specified Document Index.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documentIndexes.create",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/create",
    "pathname": "/api-reference/document-indexes/create",
    "title": "Create Document Index",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.create",
    "method": "POST",
    "endpoint_path": "/v1/document-indexes",
    "endpoint_path_alternates": [
      "/v1/document-indexes",
      "https://api.vellum.ai/v1/document-indexes",
      "https://api.vellum.ai/v1/document-indexes"
    ],
    "response_type": "json",
    "description": "Creates a new document index.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documentIndexes.retrieve",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/retrieve",
    "pathname": "/api-reference/document-indexes/retrieve",
    "title": "Retrieve Document Index",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.retrieve",
    "method": "GET",
    "endpoint_path": "/v1/document-indexes/:id",
    "endpoint_path_alternates": [
      "/v1/document-indexes/{id}",
      "https://api.vellum.ai/v1/document-indexes/:id",
      "https://api.vellum.ai/v1/document-indexes/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Used to retrieve a Document Index given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documentIndexes.list",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/list",
    "pathname": "/api-reference/document-indexes/list",
    "title": "List Document Indexes",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.list",
    "method": "GET",
    "endpoint_path": "/v1/document-indexes",
    "endpoint_path_alternates": [
      "/v1/document-indexes",
      "https://api.vellum.ai/v1/document-indexes",
      "https://api.vellum.ai/v1/document-indexes"
    ],
    "response_type": "json",
    "description": "Used to retrieve a list of Document Indexes.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documentIndexes.partialUpdate",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/partial-update",
    "pathname": "/api-reference/document-indexes/partial-update",
    "title": "Update Document Index",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.partialUpdate",
    "method": "PATCH",
    "endpoint_path": "/v1/document-indexes/:id",
    "endpoint_path_alternates": [
      "/v1/document-indexes/{id}",
      "https://api.vellum.ai/v1/document-indexes/:id",
      "https://api.vellum.ai/v1/document-indexes/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Used to partial update a Document Index given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documentIndexes.update",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/update",
    "pathname": "/api-reference/document-indexes/update",
    "title": "Replace Document Index",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.update",
    "method": "PUT",
    "endpoint_path": "/v1/document-indexes/:id",
    "endpoint_path_alternates": [
      "/v1/document-indexes/{id}",
      "https://api.vellum.ai/v1/document-indexes/:id",
      "https://api.vellum.ai/v1/document-indexes/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Used to fully update a Document Index given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742:endpoint_documentIndexes.destroy",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/destroy",
    "pathname": "/api-reference/document-indexes/destroy",
    "title": "Destroy",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.destroy",
    "method": "DELETE",
    "endpoint_path": "/v1/document-indexes/:id",
    "endpoint_path_alternates": [
      "/v1/document-indexes/{id}",
      "https://documents.vellum.ai/v1/document-indexes/:id",
      "https://documents.vellum.ai/v1/document-indexes/%7Bid%7D"
    ],
    "description": "Used to delete a Document Index given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://documents.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742:endpoint_documentIndexes.remove_document",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/document-indexes/remove-document",
    "pathname": "/api-reference/document-indexes/remove-document",
    "title": "Remove Document",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Document Indexes",
        "pathname": "/api-reference/document-indexes"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documentIndexes.remove_document",
    "method": "DELETE",
    "endpoint_path": "/v1/document-indexes/:id/documents/:document_id",
    "endpoint_path_alternates": [
      "/v1/document-indexes/{id}/documents/{document_id}",
      "https://documents.vellum.ai/v1/document-indexes/:id/documents/:document_id",
      "https://documents.vellum.ai/v1/document-indexes/%7Bid%7D/documents/%7Bdocument_id%7D"
    ],
    "description": "Removes a Document from a Document Index without deleting the Document itself.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://documents.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documents.upload",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/documents/upload",
    "pathname": "/api-reference/documents/upload",
    "title": "Upload Document",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Documents",
        "pathname": "/api-reference/documents"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documents.upload",
    "method": "POST",
    "endpoint_path": "/v1/upload-document",
    "endpoint_path_alternates": [
      "/v1/upload-document",
      "https://documents.vellum.ai/v1/upload-document",
      "https://documents.vellum.ai/v1/upload-document"
    ],
    "response_type": "json",
    "description": "Upload a document to be indexed and used for search.\nNote: Uses a base url of https://documents.vellum.ai.\nThis is a multipart/form-data request. The contents field should be a file upload. It also expects a JSON body with the following fields:\nadd_to_index_names: list[str] - Optionally include the names of all indexes that you'd like this document to be included in\n\nexternal_id: str | None - Optionally include an external ID for this document. This is useful if you want to re-upload the same document later when its contents change and would like it to be re-indexed.\n\nlabel: str - A human-friendly name for this document. Typically the filename.\n\nkeywords: list[str] | None - Optionally include a list of keywords that'll be associated with this document. Used when performing keyword searches.\n\nmetadata: dict[str, Any] - A stringified JSON object containing any metadata associated with the document that you'd like to filter upon later.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://documents.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json",
      "UploadDocumentErrorResponse",
      "UploadDocumentErrorResponse",
      "UploadDocumentErrorResponse"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documents.retrieve",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/documents/retrieve",
    "pathname": "/api-reference/documents/retrieve",
    "title": "Retrieve Document",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Documents",
        "pathname": "/api-reference/documents"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documents.retrieve",
    "method": "GET",
    "endpoint_path": "/v1/documents/:id",
    "endpoint_path_alternates": [
      "/v1/documents/{id}",
      "https://api.vellum.ai/v1/documents/:id",
      "https://api.vellum.ai/v1/documents/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Retrieve a Document, keying off of either its Vellum-generated ID or its external ID.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documents.list",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/documents/list",
    "pathname": "/api-reference/documents/list",
    "title": "List Documents",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Documents",
        "pathname": "/api-reference/documents"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documents.list",
    "method": "GET",
    "endpoint_path": "/v1/documents",
    "endpoint_path_alternates": [
      "/v1/documents",
      "https://api.vellum.ai/v1/documents",
      "https://api.vellum.ai/v1/documents"
    ],
    "response_type": "json",
    "description": "Used to list documents. Optionally filter on supported fields.",
    "availability": "GenerallyAvailable",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_documents.partialUpdate",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/documents/partial-update",
    "pathname": "/api-reference/documents/partial-update",
    "title": "Update Document",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Documents",
        "pathname": "/api-reference/documents"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documents.partialUpdate",
    "method": "PATCH",
    "endpoint_path": "/v1/documents/:id",
    "endpoint_path_alternates": [
      "/v1/documents/{id}",
      "https://api.vellum.ai/v1/documents/:id",
      "https://api.vellum.ai/v1/documents/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Update a Document, keying off of either its Vellum-generated ID or its external ID. Particularly useful for updating its metadata.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742:endpoint_documents.destroy",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/documents/destroy",
    "pathname": "/api-reference/documents/destroy",
    "title": "Destroy",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Documents",
        "pathname": "/api-reference/documents"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_documents.destroy",
    "method": "DELETE",
    "endpoint_path": "/v1/documents/:id",
    "endpoint_path_alternates": [
      "/v1/documents/{id}",
      "https://documents.vellum.ai/v1/documents/:id",
      "https://documents.vellum.ai/v1/documents/%7Bid%7D"
    ],
    "description": "Delete a Document, keying off of either its Vellum-generated ID or its external ID.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://documents.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.list_test_suite_test_cases",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/test-suites/test-cases/list",
    "pathname": "/api-reference/test-suites/test-cases/list",
    "title": "List Test Cases",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Test Suites",
        "pathname": "/api-reference/test-suites"
      },
      {
        "title": "Test Cases",
        "pathname": "/api-reference/test-suites/test-cases"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_testSuites.list_test_suite_test_cases",
    "method": "GET",
    "endpoint_path": "/v1/test-suites/:id/test-cases",
    "endpoint_path_alternates": [
      "/v1/test-suites/{id}/test-cases",
      "https://api.vellum.ai/v1/test-suites/:id/test-cases",
      "https://api.vellum.ai/v1/test-suites/%7Bid%7D/test-cases"
    ],
    "response_type": "json",
    "description": "List the Test Cases associated with a Test Suite",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.upsert_test_suite_test_case",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/test-suites/test-cases/upsert",
    "pathname": "/api-reference/test-suites/test-cases/upsert",
    "title": "Upsert Test Cases",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Test Suites",
        "pathname": "/api-reference/test-suites"
      },
      {
        "title": "Test Cases",
        "pathname": "/api-reference/test-suites/test-cases"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_testSuites.upsert_test_suite_test_case",
    "method": "POST",
    "endpoint_path": "/v1/test-suites/:id/test-cases",
    "endpoint_path_alternates": [
      "/v1/test-suites/{id}/test-cases",
      "https://api.vellum.ai/v1/test-suites/:id/test-cases",
      "https://api.vellum.ai/v1/test-suites/%7Bid%7D/test-cases"
    ],
    "response_type": "json",
    "description": "Upserts a new test case for a test suite, keying off of the optionally provided test case id.\nIf an id is provided and has a match, the test case will be updated. If no id is provided or no match\nis found, a new test case will be appended to the end.\nNote that a full replacement of the test case is performed, so any fields not provided will be removed\nor overwritten with default values.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.test_suite_test_cases_bulk",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/test-suites/test-cases/bulk-update",
    "pathname": "/api-reference/test-suites/test-cases/bulk-update",
    "title": "Bulk Update Test Cases",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Test Suites",
        "pathname": "/api-reference/test-suites"
      },
      {
        "title": "Test Cases",
        "pathname": "/api-reference/test-suites/test-cases"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_testSuites.test_suite_test_cases_bulk",
    "method": "POST",
    "endpoint_path": "/v1/test-suites/:id/test-cases-bulk",
    "endpoint_path_alternates": [
      "/v1/test-suites/{id}/test-cases-bulk",
      "https://api.vellum.ai/v1/test-suites/:id/test-cases-bulk",
      "https://api.vellum.ai/v1/test-suites/%7Bid%7D/test-cases-bulk"
    ],
    "response_type": "stream",
    "description": "Created, replace, and delete Test Cases within the specified Test Suite in bulk",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "stream"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.delete_test_suite_test_case",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/test-suites/test-cases/delete",
    "pathname": "/api-reference/test-suites/test-cases/delete",
    "title": "Delete Test Case",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Test Suites",
        "pathname": "/api-reference/test-suites"
      },
      {
        "title": "Test Cases",
        "pathname": "/api-reference/test-suites/test-cases"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_testSuites.delete_test_suite_test_case",
    "method": "DELETE",
    "endpoint_path": "/v1/test-suites/:id/test-cases/:test_case_id",
    "endpoint_path_alternates": [
      "/v1/test-suites/{id}/test-cases/{test_case_id}",
      "https://api.vellum.ai/v1/test-suites/:id/test-cases/:test_case_id",
      "https://api.vellum.ai/v1/test-suites/%7Bid%7D/test-cases/%7Btest_case_id%7D"
    ],
    "description": "Deletes an existing test case for a test suite, keying off of the test case id.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_testSuiteRuns.create",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/test-suites/runs/create",
    "pathname": "/api-reference/test-suites/runs/create",
    "title": "Create Test Suite Run",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Test Suites",
        "pathname": "/api-reference/test-suites"
      },
      {
        "title": "Test Suite Runs",
        "pathname": "/api-reference/test-suites/runs"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_testSuiteRuns.create",
    "method": "POST",
    "endpoint_path": "/v1/test-suite-runs",
    "endpoint_path_alternates": [
      "/v1/test-suite-runs",
      "https://api.vellum.ai/v1/test-suite-runs",
      "https://api.vellum.ai/v1/test-suite-runs"
    ],
    "response_type": "json",
    "description": "Trigger a Test Suite and create a new Test Suite Run",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_testSuiteRuns.retrieve",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/test-suites/runs/retrieve",
    "pathname": "/api-reference/test-suites/runs/retrieve",
    "title": "Retrieve Test Suite Run",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Test Suites",
        "pathname": "/api-reference/test-suites"
      },
      {
        "title": "Test Suite Runs",
        "pathname": "/api-reference/test-suites/runs"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_testSuiteRuns.retrieve",
    "method": "GET",
    "endpoint_path": "/v1/test-suite-runs/:id",
    "endpoint_path_alternates": [
      "/v1/test-suite-runs/{id}",
      "https://api.vellum.ai/v1/test-suite-runs/:id",
      "https://api.vellum.ai/v1/test-suite-runs/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Retrieve a specific Test Suite Run by ID",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.subpackage_testSuiteRuns.listExecutions",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/test-suites/runs/list-executions",
    "pathname": "/api-reference/test-suites/runs/list-executions",
    "title": "List Test Suite Executions",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Test Suites",
        "pathname": "/api-reference/test-suites"
      },
      {
        "title": "Test Suite Runs",
        "pathname": "/api-reference/test-suites/runs"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_testSuiteRuns.listExecutions",
    "method": "GET",
    "endpoint_path": "/v1/test-suite-runs/:id/executions",
    "endpoint_path_alternates": [
      "/v1/test-suite-runs/{id}/executions",
      "https://api.vellum.ai/v1/test-suite-runs/:id/executions",
      "https://api.vellum.ai/v1/test-suite-runs/%7Bid%7D/executions"
    ],
    "response_type": "json",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.add_entity_to_folder",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/folders/add-entity-to-folder",
    "pathname": "/api-reference/folders/add-entity-to-folder",
    "title": "Add Entity to Folder",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Folders",
        "pathname": "/api-reference/folders"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_folderEntities.add_entity_to_folder",
    "method": "POST",
    "endpoint_path": "/v1/folders/:folder_id/add-entity",
    "endpoint_path_alternates": [
      "/v1/folders/{folder_id}/add-entity",
      "https://api.vellum.ai/v1/folders/:folder_id/add-entity",
      "https://api.vellum.ai/v1/folders/%7Bfolder_id%7D/add-entity"
    ],
    "description": "Add an entity to a specific folder or root directory.\nAdding an entity to a folder will remove it from any other folders it might have been a member of.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.list-1",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/folders/list-folder-entities",
    "pathname": "/api-reference/folders/list-folder-entities",
    "title": "List Folder Entities",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Folders",
        "pathname": "/api-reference/folders"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_folderEntities.list",
    "method": "GET",
    "endpoint_path": "/v1/folder-entities",
    "endpoint_path_alternates": [
      "/v1/folder-entities",
      "https://api.vellum.ai/v1/folder-entities",
      "https://api.vellum.ai/v1/folder-entities"
    ],
    "response_type": "json",
    "description": "List all folder entities within a specified folder.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.retrieve-1",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/secrets/retrieve-workspace-secret",
    "pathname": "/api-reference/secrets/retrieve-workspace-secret",
    "title": "Retrieve Workspace Secret",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Secrets",
        "pathname": "/api-reference/secrets"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_workspaceSecrets.retrieve",
    "method": "GET",
    "endpoint_path": "/v1/workspace-secrets/:id",
    "endpoint_path_alternates": [
      "/v1/workspace-secrets/{id}",
      "https://api.vellum.ai/v1/workspace-secrets/:id",
      "https://api.vellum.ai/v1/workspace-secrets/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Used to retrieve a Workspace Secret given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  },
  {
    "objectID": "test:test.com:83d12b33-dab6-466a-9d55-0dbc8135e742.partialUpdate",
    "org_id": "test",
    "domain": "test.com",
    "canonicalPathname": "/api-reference/secrets/update-workspace-secret",
    "pathname": "/api-reference/secrets/update-workspace-secret",
    "title": "Update Workspace Secret",
    "breadcrumb": [
      {
        "title": "API Reference",
        "pathname": "/api-reference"
      },
      {
        "title": "Secrets",
        "pathname": "/api-reference/secrets"
      }
    ],
    "tab": {
      "title": "API Reference",
      "pathname": "/api-reference"
    },
    "visible_by": [
      "role/everyone"
    ],
    "authed": false,
    "page_position": 0,
    "api_type": "http",
    "api_definition_id": "83d12b33-dab6-466a-9d55-0dbc8135e742",
    "api_endpoint_id": "endpoint_workspaceSecrets.partialUpdate",
    "method": "PATCH",
    "endpoint_path": "/v1/workspace-secrets/:id",
    "endpoint_path_alternates": [
      "/v1/workspace-secrets/{id}",
      "https://api.vellum.ai/v1/workspace-secrets/:id",
      "https://api.vellum.ai/v1/workspace-secrets/%7Bid%7D"
    ],
    "response_type": "json",
    "description": "Used to update a Workspace Secret given its ID or name.",
    "availability": "Beta",
    "environments": [
      {
        "id": "Production",
        "url": "https://api.vellum.ai"
      }
    ],
    "default_environment_id": "Production",
    "keywords": [
      "endpoint",
      "api",
      "http",
      "rest",
      "openapi",
      "json"
    ],
    "type": "api-reference"
  }
]